[{"title":"Docker入门","url":"/posts/89826705/","content":"最近忙着写项目，好久没更新内容了。而且就在昨天，重装系统的时候我居然忘了把博客的本地文件保存一份！！！现在我已经失去了前面博客的所有内容，不得不花费大量时间重新把前面的内容整理一次，孩子心里苦啊。\n闲话就聊到这里,今天我们来了解一下Docker技术.Docker可以帮助我们快速的实现项目依赖环境的完整打包.方便我们将项目快速的部署到不同的设备上去.\n由于Windows上没有原生的Docker,想要运行需要套几层壳,所以这次我们使用Ubuntu.具体版本为Ubuntu24.04.(当然现在有了WSL2，其实在windows上也不是很麻烦，直接去官网https://www.docker.com/下载即可)\nDocker的安装我们首先来完场Docker的安装.这部分比较简单,先安装一些依赖\nsudo apt-get install ca-certificates curl gnupg lsb-release\n\n然后安装官方的GPG Key\nsudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\n然后将Docker的下载地址放到apt的搜索列表中\necho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\n接着更新一下列表\nsudo apt update\n\n接着下载Docker的社区版本（Docker分为社区版和商业版）\nsudo apt install docker-ce\n\n可以通过\ndocker --version\n\n来判断是否下载成功\n\nDocker的配置到此完成，我们接下来详细的了解一下Docker的结构\n容器与镜像容器与虚拟机的区别在开始这一板块之前，我们先来思考一个问题：假设我现在使用的是Ubuntu22.04,然后下载一个Ubuntu24.04的Docker，那么我是否能使用Ubuntu24.04的全部功能呢？这个问题在虚拟机上是显然的，但是在Docker中却不那么肯定。\n我们可以看一下这张图：\n\n这张图体现了虚拟机和Docker的重要区别：虚拟机的虚拟是内核级别的，所有的虚拟机相互独立，互不干扰。但是，所有的Docker共用设备的内核空间，只拥有独立的用户空间。也就是说，如果ubuntu22.04的内核支持相关功能，我们是可以顺利使用的，但如果内核不知相关功能，我们就无能为力了。\n此外，还有一点值得注意：容器与镜像的区别。\n直接构建了解了这些，我们开始尝试自己构建一个镜像，每一个应用都运行在操作系统上，所以构建自己的镜像也必须基于最基本的系统镜像，我们一般称这些镜像为Base镜像（当然，在很多时候我们也不一定真的从最基本的镜像开始构建，而是使用一些已经安装了一些必要的环境的镜像开始构建）。我们这里尝试去构建一个包含了jdk的ubuntu镜像\n首先我们拉取一个ubuntu的Base镜像(最近由于DockerHub的限制，很多镜像源都不能用了，如果下载不下来，请自行寻找合适的镜像源或者科学上网)\ndocker pull ubuntu:22.04\n\n这里注意，一个镜像的标准名称通常为name:tag的格式，name用来说明名称，tag用来说明版本\n下载完成后可以通过\ndocker images\n\n来查看当前的所有镜像\n\n可以看到，刚刚下载的Ubuntu镜像小的惊人，只有77.9MB,这是因为作为Base镜像，只保留了最基本的用户空间运行能力，我们平时很多常用的命令都是无法在这个镜像中执行的。\n接下来在容器中运行这个镜像\ndocker run -it ubuntu:22.04\n\n其中i参数指创建一个标准的输入输出接口，t参数指创建一个虚拟的tty设备来作为终端供我们使用，这两个参数一般同时使用，效果如下：\n我们已经进入了基于ubuntu镜像创建的容器的内部\n我们的目的是构建一个包含jdk的ubuntu镜像，所以现在执行下列命令\napt update &amp;&amp; apt install -y openjdk-21-jdk\n\n下载完成后可以使用exit直接退出\n现在查看以下我们的容器\ndocker ps -a\n\n如果不使用a参数则只显示处于运行状态下的容器\n\n接下来执行\ndocker commit 容器ID/名称 新的镜像名\n\nDocker中所有可以使用id的地方都可以使用ID的一部部分，只要能保证具有唯一性就好，例如我们可以在此处使用\ndocker commit fd jdk:21\n\n看一看结果\n\n注意到经过我们的一番操作后镜像的体积发生了巨大的膨胀，这是因为我们在下载jdk时不但下载了jdk,还下载了jdk运行时必要的操作系统依赖。\n对于已经存在的镜像，我们可以\ndocker start name/id #启动现有的镜像docker stop name/id #停止正在运行的镜像\n\n我们可以使用这种方法去构建任何镜像，但这种镜像的构建存在一个问题：不够透明。除你之外没有人知道这个镜像是如何被构建的，对个人使用来说，这种构建方式显然是无所谓的，但是如果这个镜像是面向其他人的，我们就不应该这么做，我们需要使用Dockerfile来完成构建\n通过Dockerfile构建在开始之前我们先删除之前创造的镜像与容器\ndocker rmi 镜像ID #删除镜像docker rm 容器ID #删除容器\n\n同样的，只要输入ID的开头，确保唯一性即可\n接下来我们创建一个名为Dockerfile的文件，并写入如下的内容\nFROM ubuntu:22.04RUN apt update &amp;&amp; apt install -y openjdk-21-jdk\n\n在该文件目录下执行\ndocker build -t jdk:21 .\n\n就能得到和我们之前所构建的jdk镜像完全相同的镜像了\n下面我展示一些在Dockerfile中常使用的命令\nFROM &lt;基础镜像&gt; #从对应的基础镜像开始构建LABEL xxx=xx #给镜像添加元数据，一般用来标识作者，版本等信息ARG xxx=xx #创建一个名为xxx的参数，其值为xx,为此后调用这个值提供方便RUN xxx #在基础镜像内执行xxxCOPY /xx /xxx #将/xx目录下的内容复制到镜像的/xxx目录下ADD https://example.com/file.tar.gz /app/ #与COPY类似，但支持远程下载WORKDIR /xx #设置容器启动时将自动跳转到容器内的/xx目录下ENV xxx=xx #为镜像添加一个名称为xxx的环境变量，其值为xxEXPOSEE xxx #对外暴露容器的xxx端口VOLUME /xx #在容器的/xx目录下创建一个挂载点用于数据持久化，这点我们后面再解释ENTRYPOINT xxx #在容器启动时自动执行xxx,优先级高于CMDCMD xxx #在容器启动时自动执行xxx\n\n当然，这并不是全部的命令，但大多数时候对我们来说已经够用了\n在这部分的最后，让我们了解一下如何将我们所创建的镜像推送到DockerHub，首先自行到Dockerhub创建一个仓库\n\n接下来我们将我们之前的镜像重新命名后推送\ndocker tag jdk:21 myjdk:21docker push 你的用户名/myjdk:21\n\n根据规范，我们必须在推送时添加自己的用户名来保证推送到属于我们自己的仓库，在拉取时同样采用\ndocker pull 你的用户名/myjdk:21\n\n的格式来确保获得正确的镜像\n这一步操作如果网络环境好可以试一试，毕竟一次性要上传800MB,在当前网络环境下有时候会比较困难\nDocker网络管理接下来我们来了解一下Docker的网络管理，我们执行如下的命令\ndocker network ls\n\n\n我们可以看到当前总共有三个网路，这三个网络是Docker在下载时就帮我们创建的，分别对应Docker支持的三种网络类型bridge null host\n我们首先来看看null网络，这个网络中只有一个本地环路，与宿主机的网络环境相互隔离，无法通过网络访问，用于部分有特殊安全需求的环境。如果想使用null网络，可以使用\ndocker run --network=none jdk:21\n\n然后是host网络，如果容器使用的是这种网络，相当于直接使用宿主机的网络环境，在这种网络下，我们，容器中的网络配置与宿主保持一致，不需要镜像额外的开放端口等操作。在这种模式下，网络通信的损失是最小的.如果想使用我们\n最后是bridge网络，或者说是桥接网络，你可以简单的理解为在宿主机上创建了一个虚拟的局域网，宿主机与容器都是这个虚拟局域网的一台设备，不同设备之间通过这个局域网进行信息交互。这也是所有容器的默认网络模式。在这种模式下，我们前面的在Dockerfile中主动暴露端口的行为就有了意义，举个简单的例子\ndocker run -p 1234:80 -n test jdk:21\n\n这里我使用了两个参数，p参数用来指定端口映射，将宿主机的1234端口映射到容器的80端口，此时对宿主机1234端口的访问就会通过桥接网络转发到容器的80端口。n参数是给容器命名的，我们之前所创建的容器起名称都是docker随即生产的，我们可以通过这个参数手动指定。\n在这里你可能会问，那我们之前在Dockerfile中提到的EXPOSE指令又有什么作用呢？这个指令更多的起到提醒作用，用于提醒用户需要将这个端口映射到宿主机中\n我们也可以创建自己的网络，例如这样\ndocker network creat --driver bridge test\n\n这样我们就创建了一个名为test的桥接网络，我们在启动时可以手动指定使用的网络\ndocker run --network=test image\n\n注意，虽然都是使用桥接网络，但是test网络与bridge网络两个网络是互相隔离的，无法互相进行通信，当然，我们也可以主动进行连接\ndocker network connect test containerID/name\n\n此时容器就被主动的连接到了test网络\n容器数据持久化还记得我们上面提到的volume指令吗？对于一个一般的容器，在停止运行时所有运行时产生的数据都将被删除，这无疑是我们所不想看到的，所以我们可以使用VOLUME指令创建挂载点，此时docker会产生一个匿名卷来存储doker对应目录下的数据，这个匿名卷在宿主机上的路径一般为/var/lib/docker/volumes，不过我们可以选择进一步的定制化一些，我们可以将容器的数据挂载到宿主机的指定路径下，使用\ndocker run -v /host/path:/container/path image\n\n此时会将容器的&#x2F;container&#x2F;path与宿主机的&#x2F;host&#x2F;path相互绑定，宿主机与容器任何一方对数据的修改都会在另一方体现\n如果我们使用v参数但不指定宿主机路径，则会在宿主机上自动创建对应路径\n如果我们想要在多个容器之间共享数据呢，聪明的你一定想到创建一个公共目录，经所有容器都挂载到对应的目录。但是我们还有别的办法：直接将一个容器的路径挂载到另一个容器\ndocker run -p 80:80 --volumes-from=data_test test\n\n此时test继承了data_test的挂载信息，在总体容器数量比较多时我们通常会创建一个专门的容器用来管理数据（被称为数据卷容器），例如上面的data_test,所有的容器再继承其挂载方式\nDocker容器管理接下来我们来聊一聊对运行状态下的容器的管理，有以下常用的命令\ndocker log 容器名/ID\n\n可以用来输出容器中的控制台信息（f参数可用来保持持续输出）\ndocker attach 容器ID/名称\n\n直接进入某个运行的容器的内部，注意在完成操作后先按Ctrl+P再按Ctrl+Q退出，千万不要按Ctrl+C这会导致容器停止运行\ndocker exec -it 容器ID/名称\n\n为容器创建一个新的bash终端，如果容器中运行的项目会不断的对控制台输出信息，那么可以通过这个指令开启一个新的终端来对容器进行操作\ndocker stats\n\n用于查看所有容器的状态\ndocker top 容器ID/名称\n\n查看某个容器的所有进程信息\n接下来是几个比较不推荐的\ndocker kill 容器ID/名称 #强制终止容器docker pause 容器ID/名称 #暂停容器docker unpause 容器ID/名称 #与上一条相反\n\n其实还有很多操作，但是这些操作都是偏运维向的，这里就不做介绍了\n常用参数介绍注意，docker非常重视灵活性，所有在dockefile中规定的东西都可以被在启动时覆盖，实际的覆盖操作使用以下这些参数\n\n\n\n参数\n描述\n示例\n\n\n\n\n\n-d\n后台运行容器\ndocker run -d IMAGE\n\n\n\n\n-it\n交互式终端，-i 保持标准输入打开，-t 分配一个伪终端\ndocker run -it IMAGE\n\n\n\n\n--name\n为容器指定一个名称\ndocker run --name mycontainer -d IMAGE\n\n\n\n\n-p\n端口映射，格式为 主机端口:容器端口\ndocker run -p 8080:80 -d IMAGE\n\n\n\n\n-v\n数据卷映射，格式为 主机路径:容器路径[:权限]\ndocker run -v /host/path:/container/path -d IMAGE\n\n\n\n\n--env 或 -e\n设置环境变量\ndocker run --env MY_VAR=value -d IMAGE\n\n\n\n\n--network\n将容器连接到指定的 Docker 网络\ndocker run --network mynetwork -d IMAGE\n\n\n\n\n--restart\n设置容器的重启策略，可选值为 no、on-failure、always、unless-stopped\ndocker run --restart always -d IMAGE\n\n\n\n\n--link\n将容器连接到另一个容器\ndocker run --link other-container:alias -d IMAGE\n\n\n\n\n--cpus\n限制容器使用的 CPU 资源\ndocker run --cpus=&quot;1.5&quot; -d IMAGE\n\n\n\n\n--memory\n限制容器使用的内存\ndocker run --memory=&quot;256m&quot; -d IMAGE\n\n\n\n\n--gpus\n指定容器可以访问的 GPU 设备\ndocker run --gpus all -d IMAGE\n\n\n\n\n--log-driver\n指定日志驱动\ndocker run --log-driver=syslog -d IMAGE\n\n\n\n\n--health-cmd\n配置容器的健康检查命令\n&#96;docker run –health-cmd&#x3D;”curl -f http://localhost/\n\nexit 1” -d IMAGE&#96;\n\n\n--user\n指定容器内进程的用户\ndocker run --user username -d IMAGE\n\n\n\n\n--security-opt\n设置 SELinux 或 AppArmor 配置\ndocker run --security-opt seccomp=unconfined -d IMAGE\n\n\n\n\n--cap-add\n添加容器的 Linux 能力\ndocker run --cap-add=SYS_ADMIN -d IMAGE\n\n\n\n\n--cap-drop\n删除容器的 Linux 能力\ndocker run --cap-drop=SYS_ADMIN -d IMAGE\n\n\n\n\n--privileged\n给容器赋予特权，可以访问主机的设备\ndocker run --privileged -d IMAGE\n\n\n\n\n--tmpfs\n在容器内创建临时文件系统\ndocker run --tmpfs /tmp -d IMAGE\n\n\n\n\n--ulimit\n设置容器的资源限制，如最大打开文件数、最大进程数等\ndocker run --ulimit nofile=1024:1024 -d IMAGE\n\n\n\n\n--hostname\n设置容器的主机名\ndocker run --hostname my_container -d IMAGE\n\n\n\n\n--dns\n指定容器使用的自定义 DNS 服务器\ndocker run --dns 8.8.8.8 -d IMAGE\n\n\n\n\n--dns-search\n指定容器的 DNS 域\ndocker run --dns-search example.com -d IMAGE\n\n\n\n\n--entrypoint\n覆盖镜像的默认入口点\ndocker run --entrypoint /custom_entrypoint -d IMAGE\n\n\n\n\n--rm\n容器退出时自动删除容器\ndocker run --rm -d IMAGE\n\n\n\n\n--mount\n更详细的挂载配置，支持类型 bind、volume、tmpfs\ndocker run --mount type=bind,source=/data,target=/app/data -d IMAGE\n\n\n\n\n--shm-size\n设置容器的共享内存大小\ndocker run --shm-size 2g -d IMAGE\n\n\n\n\n--volume-driver\n指定容器使用的卷驱动程序\ndocker run --volume-driver my_driver -d IMAGE\n\n\n\n\n--env-file\n从文件读取环境变量\ndocker run --env-file=env.list -d IMAGE\n\n\n\n\n--label\n为容器添加元数据标签\ndocker run --label &quot;env=prod&quot; -d IMAGE\n\n\n\n\n需要特别说明的是ENTRYPOINT可以通过--entrypoint  覆盖，而CMD指令可以通过类似\ndocker run my_image echo &quot;Hello, World!&quot;\n\n这样原来的CMD命令将会被覆盖，如果需要的命令过于复杂，你还可以这样\ndocker run my_image &lt; cmd.sh\n\n直接编写一份完整的脚本然后导入\n结语如果你之前来过我的站，你可能会发现所有的之前的文章都已经消失了，由于某次出人意料的事故，所有之前写下的文章都美丽，悲～～～。所以只好从零开始了，有很多东西确实比较有用，有空的话我会尽力再尝试写一份的\n\n","tags":["杂谈"]},{"title":"IDEA中VIM插件的使用","url":"/posts/74745528/","content":"  今天我们讲一讲关于idea中vim插件的使用。其实网上一直有这样两波人，一批人在疯狂的吹嘘vim到底有多好用，甚至看不起平时使用IDE的人；另一批人却将vim的使用者称之为装。 从我个人的使用感受上来说，vim确实是个好东西，唯一的问题就是不怎么好上手，在习惯以后确实能够大大提高编码效率。但是真的完全用vim写代码，需要做各种繁琐的配置，给vim安装各种各样的插件，还不一定能百分百达到完整的IDE的效果，所以我的选择是IDEEA加vim插件，使用起来感觉要好很多\nvim插件下载几乎所有的主流IDE都有对应的vim插件，而且大部分还做的不错。在IDEA中打开自带的插件市场搜索vim并下载下面的三个插件\n\n下载完成后你可以看到类似的状态，右下角出现了一个绿色的normal,光标变成了按过Insert键后的样式就说明下载成功了\n\n基本的使用接下来讲一下vim的基本使用，这些操作和vim保持一致，可以在任何一个vim环境中使用。\n我实在懒得把这些东西重写一次，所以直接使用来自于菜鸟教程的表格，这里是原网页https://www.runoob.com/linux/linux-vim.html\n\n\n\n移动光标的方法\n\n\n\n\nh 或 向左箭头键(←)\n光标向左移动一个字符\n\n\nj 或 向下箭头键(↓)\n光标向下移动一个字符\n\n\nk 或 向上箭头键(↑)\n光标向上移动一个字符\n\n\nl 或 向右箭头键(→)\n光标向右移动一个字符\n\n\n如果你将右手放在键盘上的话，你会发现 hjkl 是排列在一起的，因此可以使用这四个按钮来移动光标。 如果想要进行多次移动的话，例如向下移动 30 行，可以使用 “30j” 或 “30↓” 的组合按键， 亦即加上想要进行的次数(数字)后，按下动作即可！\n\n\n\n[Ctrl] + [f]\n屏幕『向下』移动一页，相当于 [Page Down]按键 (常用)\n\n\n[Ctrl] + [b]\n屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用)\n\n\n[Ctrl] + [d]\n屏幕『向下』移动半页\n\n\n[Ctrl] + [u]\n屏幕『向上』移动半页\n\n\n+\n光标移动到非空格符的下一行\n\n\n-\n光标移动到非空格符的上一行\n\n\nn\n那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一行的 n 个字符。例如 20 则光标会向后面移动 20 个字符距离。\n\n\n0 或功能键[Home]\n这是数字『 0 』：移动到这一行的最前面字符处 (常用)\n\n\n$ 或功能键[End]\n移动到这一行的最后面字符处(常用)\n\n\nH\n光标移动到这个屏幕的最上方那一行的第一个字符\n\n\nM\n光标移动到这个屏幕的中央那一行的第一个字符\n\n\nL\n光标移动到这个屏幕的最下方那一行的第一个字符\n\n\nG\n移动到这个档案的最后一行(常用)\n\n\nnG\nn 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu)\n\n\ngg\n移动到这个档案的第一行，相当于 1G 啊！ (常用)\n\n\nn\nn 为数字。光标向下移动 n 行(常用)\n\n\n搜索替换\n\n\n\n&#x2F;word\n向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 vbird 这个字符串，就输入 &#x2F;vbird 即可！ (常用)\n\n\n?word\n向光标之上寻找一个字符串名称为 word 的字符串。\n\n\nn\n这个 n 是英文按键。代表重复前一个搜寻的动作。举例来说， 如果刚刚我们执行 &#x2F;vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为 vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为 vbird 的字符串！\n\n\nN\n这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 &#x2F;vbird 后，按下 N 则表示『向上』搜寻 vbird 。\n\n\n使用 &#x2F;word 配合 n 及 N 是非常有帮助的！可以让你重复的找到一些你搜寻的关键词！\n\n\n\n:n1,n2s&#x2F;word1&#x2F;word2&#x2F;g\nn1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则： 『:100,200s&#x2F;vbird&#x2F;VBIRD&#x2F;g』。(常用)\n\n\n:1,$s&#x2F;word1&#x2F;word2&#x2F;g 或 :%s&#x2F;word1&#x2F;word2&#x2F;g\n从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！(常用)\n\n\n:1,$s&#x2F;word1&#x2F;word2&#x2F;gc 或 :%s&#x2F;word1&#x2F;word2&#x2F;gc\n从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用)\n\n\n删除、复制与贴上\n\n\n\nx, X\n在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用)\n\n\nnx\nn 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。\n\n\ndd\n剪切游标所在的那一整行(常用)，用 p&#x2F;P 可以粘贴。\n\n\nndd\nn 为数字。剪切光标所在的向下 n 行，例如 20dd 则是剪切 20 行(常用)，用 p&#x2F;P 可以粘贴。\n\n\nd1G\n删除光标所在到第一行的所有数据\n\n\ndG\n删除光标所在到最后一行的所有数据\n\n\nd$\n删除游标所在处，到该行的最后一个字符\n\n\nd0\n那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符\n\n\nyy\n复制游标所在的那一行(常用)\n\n\nnyy\nn 为数字。复制光标所在的向下 n 行，例如 20yy 则是复制 20 行(常用)\n\n\ny1G\n复制游标所在行到第一行的所有数据\n\n\nyG\n复制游标所在行到最后一行的所有数据\n\n\ny0\n复制光标所在的那个字符到该行行首的所有数据\n\n\ny$\n复制光标所在的那个字符到该行行尾的所有数据\n\n\np, P\np 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！ 举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？ 那么原本的第 20 行会被推到变成 30 行。 (常用)\n\n\nJ\n将光标所在行与下一行的数据结合成同一行\n\n\nc\n重复删除多个数据，例如向下删除 10 行，[ 10cj ]\n\n\nu\n复原前一个动作。(常用)\n\n\n[Ctrl]+r\n重做上一个动作。(常用)\n\n\n这个 u 与 [Ctrl]+r 是很常用的指令！一个是复原，另一个则是重做一次～ 利用这两个功能按键，你的编辑，嘿嘿！很快乐的啦！\n\n\n\n.\n不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用)\n\n\n第二部分：一般模式切换到编辑模式的可用的按钮说明\n\n\n进入输入或取代的编辑模式\n\n\n\n\ni, I\n进入输入模式(Insert mode)： i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』。 (常用)\n\n\na, A\n进入输入模式(Insert mode)： a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』。(常用)\n\n\no, O\n进入输入模式(Insert mode)： 这是英文字母 o 的大小写。o 为在目前光标所在的下一行处输入新的一行； O 为在目前光标所在的上一行处输入新的一行！(常用)\n\n\nr, R\n进入取代模式(Replace mode)： r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止；(常用)\n\n\n上面这些按键中，在 vi 画面的左下角处会出现『–INSERT–』或『–REPLACE–』的字样。 由名称就知道该动作了吧！！特别注意的是，我们上面也提过了，你想要在档案里面输入字符时， 一定要在左下角处看到 INSERT 或 REPLACE 才能输入喔！\n\n\n\n[Esc]\n退出编辑模式，回到一般模式中(常用)\n\n\n第三部分：一般模式切换到指令行模式的可用的按钮说明\n\n\n指令行的储存、离开等指令\n\n\n\n\n:w\n将编辑的数据写入硬盘档案中(常用)\n\n\n:w!\n若文件属性为『只读』时，强制写入该档案。不过，到底能不能写入， 还是跟你对该档案的档案权限有关啊！\n\n\n:q\n离开 vi (常用)\n\n\n:q!\n若曾修改过档案，又不想储存，使用 ! 为强制离开不储存档案。\n\n\n注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～\n\n\n\n:wq\n储存后离开，若为 :wq! 则为强制储存后离开 (常用)\n\n\nZZ\n这是大写的 Z 喔！如果修改过，保存当前文件，然后退出！效果等同于(保存并退出)\n\n\nZQ\n不保存，强制退出。效果等同于 :q!。\n\n\n:w [filename]\n将编辑的数据储存成另一个档案（类似另存新档）\n\n\n:r [filename]\n在编辑的数据中，读入另一个档案的数据。亦即将 『filename』 这个档案内容加到游标所在行后面\n\n\n:n1,n2 w [filename]\n将 n1 到 n2 的内容储存成 filename 这个档案。\n\n\n:! command\n暂时离开 vi 到指令行模式下执行 command 的显示结果！例如 『:! ls &#x2F;home』即可在 vi 当中察看 &#x2F;home 底下以 ls 输出的档案信息！\n\n\nvim 环境的变更\n\n\n\n:set nu\n显示行号，设定之后，会在每一行的前缀显示该行的行号\n\n\n:set nonu\n与 set nu 相反，为取消行号！\n\n\n大家可以自行查看这些操作。你会发现这些操作保证了我们在双手不离开键盘中心区的前提下可以完成几乎所有的编辑操作，用习惯后还是非常爽的\n简单的配置但是从我个人的使用体验上来说，还是要对插件进行一些简单的配置，这样才能用起来更爽。点击normal左侧的彩色v图标\n\n然后选择settings\n\n接下来进入这个页面\n\n可以避免vim插件覆盖一些我们常用的快捷键的功能，比如我将Ctrl+A,Ctrl+C等常用的按键功能保留了下来\n接下来点击应用后关掉这个页面，再次点击v图标，选择Creat ～&#x2F;.ideavimrc 进入vim插件的配置文件\n我在下面贴一下我自己的配置并提供比较详细的注释，又需要的可以自己改写\nbasicPlug &#x27;machakann/vim-highlightedyank&#x27;&quot; Commentary pluginPlug &#x27;tpope/vim-commentary&#x27;&quot; 1. 基础 Vim 行为&quot; ----------------------------set number&quot; 在编辑器左侧显示绝对行号，有助于快速跳转到指定行（如输入 50G）并与同事共享行号定位。vim原生选项。set relativenumber&quot; 将当前行显示为绝对行号，其它行显示相对行号（与当前行的距离）。在进行跳转（例如 5j、3k）或上下文操作时非常直观。set cursorline&quot; 在当前行绘制高亮背景，增强光标位置的视觉识别，减少长文件中定位迷失的可能。set showmode&quot; 在命令行区域显示当前模式（-- INSERT --、-- VISUAL -- 等），方便快速确认当前是普通模式还是插入模式。set showcmd&quot; 当你输入多键命令（例如 d5w）时，实时在底部显示已输入的部分，帮助跟踪复杂映射或宏输入。set incsearch&quot; 在输入搜索模式（/pattern）时，边输入边高亮匹配，实时预览匹配结果，无需回车确认即可判断效果。set hlsearch&quot; 持续高亮所有与搜索模式匹配的项，便于一次性观察整个文件中的分布位置。set scrolloff=5&quot; 光标上下留有 5 行空白，以保持视野中心；在滚动时不至于光标贴近屏幕边缘。set sidescrolloff=5&quot; 同理，左右侧留 5 列空白，适用于超长行的水平滚动。set clipboard+=unnamed&quot; 将 Vim 的剪贴板与系统剪贴板合并，复制/粘贴可直接与 IDEA 与其他应用共享，免去额外切换。set wildmenu&quot; 启用命令行自动补全菜单，按 Tab 循环选择补全项，比原生补全反馈更友好。set wildmode=longest:full,full&quot; 补全方式：先补全公共前缀，再列出所有匹配项。提升多候选补全的效率与准确性。&quot; 2. Leader 键与快捷键映射&quot; ----------------------------let mapleader=&quot; &quot;&quot; 将“Leader 键”设为空格键；避免与常见 Vim 默认映射冲突，空格易按且手感舒适。&quot; 文件与项目操作nnoremap &lt;leader&gt;w :w&lt;CR&gt;&quot; 在普通模式下，按 空格+w 保存当前文件，等效于 :w。nnoremap &lt;leader&gt;q :q&lt;CR&gt;&quot; 按 空格+q 关闭当前编辑窗口。可按需改为 :bd 以保留分屏布局。nnoremap &lt;leader&gt;ff :action FindInPath&lt;CR&gt;&quot; 空格+ff 调用 IDEA 的“全局查找文件/符号”功能（Find in Path），跨项目搜索。nnoremap &lt;leader&gt;fr :action ReplaceInPath&lt;CR&gt;&quot; 空格+fr 调用“全局替换”功能（Replace in Path），在整个项目中批量替换。&quot; 窗口与标签管理nnoremap &lt;leader&gt;tn :tabnew&lt;CR&gt;&quot; 空格+tn 新建一个标签页，便于并行打开多个文件。nnoremap &lt;leader&gt;to :tabonly&lt;CR&gt;&quot; 空格+to 关闭除当前标签外的所有标签，只保留当前视图。imap a; &lt;Esc&gt;&quot; 将&lt;Esc&gt;映射为a;避免误触的同时方便使用，有些人也比较喜欢jj等映射方式&quot; 3. IntelliJ IDEA Action 映射&quot; ----------------------------&quot; IdeaVim 特有命令格式：:action + IDEA 内部 Action ID&quot; 可在 IDEA 中开启 “IdeaVim: Track Action Ids” 来得知鼠标点击或快捷键触发的 Action ID。nnoremap &lt;leader&gt;cf :action ReformatCode&lt;CR&gt;&quot; 空格+cf 触发 IDEA 的“代码格式化”功能，自动应用项目中的代码风格规则。nnoremap &lt;leader&gt;oi :action OptimizeImports&lt;CR&gt;&quot; 空格+oi 调用“优化导入”，自动移除无用 import 并按配置排序。nnoremap gd :action GotoDeclaration&lt;CR&gt;&quot; 在普通模式下按 gd，跳转到光标所在符号的声明位置，便于快速阅读实现细节。nnoremap gr :action FindUsages&lt;CR&gt;&quot; 按 gr 查找符号所有用法，在底部面板中展示所有引用，方便代码审计与重构。nnoremap &lt;leader&gt;r :action Run&lt;CR&gt;&quot; 空格+r 运行当前上下文（文件、测试或应用），等同于点击工具栏 Run 按钮。nnoremap &lt;leader&gt;d :action Debug&lt;CR&gt;&quot; 空格+d 启动调试，自动进入 Debug 模式，便于单步排查逻辑。&quot; 4. 可选：引入本地 Vim 配置&quot; ----------------------------&quot; 如果你同时在终端使用 Vim，可将常用 Vim 配置放在 ~/.vimrc，&quot; 在 IdeaVim 中通过以下命令复用：&quot; source ~/.vimrc\n\n这里反复提到了leader键，所谓的leader键可以理解为一个前缀键，类似于一个自定义的Ctrl键，默认为反斜杠，长按时进入特殊模式，此时可与继续搭配其他案件实现各种各样的功能\n结语刚刚接触时由于记不清各个案件所以会有比较明显的滞涩感，不过只要时间长了用的熟悉了，以后就难以离开这种感觉了\n\n","tags":["杂谈"]},{"title":"JSON解析","url":"/posts/1028a889/","content":"  既然要手写一个可用的spring框架，那么网络通信部分是必不可少的，既然涉及到了网络通信，那么显然json解析能力是必须具备的，所以我们今天来试着手写一个json解析器吧\nJSON的规则首先我们研究以下JSON解析的问题，开始之前我们可以先看看JSON的标准\n\nJSON（JavaScript Object Notation）是一种轻量级的数据交换格式，易于阅读和编写，也易于机器解析和生成。以下是 JSON 的主要规则和特点：\n1. 基本结构\nJSON 数据由两种结构组成：\n对象（Object）：无序的键值对集合，用花括号 &#123;&#125; 表示。\n数组（Array）：有序的值的集合，用方括号 [] 表示。\n\n\n\n2. 数据类型   JSON 支持以下数据类型：\n\n字符串：用双引号 &quot; 括起来的文本，例如 &quot;Hello, World!&quot;\n数字：整数或浮点数，例如 42 或 3.14\n布尔值：true 或 false\n空值：null\n对象：键值对的集合，例如 &#123; &quot;name&quot;: &quot;Alice&quot;, &quot;age&quot;: 30 &#125;\n数组：值的有序列表，例如 [1, 2, 3, &quot;apple&quot;]\n\n3. 键值对规则\n键（Key）必须是字符串，并且用双引号 &quot; 括起来。\n键和值之间用冒号 : 分隔。\n键值对之间用逗号 , 分隔。\n示例：&#123;  &quot;name&quot;: &quot;Alice&quot;,  &quot;age&quot;: 30,  &quot;isStudent&quot;: false&#125;\n\n4. 数组规则\n数组中的值可以是任何 JSON 支持的数据类型。\n数组中的值用逗号 , 分隔。\n示例：[  &quot;apple&quot;,  &quot;banana&quot;,  42,  true,  &#123; &quot;name&quot;: &quot;Alice&quot; &#125;]\n\n5. 嵌套结构\nJSON 支持嵌套的对象和数组。\n示例：&#123;  &quot;name&quot;: &quot;Alice&quot;,  &quot;age&quot;: 30,  &quot;hobbies&quot;: [&quot;reading&quot;, &quot;traveling&quot;],  &quot;address&quot;: &#123;    &quot;street&quot;: &quot;123 Main St&quot;,    &quot;city&quot;: &quot;New York&quot;  &#125;&#125;\n\n6. 格式规范\nJSON 数据必须是有效的对象或数组。\n键必须用双引号括起来（单引号无效）。\n逗号不能出现在最后一个键值对或数组值之后（即不能有尾随逗号）。\n示例（错误）：&#123; &quot;name&quot;: &quot;Alice&quot;, &#125;  // 错误：尾随逗号\n\n7. JSON 的用途\n用于 Web 应用程序中的数据交换。\n用于配置文件（如 .json 文件）。\n用于 API 数据传输。\n\n8. JSON 与 JavaScript 的关系\nJSON 是 JavaScript 的一个子集，但独立于语言，可以被多种编程语言解析和生成。\n\n总结来说，JSON 是一种简单、灵活且广泛使用的数据格式，遵循上述规则可以确保数据的正确性和可读性。\n\n上面这部分是直接从网上找到的相关规范。仔细考虑以下，该怎们做？\n尝试解析我随便贴一段json,让我们来分析以下我们可能要处理的情况\n&#123;  &quot;name&quot;: &quot;Alice&quot;,  &quot;age&quot;: 30,  &quot;hobbies&quot;: [&quot;reading&quot;, &quot;traveling&quot;],  &quot;address&quot;: &#123;    &quot;street&quot;: &quot;123 Main St&quot;,    &quot;city&quot;: &quot;New York&quot;  &#125;&#125;\n\n我们可能遇到的情况包括：\n\n遇到&#123;，表示一层解析的开始，如果在本层解析过程中遇到了新的&#123;，则进入新的解析层，换句话说，我们需要一个递归结构来处理问题\n遇到&#125;，表示当前层的解析结束\n遇到“，表示某个key或者value,可以考虑通过识别：来辨别这是一个key还是value,\n遇到[,表示数组的开始\n遇到,,表示键值对之间的分割\n遇到/，转义字符，后面的一个字符需要转义，\n\n仔细思考上面的信息，我们可以大概的写出一个可用的demo（建议先自己尝试一下，还是有一点难度的）\npackage Winter.Parser.JsonPaser;import java.util.*;public class JsonParser &#123;    String json;    int index;    private JsonParser(String json) &#123;        this.json = json;        this.index = 0;    &#125;    public void skipWhiteSpace() &#123;        while (Character.isWhitespace(json.charAt(index))) &#123;            index++;        &#125;    &#125;//跳过空格的方法    public void expectString(String target) &#123;        int start = index;        for (int i = 0; i &lt; target.length(); i++) &#123;if (target.charAt(i) != json.charAt(start)) &#123;                throw new RuntimeException(&quot;Expecting string at index &quot; + index + &quot; but found &quot; + target.charAt(i));            &#125;            start++;        &#125;//用于检测程序是否是按照我们期望的方式进行    &#125;    public Object parseValue() &#123;        skipWhiteSpace();        char ch = json.charAt(index);        return switch (ch) &#123;            case &#x27;&#123;&#x27; -&gt; parseObject();//通过首个字符类型判断解析方法            case &#x27;[&#x27; -&gt; parseArray();            case &#x27;&quot;&#x27; -&gt; parseString();            case &#x27;t&#x27; -&gt; parseTrue();            case &#x27;f&#x27; -&gt; parseFalse();            case &#x27;n&#x27; -&gt; parseNull();            default -&gt; &#123;                if (ch == &#x27;-&#x27; || Character.isDigit(ch)) &#123;                    yield parseNumber();                &#125;//处理判断数字的情况                throw new RuntimeException(&quot;Unexpected character at position &quot; + index + &quot;: &quot; + ch);            &#125;        &#125;;    &#125;    private Object parseObject() &#123;        Map&lt;String, Object&gt; jsonNodeMap = new LinkedHashMap&lt;&gt;();        expectString(&quot;&#123;&quot;);        index++;        skipWhiteSpace();        if(json.charAt(index)==&#x27;&#125;&#x27;)&#123;            index++;            return jsonNodeMap;        &#125;        while (true)&#123;            skipWhiteSpace();            String key = parseString();//由于key一定是字符串，直接用字符串的方式解析            skipWhiteSpace();            expectString(&quot;:&quot;);            index++;//跳过冒号            Object value = parseValue();//获取value            jsonNodeMap.put(key,value);            if(json.charAt(index)==&#x27;&#125;&#x27;)&#123;break;&#125;            if(json.charAt(index) !=&#x27;,&#x27;)&#123;                throw new RuntimeException(&quot;Unexpected character &#x27;&quot; + json.charAt(index) + &quot;&#x27; at index &quot; + index);            &#125;            index++;//用于跳过键值对之间的逗号        &#125;        return jsonNodeMap;    &#125;    private String parseString() &#123;        StringBuilder stringBuilder = new StringBuilder();        expectString(&quot;\\&quot;&quot;);        index++;//跳过引号        skipWhiteSpace();        while (json.charAt(index) != &#x27;&quot;&#x27;) &#123;//处理可能的转义字符            if (json.charAt(index) == &#x27;\\\\&#x27;) &#123;                index++;//跳过用于转义的\\                char c = json.charAt(index);                switch (c) &#123;                    case &#x27;t&#x27; -&gt; stringBuilder.append(&quot;\\t&quot;);                    case &#x27;f&#x27; -&gt; stringBuilder.append(&quot;\\f&quot;);                    case &#x27;n&#x27; -&gt; stringBuilder.append(&quot;\\n&quot;);                    case &#x27;b&#x27; -&gt; stringBuilder.append(&quot;\\b&quot;);                    case &#x27;r&#x27; -&gt; stringBuilder.append(&quot;\\r&quot;);                    case &#x27;&quot;&#x27; -&gt; stringBuilder.append(&quot;\\&quot;&quot;);                    case &#x27;/&#x27; -&gt; stringBuilder.append(&quot;/&quot;);                    case &#x27;\\\\&#x27; -&gt; stringBuilder.append(&quot;\\\\&quot;);                    case &#x27;u&#x27; -&gt; &#123;//处理特殊的unicode转义                        if (index + 4 &gt;= json.length()) &#123;                            throw new RuntimeException(&quot;Unexpected unicode sequence at index &quot; + index);                        &#125;                        stringBuilder.append((char) Integer.parseInt(json.substring(index+1, index + 4), 16));                        index += 4;                    &#125;                    default -&gt; throw new RuntimeException(&quot;Unexpected character &#x27;&quot; + c + &quot;&#x27; at index &quot; + index);                &#125;                index++;//跳过被转义的字符            &#125; else &#123;                stringBuilder.append(json.charAt(index));                index++;            &#125;        &#125;        index++;//跳过字符串末尾的引号        return stringBuilder.toString();    &#125;    private Number parseNumber() &#123;        skipWhiteSpace();        int start = index;        if(json.charAt(index)==&#x27;-&#x27;)&#123;            index++;        &#125;        while (index &lt; json.length() &amp;&amp; Character.isDigit(json.charAt(index))) &#123;index++;&#125;        if(json.charAt(index)==&#x27;.&#x27;)&#123;//处理浮点数            do &#123;                index++;            &#125; while (index &lt; json.length() &amp;&amp; Character.isDigit(json.charAt(index)));        &#125;        if(json.charAt(index)==&#x27;e&#x27; || json.charAt(index)==&#x27;E&#x27;)&#123;//处理科学计数法            do &#123;                index++;            &#125; while (index &lt; json.length() &amp;&amp; Character.isDigit(json.charAt(index)));        &#125;        String number = json.substring(start,index);//返回解析得到的数字        if(number.contains(&quot;e&quot;) || number.contains(&quot;E&quot;) || number.contains(&quot;.&quot;))&#123;            return Double.parseDouble(number);        &#125;else &#123;            try &#123;            return Integer.parseInt(number);            &#125;catch (NumberFormatException e)&#123;                return Long.parseLong(number);            &#125;        &#125;    &#125;    public List&lt;Object&gt; parseArray() &#123;        skipWhiteSpace();        List&lt;Object&gt; list = new ArrayList&lt;&gt;();        expectString(&quot;[&quot;);        index++;        skipWhiteSpace();        while (json.charAt(index) != &#x27;]&#x27;) &#123;            skipWhiteSpace();            list.add(parseValue());            if(json.charAt(index)!=&#x27;]&#x27;)&#123;index++;&#125;//用于跳过数组元素之间的逗号        &#125;        index++;//跳过]        return list;    &#125;    private boolean parseFalse() &#123;        expectString(&quot;false&quot;);        index+=5;        return false;    &#125;    private boolean parseTrue()&#123;        expectString(&quot;true&quot;);        index+=4;        return true;    &#125;    private Object parseNull() &#123;        expectString(&quot;null&quot;);        index+=4;        return null;    &#125;    public static void main(String[] args) &#123;        String json = &quot;&#123;\\&quot;greeting\\&quot;:\\&quot;你好，世界！\\&quot;,\\&quot;farewell\\&quot;:\\&quot;再见，朋友！\\&quot;&#125;&quot;;        JsonParser parser = new JsonParser(json);        Object value = parser.parseValue();        System.out.println(value);    &#125;&#125;\n\n感觉如何？如果能够理清所有的逻辑，自己独立写一个还是比较简单的，毕竟也就不到200行的代码量。当然，这个解析器从效率上来将肯定没有办法和一些主流的库比，但不管怎么说，这玩意能用了。\n建议去找ai写几个测试用例试一试（要求不要进行格式化），这个解析器其实只考虑了一些基本情况，你可以试着补足\n查询支持在完成解析后，我们肯定要做一下查询的支持，这样才能方便我们下一步与框架的继承，其实有上面的基础，这一步非常简单，基本的思路如下\npublic class JSON &#123;    private final Map&lt;String,Object&gt; jsonMap;    public JSON(String json) &#123;        JsonParser jp = new JsonParser(json);        Object ret = jp.parseValue();        if(!(ret instanceof Map))&#123;            throw new RuntimeException(&quot;JSON parsing failed&quot;);        &#125;        this.jsonMap = (Map&lt;String, Object&gt;) ret;    &#125;    // 新增查询方法    public List&lt;Object&gt; query(String path) &#123;        List&lt;Object&gt; result = new ArrayList&lt;&gt;();        String[] keys = path.split(&quot;\\\\.&quot;);        queryRecursive(jsonMap, keys, 0, result);        return result;    &#125;//查询方法//用于递归查询    private void queryRecursive(Object value, String[] keys, int depth, List&lt;Object&gt; result) &#123;        if (depth &gt;= keys.length) &#123;//如果递归深度达到了数组长度，停止递归，将结果保存到list中            result.add(value);            return;        &#125;        String key = keys[depth];        if (value instanceof Map) &#123;//如果是一堆嵌套的map,反复的递归直到指定层数            Map&lt;String, Object&gt; map = (Map&lt;String, Object&gt;) value;            if (map.containsKey(key)) &#123;                queryRecursive(map.get(key), keys, depth + 1, result);            &#125;        &#125; else if (value instanceof List) &#123;            List&lt;Object&gt; list = (List&lt;Object&gt;) value;//如果发现数组类型，遍历数组类型的所有元素            for (Object item : list) &#123;//用于处理数组类型                queryRecursive(item, keys, depth, result);            &#125;        &#125;    &#125;   &#125;\n\n怎么样，写起来也不是非常困难，反正就是不断递归查找。\n当然，这个方法也存在问题，首先，返回的是一个list,使用的时候还要做各种类型转换与遍历。但不管怎么说，这玩意能用了，这就是好事。\n结语今天就到这里了，嘴上说简单，但还是写的头疼，是在写不动了，先就此打住吧，下一期实现一个线程池，再下一期写一个请求转发器，最后再补充一些事务方面的东西，支持一下数据库交互，这套框架就差不多将就这能用了\n\n","tags":["手写Spring"]},{"title":"Java的反射与代理","url":"/posts/fabcc437/","content":"最近比较闲，所以来整点活，让我们从0到1手写一个Spring框架吧（只使用Java SE部分的相关内容，不使用任何依赖），不过在正式开始之前，我们要去了解一些基础知识（如果你确信了解了这些知识，可以直接跳过）。\n我们今天来讲一讲反射与代理相关的知识。\n首先我们从Java的类加载机制讲起\nJava的类加载机制我们都知道对于Java来说万物皆对象，所以你猜猜类是什么？类当然是对象了，所有的类在JVM中都被视为一种特殊的对象：Class对象。我们先反编译出来看一看，下面是这个类的头部\npublic final class Class&lt;T&gt; implements Serializable, GenericDeclaration, Type, AnnotatedElement, TypeDescriptor.OfField&lt;Class&lt;?&gt;&gt;, Constable\n\n类的加载流程大致如下\n\nJVM读取.class文件并将字节码转化为二进制数据，依照二进制数据创建一个上面提到的java.lang.Class对象来表示某个特定的类\n进行验证，确保所有的Class对象符合规范，不会危害JVM安全\n开始为对应的静态属性分配内存并设置默认的初始值\n进行解析，为所有的属性，方法添加对应的引用映射，如将类名指向Class对象\n执行类加载操作，调用对应的类加载器进行类的加载\n\n我们可以在Class类中发现Class类的构造方法\nprivate Class(ClassLoader loader, Class&lt;?&gt; arrayComponentType) &#123;    this.classLoader = loader;    this.componentType = arrayComponentType;&#125;\n\n其中的ClassLoader就是我们所说的类加载器\nJava 的类加载器采用层次结构，主要包括以下几种：\n\n启动类加载器（Bootstrap ClassLoader）：\n负责加载 Java 核心类库（如 rt.jar 中的类）。\n它是虚拟机的一部分，通常由 C++ 实现，不是 Java 代码。\n没有父类加载器。\n\n\n扩展类加载器（Extension ClassLoader）：\n负责加载 Java 的扩展类库（如 jre/lib/ext 目录下的 JAR 文件）。\n它是 sun.misc.Launcher$ExtClassLoader 的实例，父类加载器是启动类加载器。\n\n\n应用程序类加载器（Application ClassLoader）：\n也称为系统类加载器，负责加载用户类路径（CLASSPATH）指定的类。\n它是 sun.misc.Launcher$AppClassLoader 的实例，父类加载器是扩展类加载器。\n\n\n自定义类加载器：\n用户可以通过继承 java.lang.ClassLoader 类来实现自定义类加载器。\n用于加载特定路径或来源的类。\n\n\n\n我们先来看一看这个默认的类加载器在干什么吧，由于私有方法太多，我这里只贴一些比较关键的内容，首先是一个最为重要的类加载方法\npublic Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123;    return this.loadClass(name, false);&#125;protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123;    synchronized(this.getClassLoadingLock(name)) &#123;        Class&lt;?&gt; c = this.findLoadedClass(name);//这个方法会调用一个通过C++实现方法检测类是否已经被加载        if (c == null) &#123;//如果没有加载则开始加载            long t0 = System.nanoTime();//此处为获取JVM运行时间            try &#123;                if (this.parent != null) &#123;                    c = this.parent.loadClass(name, false);//如果该加载器存在父类则调用父加载器进行加载                &#125; else &#123;                    c = findBootstrapClassOrNull(name);//如果不存在则进行加载 ，这个方法同样是C++实现的                &#125;            &#125; catch (ClassNotFoundException var10) &#123;//如果父加载器加载失败则捕获异常并继续运行            &#125;            if (c == null) &#123;                long t1 = System.nanoTime();                c = this.findClass(name);//这个方法现在实际上是一个空方法，交给子类实现，默认运行到此处时会直接抛异常                PerfCounter.getParentDelegationTime().addTime(t1 - t0);//这些都是用于记录类加载时间的，用于性能优化                PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);                PerfCounter.getFindClasses().increment();            &#125;        &#125;        if (resolve) &#123;            this.resolveClass(c);//这里是永远不会对外界开放的，不必关心        &#125;        return c;    &#125;&#125;\n\n你会发现这样一个逻辑：一般情况下，总是优先调用父加载器进行加载，这种加载机制被称之为双亲委派机制，原生的所有类加载器都会尽可能的将类加载任务委派给自己的父类的实例，这样做的根本目的是避免一个类被重复加载。\n还有一个比较关键的类加载器方法\nprotected final Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len, ProtectionDomain protectionDomain) throws ClassFormatError     protectionDomain = this.preDefineClass(name, protectionDomain);    String source = this.defineClassSourceLocation(protectionDomain);    Class&lt;?&gt; c = defineClass1(this, name, b, off, len, protectionDomain, source);    this.postDefineClass(c, protectionDomain);    return c;&#125;\n\n这个方法用来将二进制数据转换为类对象，不过很遗憾，这个方法也是C++实现的\n那么这个类加载器在哪里被调用呢，可以简单的认为当某个类第一次被需要时，JVM会尝试调用类加载器来完成加载，这一部分我们在讲解反射部分时会具体的展示。\n我们最后再梳理以下JAVA的类加载机制：当某个类被需要时，JVM将通过类加载器直接加载这个类，这一过程遵循双亲委派机制，加载的结果是一个Class对象\n反射操作接下来我们解释什么是反射。这是我们一般情况下获取对象的方法\nTest test =new Test()\n\n不管怎么改，无论是什么建造者模式，工厂模式等等各种花活，都逃不出在某处new一个对象出来，但是你注意到这样一个问题了吗？Spring的依赖注入是如何实现的，框架的编写者是无法事先得知对象的名称的，又如何获取对象用来注入呢？正是通过反射\n举一个简单的例子，我可以通过这样的方式来构建一个字符串对象\npublic class Main &#123;    public static void main(String[] args) &#123;        try &#123;            String aString =(String) String.class.getConstructor().newInstance();            String bString = (String) Class.forName(&quot;java.lang.String&quot;).getConstructor().newInstance();        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\n你看，我全程绝对没有new,哪怕你顺着源码查下去也绝对找不到任何new,这就是创建对象的另一种方式：反射。你或许想不到这有什么用，但是不要着急，我们先来了解以下关于反射的各种使用\n构建对象在知道对象名称时我们可以这样来实现\npublic static void main(String[] args) &#123;    try &#123;        Class&lt;?&gt; stringClass = Class.forName(&quot;java.lang.String&quot;);        Constructor&lt;?&gt; stringConstructor = stringClass.getConstructor();//获得类的构造器        Object string = stringConstructor.newInstance();//使用构造器来完成构造    &#125; catch (Exception e) &#123;        throw new RuntimeException(e);    &#125;&#125;\n\n上面的是JDK9之后的写法，如果你使用JDK8,甚至可以直接\npublic static void main(String[] args) &#123;    try &#123;        Class&lt;?&gt; stringClass = Class.forName(&quot;java.lang.String&quot;);        Object string = stringClass.newInstance();    &#125; catch (Exception e) &#123;        throw new RuntimeException(e);    &#125;&#125;\n\n我们上面还提到了\nClass&lt;?&gt; intClass =int.class;\n\n这样的方法来获取类对象， class属性是直接来自于Object对象的，所有对象都天然的拥有这个属性。\n当然，对于一个对象，你也可以通过\nString s=&quot;Hello World&quot;;Class&lt;?&gt; c =s.getClass();\n\n这样的方式来获取class对象，在获取类对象后你可以按照上面的流程来获取对象。\n请注意\n\n所有的基本数据类型，基本数据类型的数组类型，基本数据类型的包装类型都拥有独立且唯一的Class对象\n类本身和对应的数组类型是拥有独立的Class对象\n所有的类永远只拥有一个类对象（这一点在必要时是可以被手动打破的）\n\n值得一提的是在利用类对象获取构造器时我们可以主动的选择构造方法，例如对于这个类\npublic class Student &#123;    private String name;    private int age;    public Student(String name, int age) &#123;        this.name = name;        this.age = age;    &#125;    public Student()&#123;        this.age = 0;        this.name = &quot;0&quot;;    &#125;    public String test()&#123;        return name;    &#125;&#125;\n\n我们可以做一个这样的测试\npublic class Main &#123;    public static void main(String[] args) &#123;        try &#123;            Class&lt;?&gt; clazz = Class.forName(&quot;Student&quot;);            Constructor&lt;?&gt; constructor1 = clazz.getConstructor();//获取无参构造            Constructor&lt;?&gt; constructor2 = clazz.getConstructor(String.class,int.class);//获取全参构造            Student student1 = (Student) constructor1.newInstance();            Student student2 = (Student) constructor2.newInstance(&quot;aaa&quot;,111);            System.out.println(student1.test());            System.out.println(student2.test());        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\n获取对象信息我们可以通过反射来获取一些类的信息\nClass&lt;?&gt; clazz = Class.forName(&quot;Student&quot;);System.out.println(clazz.getSuperclass().getName());//获取父类for(Class&lt;?&gt; c: clazz.getInterfaces())&#123;    System.out.println(clazz.getName());//获取接口&#125;for (Annotation annotation: clazz.getAnnotations())&#123;    System.out.println(annotation.annotationType().getName());&#125;//获取注解\n\n此外，反射还能允许我们做一些比较疯狂的事情，比如访问私有字段，还是上面的Student类，age字段显然是私有的，且不存在任何方法进行访问，真的吗\npublic class Main &#123;    public static void main(String[] args) &#123;        try &#123;            Student student = new Student();            Field field = student.getClass().getDeclaredField(&quot;age&quot;);//获取字段            field.setAccessible(true);//强制运行字段访问            System.out.println(field.get(student));//输出0            field.setInt(student, 11);//修改字段值            System.out.println(field.get(student));//输出11        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\n实际上哪怕是final字段。只要愿意也是可以修改的(不过JDK9之后禁止了，但仍然可以通过一些方式开启)\n这也意味这个一个问题：Java的一个核心理念：封装被突破了。你不让我访问？这是你能挡得住的？我不但能访问，我还能修改。所以实际上所有的封装实际上来自于程序员之间的君子约定：我们互相约定好这部分只在规定范围内访问，当然如果你非要访问，也没什么办法。\n调用方法我们甚至都已经访问了属性了，怎么能做不到调用方法呢？为了方便解释我们先改一改Student方法\npublic class Student &#123;    private String name;    private int age;    public Student(String name, int age) &#123;        this.name = name;        this.age = age;    &#125;    public Student()&#123;        this.age = 0;        this.name = &quot;0&quot;;    &#125;    public String test()&#123;        return name;    &#125;    public String test(String s)&#123;        return s+name;    &#125;&#125;\n\n然后直接上\npublic class Main &#123;    public static void main(String[] args) &#123;        try &#123;            Student student = new Student();            Method method = student.getClass().getMethod(&quot;test&quot;,String.class);//通过名称与参数类型来获取方法            System.out.println(method.invoke(student,&quot;1&quot;));        &#125; catch (Exception e) &#123;            throw new RuntimeException(e);        &#125;    &#125;&#125;\n\n由于编译时形参无法被保留，我们无法直接通过名称获得\n特别的，如果参数类型为可变参数，可选择\nMethod method = clazz.getDeclaredMethod(&quot;test&quot;, String[].class);\n\n不过对于私有方法，就像final字段一样，默认情况下无法被直接使用，需要在启动时添加\n--add-opens java.base/java.lang=ALL-UNNAMED\n\n来允许所有反射\n实现一个简单的IoC容器有了上面的基础，我们已经可以实现一个简单的Bean管理器了。我们先回忆以下Spring中Bean管理器拥有哪些功能：\n\n扫面并创建所有的Bean\n完成依赖注入\n支持在任何地方提供Bean\n\n我们逐个来完成这些需求，为了方便，我们这里只提供注解形式的注册Bean的方法，先写一个注解\n@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface Componenet &#123;&#125;\n\n还要写一个用于自动绑定的注解\n@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface AutoWired &#123;&#125;\n\n我们尝试搭建一个大概的框架\npublic class MyIocContainer &#123;    private Map&lt;String, Object&gt; beanMap = new HashMap&lt;&gt;();    private List&lt;String&gt; basePackageList =new ArrayList&lt;&gt;();    private final ClassPathLoader classPathLoader = new ClassPathLoader();    public void addBasePackage(String basePackage) &#123;        this.basePackageList.add(basePackage);    &#125;//用于规定扫描路径    public void scanPackage(Class&lt;?&gt; clazz) &#123;//此处模仿Spring,填入Main.class来确定运行位置        if(basePackageList.isEmpty()) &#123;            basePackageList.add(clazz.getPackage().getName());        &#125;        for (String basePackage : basePackageList) &#123;//遍历所有路径加载Bean            try &#123;                loadBean(beanMap, basePackage);            &#125; catch (Exception e) &#123;                throw new RuntimeException(e);            &#125;        &#125;        autoWiring();    &#125;    public Object getBean(String className) &#123;        return beanMap.get(className);    &#125;    private void autoWiring()&#123;        for (Map.Entry&lt;String, Object&gt; entry : beanMap.entrySet()) &#123;            for (Field field : entry.getValue().getClass().getDeclaredFields()) &#123;//遍历所有的Bean完成依赖注入                field.setAccessible(true);                if(!field.isAnnotationPresent(AutoWired.class))&#123;                    continue;                &#125;                if(beanMap.containsKey(field.getType().getName()))&#123;                    try &#123;                        field.set(entry.getValue(),beanMap.get(field.getType().getName()));                    &#125; catch (IllegalAccessException e) &#123;                        throw new RuntimeException(e);                    &#125;                &#125;else &#123;                    throw new RuntimeException(&quot;只能自动绑定已注册的Bean&quot;);                &#125;            &#125;        &#125;    &#125;&#125;\n\n接下来完成加载Bean的方法\nprivate void loadBean(Map&lt;String,Object&gt; beanMap, String packageName) throws ClassNotFoundException, NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException &#123;    URL dir = classLoader.getResource(packageName);//这部分文件的获取实际上使用类路径，这个概念我们下一篇再来研究    packageName = packageName.replace(&#x27;/&#x27;, &#x27;.&#x27;);    if (dir == null) &#123;        return;    &#125;//如果投入的路径不存在，直接返回    File dirFile = new File(dir.getFile());    if (!dirFile.exists() || !dirFile.isDirectory()) &#123;        return;    &#125;//对应的类路径不存在或者不是目录，直接返回    File[] files = dirFile.listFiles();    if (files != null) &#123;        for (File file : files) &#123;            if (file.isDirectory()) &#123;                loadBean(beanMap, packageName.replace(&quot;.&quot;,&quot;/&quot;) + &quot;/&quot; + file.getName());                continue;            &#125;            String className = packageName + &quot;.&quot; + file.getName().replace(&quot;.class&quot;, &quot;&quot;);            Class&lt;?&gt; clazz = classLoader.loadClass(className);            if(clazz.isInterface() || clazz.isAnnotation() || clazz.isEnum() || Modifier.isAbstract(clazz.getModifiers())) &#123;                continue;            &#125;//接口，抽象类和注解都不能使用构造方法构造，直接跳过避免报错            if(clazz.isAnnotationPresent(Componenet.class)) &#123;                Constructor&lt;?&gt; constructor =clazz.getConstructor();                constructor.setAccessible(true);                beanMap.put(className,constructor.newInstance());            &#125;//加载类        &#125;    &#125;&#125;\n\n虽然非常的简陋，但是这个IoC容器在功能上已经和Spring的IoC容器一致了，我们的全部实现只有不到100行代码。不过，这个容器仍然存在很多问题，举个简单的例子，如果有些类中包含一些static属性，这些属性对应的类在加载当前类时并没有被正确的加载，那么报错是必然的，想一想该怎么处理这个问题。此外，如果类足够多，我们是不是需要添加对应的多线程支持，这个类显然没有考虑多线程的情况，该怎么解决？这些问题我先留在，我们将来再解决。\n动态代理是什么所谓的动态代理就是通过反射获取类的相关方法，在执行时代替这个类去执行对应的方法，在这一过程中可以对方法进行一定的修饰\n所以这有什么用？仔细想想，Mybatis是怎么实现的？不就是通过对接口方法的代理吗？Spring的AOP或者说面向切面怎么实现的，不也是通过对类的代理吗？\n如果你想的话可以直接自己手搓一个动态代理机制出来，不过Java毕竟原生提供了动态代理的实现，我们还是直接调用吧，其中的关键是两个类\n\njava.lang.reflect.Proxy：代理类，用于动态创建代理对象。\njava.lang.reflect.InvocationHandler：调用句柄接口，用于处理代理对象的方法调用。\n\n我们写一个简单的例子，这是一个接口\npublic interface Service &#123;    void doSomething();    String test();&#125;\n\n接着完成这个接口的实现\npublic class ServiceImpl implements Service &#123;    public void doSomething() &#123;        System.out.println(&quot;doSomething&quot;);    &#125;    public String test() &#123;        return &quot;test&quot;;    &#125;&#125;\n\n接下来我们完成一个代理类\npublic class MyProxy implements InvocationHandler &#123;    private final Object target;    public MyProxy(Object target) &#123;        this.target = target;    &#125;    @Override    public Object invoke(Object o, Method method, Object[] objects) throws Throwable &#123;        System.out.println(&quot;执行前操作&quot;);        Object result = method.invoke(target, objects);        System.out.println(&quot;执行后操作&quot;);        return result;    &#125;    public static Object getProxyInstance(Object target) &#123;        return Proxy.newProxyInstance(target.getClass().getClassLoader(),//获得类加载器                target.getClass().getInterfaces(),//获得所实现的接口                new MyProxy(target));//提供一个调用句柄    &#125;&#125;\n\n你会发现这个代理类是通用的，接下来我们尝试使用以下代理类\npublic class Main &#123;    public static void main(String[] args) &#123;        Service service1 = new ServiceImpl();        Service service2 = (Service) MyProxy.getProxyInstance(service1);        service1.doSomething();        service2.doSomething();        System.out.println(service1.test());        System.out.println(service2.test());        System.out.println(service1.hashCode());        System.out.println(service2.hashCode());        System.out.println(service1.getClass().getName());        System.out.println(service2.getClass().getName());    &#125;&#125;\n\n运行结果如下\n执行前操作doSomething执行后操作test执行前操作执行后操作test2084435065执行前操作执行后操作2084435065abc.proxy.ServiceImpljdk.proxy1.$Proxy0\n\n在我不解释的情况下你是否能理解为什么会出现这样的输出结果呢，我们分段来看\n首先是前四行输出，无代理的对象直接输出，有代理的对象按照我们所规定的操作顺序来处理\n接着看5到8行，执行顺序变了吗？并没有，只不过在受到代理的对象中，调用任何一个方法本质上都是通过我们重写的invoke方法来实现的，控制台输出在Invoke方法执行完毕后才得到了要输出的结果\n再来看一看这个8到11行，不是说会产生新的代理类吗，那么为什么哈希是相同的，有点诡异。\n再看一看12和13行，类名不一样，是符合我们预期的，不过还有一个问题，这次从结果上看居然没有被代理？这是什么情况？原因实际上非常简单，如果粗暴的将所有的方法代理，那么区分代理类与原来的类就成了一件麻烦的事情，所以这个方法并没有被代理。\n实现一个简单的AOP框架我们可以使用动态代理来实现一个简单的AOP框架，不过很遗憾我们现有的知识是不足以让我们完整的实现Spring的AOP能力的，JDK的动态代理只做到了类一级，不能精细的对方法进行控制，这种能力需要对特定的字节码进行操作，所以我们还是暂时不讲了。\n不过简单的类级别的AOP框架还是很容易实现的，我们试着写一个吧，为了方便，我们这里只考虑三种情况：执行前，执行后，抛出异常时。我们将这三种情况规范为对应的接口\npublic interface BeforeExecution &#123;    void before(Object[] objects) throws Throwable;&#125;public interface BeforeExecution &#123;    void before(Object[] objects) throws Throwable;&#125;public interface ThrowException &#123;    void throwException(Object[] objects，Throwable throwable) throws Throwable;&#125;//这里的objects实际上是方法的参数，使用者可以利用这些参数\n\n然后考虑创建对应的代理类，我随便写一个可能的例子\npublic class ProxyFactory  &#123;    private static final ClassLoader classLoader = Thread.currentThread().getContextClassLoader();    private static AfterExecution afterExecution = null;    private static ThrowException throwException = null;    private static BeforeExecution beforeExecution = null;    private static boolean isClean=true;    public static void setAfterExecution(AfterExecution afterExecution) &#123;        ProxyFactory.afterExecution = afterExecution;    &#125;    public static void setThrowException(ThrowException throwException) &#123;        ProxyFactory.throwException = throwException;    &#125;    public static void setBeforeExecution(BeforeExecution beforeExecution) &#123;        ProxyFactory.beforeExecution = beforeExecution;    &#125;    private static Object getProxy0(Object target,InvocationHandler invocationHandler) throws Throwable &#123;        return Proxy.newProxyInstance(classLoader, target.getClass().getInterfaces(), invocationHandler);    &#125;    public static Object getProxy(Object target) throws Throwable &#123;        if(!isClean) &#123;            throw new RuntimeException(&quot;使用后未复位&quot;);        &#125;else&#123;            isClean=false;        &#125;        //这里其实采用的是装饰模式的思想，不断的对原来的类进行装饰最终得到我们想要的对象        if (beforeExecution != null) &#123;            target = getProxy0(target, (o, method, objects) -&gt; &#123;                beforeExecution.before(objects);                return method.invoke(o, objects);            &#125;);        &#125;        if (afterExecution != null) &#123;            target =getProxy0(target,(o,method,objects)-&gt;&#123;                Object result = method.invoke(o, objects);                afterExecution.afterExecution(objects);                return result;            &#125;);        &#125;        if (throwException != null) &#123;            target =getProxy0(target,(o,method,objects)-&gt;&#123;                Object result = null;                try &#123;                    result = method.invoke(o, objects);                &#125;catch (Throwable throwable) &#123;                    throwException.throwException(objects ,throwable);                &#125;                return result;            &#125;);        &#125;        return target;    &#125;    public static void clean() &#123;//这是一个复位方法，避免产生不必要的代理        isClean=true;        afterExecution=null;        throwException=null;        beforeExecution=null;    &#125;&#125;\n\n结语这部分的知识就讲到这里，我们下一篇将会探讨关于文件处理相关的问题，顺路继续优化我们的IoC容器\n\n","tags":["手写Spring"]},{"title":"KMP算法","url":"/posts/2da0528d/","content":"今天新开一个 tag，专门用来聊一些算法，我们第一篇讲一讲相当注明的字符串匹配算法，这个算饭解决的是如下的问题：\n\n对于任意一个字符串 s，给定另一个字符串 m，请判断 m 是否为 s 的子串，即 s 中是否包含 m，并指出 s 中出现 m 的具体位置例如对于 abc，我们称 ab，a 等字符串为其子串\n\n我们能想到的最简单的算法就是通过两个循环嵌套来解决问题了，我们认为这种算法的复杂度为 O（m * n），这种写法还是比较简单的，我就不具体写了，今天我们来讲另一种解决思路：KMP 算法。\nKMP 算法由三位大佬共同发现，KMP 分别是三位的名字的首字母，没什么特别的含义。\n在具体的介绍算法之前，我们先引入几个概念：（将字符串 s 称为文本串，m 称为模式串）\n\n前缀： 指的是一个字符串不包含最后一个字符且以该字符串的第一个字符开头的所有子串，例如对于字符串 asdf，其前缀包括 a, as, asd\n后缀： 指的是一个字符串不包含第一个字符且以该字符串的最后一个字符结尾的所有子串，例如对于字符串 asdf, 其后缀包括 f, df, sdf\n最长公共前后缀长度： 即一个字符串的前缀集与后缀集的交集中最长字符串的长度\n部分匹配表： 创建一个与模式串长度相同的数组 n，n[i]的值为由模式串第 0 位到第 i 位所组成的子字符串的最长公共前后缀长度，我们称 n 为该模式串的部分匹配表\n\n然后介绍 KMP 算法的流程（假设文本串为 s，模式串为 m，已经创建了一个部分匹配表 n）：\n\n创建两个指针 i 与 j 分别指向 s[0]与 m[0]\n如果 s[0]与 m[0]相同，i 与 j 共同向后移一位\n如果 s[0]与 m[0]不同，且 j&#x3D;0，那么 i 向后移动一位，如果 j 不为 0，那么令 j&#x3D;n[j-1], 继续进行匹配\n直到 j 等于 m 的长度减 1，说明完全匹配，此时 i-j 即为模式串的一个起始点\n如果需要找出全部匹配点位，那么将 j 归零继续寻找这里最为魔法的地方就在于第三步，这是什么诡异的操作？仔细想想，我们是在第 j 位发现不同的，这意味着其实文本串中的第 i-j 位到第 i-1 位与模式串中的第 0 位到第 j-1 位相同，那么如果 n[j-1]的值为 a，就一定有文本串的第 i-a 位到第 i-1 位与模式串的第 0 位到第 a-1 位相同，既然如此，我们直接从模式串的第 a 位与文本串的第 i 位开始继续比较。这个过程很好的利用了之前获取到的信息来进行比较。\n\n有了上面的信息，你是否能够想出一个办法来创建一个模式串的部分匹配表？提示，创建部分匹配表的方法和上面匹配的过程非常像，我这里简单的写一个 java 版本的，你可以思考完后再看\npublic class KMP &#123;      String s; //s是文本串     String p;  //p是模式串    int[] next;  //习惯上将部分匹配表称为next    public kmp(String s, String p)&#123;          this.s = s;          this.p = p;          next = new int[p.length()];          getNext();      &#125;      private void getNext() &#123;          int j = 0;          next[0] = 0;          for (int i = 1; i &lt; p.length(); i++) &#123;              while (j &gt; 0 &amp;&amp; p.charAt(j) != p.charAt(i))&#123;                  j = next[j - 1];              &#125;              if (p.charAt(j) == p.charAt(i))&#123;                  j++;              &#125;              next[i] = j;          &#125;      &#125;      public int kmp()&#123;          int i = 0;          int j = 0;          while(i &lt; s.length() &amp;&amp; j &lt; p.length())&#123;              if(j == -1 || s.charAt(i) == p.charAt(j))&#123;                  i++;                  j++;              &#125;else&#123;                  j = next[j-1];              &#125;          &#125;          if(j == p.length())&#123;              return i-j;          &#125;          else&#123;              return -1;          &#125;      &#125;  &#125;\n有上面的基础，我相信 kmp 方法看懂一定不是什么问题，那么部分匹配表的生成过程呢，你真的明白了吗？我们可以这样理解。\n\n第一轮循环中如果 p[0]&#x3D;p[1]那么 next[1]&#x3D;1 否则 next[1]&#x3D;0，这一步很好理解，只有 aa，bb 这一类首两个字符完全相同的情况下才能保证前缀与后缀存在相同项\n第二轮中 i 变成了 2，如果第 j 位和第 2 位相同，此时相当于第 1 位和第 2 位相同，也就是说字符串类似于 aaa，三个字符完全相同，此时最大公共前后缀长度一定为 2；如果第 j 位和第 2 位不相同进入 while 循环，令j &#x3D; next[j - 1]再次比较，这同样借用了前面获得的信息，如果next[j - 1]&#x3D;a，那么第 0 到第 a-1 位这一前缀与第 i-a 到第 i-1 位是相同的，比较第 a 位与第 i 位即可\n如果第 a 位与第 i 位相同，那么第 0 位到第 i 位这一子串的最大公共前后缀长度一定为 a+1, 也就是 j++。而如果不相同，我们站在当前位置考虑，再次令j &#x3D; next[j - 1]，就有了和第二步中基本相同的考虑。而在极端情况下，j 最终等于 0，也会退出 while 循环\n\n不过如果你去网上搜索一下 kmp 算法的模板，一般的解法类似下面 (我随便找的)\nclass Solution &#123;    public void getNext(int[] next, String s)&#123;        int j = -1;        next[0] = j;        for (int i = 1; i &lt; s.length(); i++)&#123;            while(j &gt;= 0 &amp;&amp; s.charAt(i) != s.charAt(j+1))&#123;                j=next[j];            &#125;            if(s.charAt(i) == s.charAt(j+1))&#123;                j++;            &#125;            next[i] = j;        &#125;    &#125;    public int strStr(String haystack, String needle) &#123;        if(needle.length()==0)&#123;            return 0;        &#125;        int[] next = new int[needle.length()];        getNext(next, needle);        int j = -1;        for(int i = 0; i &lt; haystack.length(); i++)&#123;            while(j&gt;=0 &amp;&amp; haystack.charAt(i) != needle.charAt(j+1))&#123;                j = next[j];            &#125;            if(haystack.charAt(i) == needle.charAt(j+1))&#123;                j++;            &#125;            if(j == needle.length()-1)&#123;                return (i-needle.length()+1);            &#125;        &#125;        return -1;    &#125;&#125;\n上面的解法简单的理解是相当于做了一个变量代换，将我给出的代码中的 j 减去 1 然后视为新的 j，你只要将这个模板中的 j 替换为 j-1 就可以再次得到我给出的版本。\n最后我给出力扣的对应题目连接，你可以尝试一下（这玩意直接暴力算法也能过不过最好自己尝试着写一遍 KMP）：https://leetcode.cn/problems/find-the-index-of-the-first-occurrence-in-a-string/description/\n\n又发现一道题可以帮助理解 KMP 算法，所以我贴在这里，可以先看看https://leetcode.cn/problems/repeated-substring-pattern/\n这道题要求的是判断一个字符串是否是由某个子串重复 n 次产生的，同样，这道题我们可以直接暴力计算，直接使用两个循环逐次对比，但对于这类问题，我们可以选择直接使用 KMP 来快速求解，我先贴一段我写的版本\nbool repeatedSubstringPattern(char* s) &#123;      int len = strlen(s);      int i=0;      int j=1;      int next[len];      next[0]=0;      while(j&lt;len) &#123;//先把部分匹配表搞出来          if (s[i]==s[j]) &#123;              next[j]=i+1;              j++;              i++;          &#125;else &#123;              if (i&gt;0) &#123;                  i=next[i-1];              &#125;else &#123;                  next[j]=0;                  j++;              &#125;          &#125;      &#125;        if (next[len-1]==0) &#123;//只要是重复产生的，那么这个字符串一定存在相同的非空前后缀          return false;      &#125;      int sublen = len-next[len-1];//字符串长度减去当前串的最大公共前后缀长度    if (len%sublen==0) &#123;//如果len是sublen的倍数，那么一定是重复产生的        return true;      &#125;      return false;    &#125;\n\n那么问题来了，为什么上面只要 len 是 sunlen 的倍数就一定是重复产生的呢，我们假设一个字符串是由某个子串重复产生的，我们设这个子串为 a，那么我们假设：\n最长前缀：a a a a字符串：  a a a a a最长后缀：  a a a a\n我们可以直观的看到此时的 sublen 就是最小子串 a，这很好理解，如果一个字符串是由某个子串重复 n 次产生的，那么其最大前后缀必然为该子串重复 n-1 次产生；反之，\n\n","tags":["算法笔记"]},{"title":"NIO体系","url":"/posts/81499a4c/","content":"理论上来说下一步应该是实现一些SpringWeb中的相关功能了，比如基本的HTTP通信实现，但是要实现Spring中的效果需要用Java的异步IO体系，这一部分比较复杂，且网上我也没找到太多比较好的资料，所以就有了这一篇，我们专门来讨论一下NIO体系的相关知识\n缓冲区相信大家都使用过BufferedReader等带缓冲的输入输出流，这些自带缓冲区的输入输出流主要被用于在数据量比较大的时候的数据输入输出，这些流都在java.io包下，但这些不是我们今天真正要介绍的内容下。在java.nio包下还有一套单独实现的缓冲机制，所有缓冲类从一个叫做Buffer的类开始，下面是这个类的一些基础内容\npublic abstract sealed class Buffer permits ByteBuffer, CharBuffer, DoubleBuffer, FloatBuffer, IntBuffer, LongBuffer, ShortBuffer &#123;//sealed是jdk17的新特性，称为密封类，及只允许permits后的类继承    static final Unsafe UNSAFE = Unsafe.getUnsafe();//unsafe类提供了直接的内存操作能力    static final ScopedMemoryAccess SCOPED_MEMORY_ACCESS = ScopedMemoryAccess.getScopedMemoryAccess();    //内存范围      static final int SPLITERATOR_CHARACTERISTICS = 16464;      private int mark = -1;      private int position = 0;      private int limit;      private final int capacity;      long address;      final MemorySegment segment;      &#125;\n我们最好还是实际操作一下创建一个缓冲区来看看到底是怎么操作的，这个类是个抽象类，我们选择这个类的一个子类 intbuffer 来创建一个子类吧。大概的流程如下\npublic class Main &#123;    public static void main(String[] args) &#123;        IntBuffer intBuffer = IntBuffer.allocate(10);//直接申请一个大小为10的缓存        int[] ints = new int[10];        IntBuffer intBuffer2 = IntBuffer.wrap(ints);//将这个数组放到缓存中    &#125;&#125;\n我们接下来可以看看发生了什么\npublic static IntBuffer allocate(int capacity) &#123;    if (capacity &lt; 0) &#123;        throw createCapacityException(capacity);    &#125; else &#123;        return new HeapIntBuffer(capacity, capacity, (MemorySegment)null);//如果容量大于等0，创建一个堆int缓存    &#125;&#125;\n然后追踪几层找到实际的构造方法这个构造方法长这样\nHeapIntBuffer(int cap, int lim, MemorySegment segment) &#123;      super(-1, 0, lim, cap, new int[cap], 0, segment);      this.address = ARRAY_BASE_OFFSET;  &#125;\n然后继续往下找 super 方法就可以发现下面这个\nIntBuffer(int mark, int pos, int lim, int cap, int[] hb, int offset, MemorySegment segment) &#123;      super(mark, pos, lim, cap, segment);      this.hb = hb;      this.offset = offset;  &#125;//这里其实就体现出来了，实际上这个类也是在使用数组在存储int，就存在hb中\n接着看 super 就是下面这个\nBuffer(int mark, int pos, int lim, int cap, MemorySegment segment) &#123;        if (cap &lt; 0) &#123;            throw createCapacityException(cap);        &#125; else &#123;            this.capacity = cap;            this.segment = segment;            this.limit(lim);            this.position(pos);            if (mark &gt;= 0) &#123;                if (mark &gt; pos) &#123;                    throw new IllegalArgumentException(&quot;mark &gt; position: (&quot; + mark + &quot; &gt; &quot; + pos + &quot;)&quot;);                &#125;                this.mark = mark;            &#125;        &#125;    &#125;\n\n这里存在四个量：mark, position, limit, capacity。这四个量分别代表标记位置，实际位置，最大位置，数组容量。标记位置用于标记特定的位置实现跳转读取，所以初始状态为-1 即表示没有标记，实际位置就是数组的 index，最大位置为允许实际位置的最大值，数组容量是数组的实际容量。此外还有一个 offset 是操作的偏移量\n常见操作接下来我们看几个比较常见的操作，首先是写操作，主要使用 put 方法，实现如下\n//ix用来确定偏移量protected int ix(int i) &#123;    return i + this.offset;&#125;//获取下一个位置final int nextPutIndex() &#123;    int p = this.position;    if (p &gt;= this.limit) &#123;        throw new BufferOverflowException();    &#125; else &#123;        this.position = p + 1;        return p;    &#125;&#125;public IntBuffer put(int x) &#123;      this.hb[this.ix(this.nextPutIndex())] = x;      return this;  &#125;    public IntBuffer put(int i, int x) &#123;      this.hb[this.ix(this.checkIndex(i))] = x;      return this;  &#125;\n\n然后还包括两个针对数组和缓冲区的 put 方法我就不展示了，接下来看一眼获取的 get 方法\n//nextGetIndex和put中的nextPutIndex实现是相同的public int get() &#123;      return this.hb[this.ix(this.nextGetIndex())];  &#125;    public int get(int i) &#123;      return this.hb[this.ix(this.checkIndex(i))];  &#125;    public IntBuffer get(int[] dst, int offset, int length) &#123;      this.checkSession();//无需在意的合法性检查      Objects.checkFromIndexSize(offset, length, dst.length);      int pos = this.position();      if (length &gt; this.limit() - pos) &#123;          throw new BufferUnderflowException();      &#125; else &#123;          System.arraycopy(this.hb, this.ix(pos), dst, offset, length);        //从当前的position开始复制          this.position(pos + length);          return this;      &#125;  &#125;\n然后是 mark 和 reset 方法\npublic Buffer mark() &#123;      this.mark = this.position;      return this;  &#125;//将当前位置标记    public Buffer reset() &#123;      int m = this.mark;      if (m &lt; 0) &#123;          throw new InvalidMarkException();      &#125; else &#123;          this.position = m;          return this;      &#125;  &#125;//位置指针跳转到mark处\n缓冲区的基本操作就了解到这里，内部的其余方法有兴趣的可以自己看看，但个人觉得也没什么必要，用得着的时候查就对了，这不是我们今天的重点，我们来看看下个部分\n直接缓冲区我们之前的缓冲占用的是 jvm 的堆内存，本质上就是几个数组，那么我们是否可以申请一些对外内存来使用呢，当然可以，我们可以选择使用下面的这个方法来实现\npublic static void main(String[] args) &#123; //这里我们申请一个直接缓冲区    ByteBuffer buffer = ByteBuffer.allocateDirect(10); //使用方式基本和之前是一样的    buffer.put((byte) 66);    buffer.flip();//这个方法将缓冲区翻转，简单理解就是将指针移动的方向反向   System.out.println(buffer.get()); &#125;\n这个缓冲区在使用上与堆缓冲的使用是一致的，但差别在于这个缓冲区直接通过系统的 IO 实现，理论上会比堆缓冲快一点\n通道类与选择器那么缓冲类有什么用，有这功夫我不如直接使用一个 List，还更方便一些。事实上这些类是专门用于适配通道类的。通道类包括文件通道和网络通道，是 NIO 机制的实现。所有的通道类都继承自 Channel 类。这些通道类有什么作用呢？我们以网络通信为例来做一个比较，在没有 NIO 机制的情况下如果我们要实现一个网络通信，我们可以这么写：\npublic static void main(String[] args) &#123;      try &#123;          Executor executor = Executors.newFixedThreadPool(12);          ServerSocket serverSocket = new ServerSocket(8080);          BlockingDeque&lt;Socket&gt; sockets = new LinkedBlockingDeque&lt;&gt;();          executor.execute(() -&gt; &#123;              while(true)&#123;                  try &#123;                      Socket socket =serverSocket.accept();                      sockets.add(socket);                  &#125; catch (IOException e) &#123;                      throw new RuntimeException(e);                  &#125;              &#125;          &#125;);          while(true)&#123;              Socket socket = sockets.poll();              executor.execute(() -&gt; &#123;                  try &#123;                      while(true)&#123;                          BufferedReader bufferedReader =new BufferedReader(new InputStreamReader(socket.getInputStream()));                        //在这里如果读不到信息回阻塞到有信息为止                          String s = bufferedReader.readLine();                          BufferedWriter bufferedWriter =new BufferedWriter(new OutputStreamWriter(socket.getOutputStream()));                          bufferedWriter.write(s);                          bufferedWriter.flush();                      &#125;                  &#125; catch (IOException e) &#123;                      throw new RuntimeException(e);                  &#125;              &#125;)                        &#125;      &#125; catch (IOException e) &#123;          throw new RuntimeException(e);      &#125;  &#125;\n\n这么搞在人数比较少的前提下当然没什么问题，但如果同时连接的客户端足够多，那么每个连接都需要消耗一个线程，而如你所见，我们只给这个程序分配了 12 个线程，也就是说最大处理 12 个连接，这怎么够呢？有没有什么办法可以解决这个问题呢？当然有，我们可以通过异步 IO 来解决这个问题，像下面这样\npublic class Main &#123;      public static void main(String[] args) &#123;          try &#123;              ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();            //选用通道版本ServerSocket             serverSocketChannel.bind(new InetSocketAddress(&quot;127.0.0.1&quot;, 8888));              //绑定端口            Selector selector = Selector.open();//创建一个选择器              serverSocketChannel.configureBlocking(false);            //默认状态下通道版本的Socket同样会在调用acept方法时阻塞直到有连接加入，我们这里手动配置为非阻塞            serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);              //将这个通道注册到刚刚的选择器中，并要求选择器监听接受事件            ExecutorService executor = Executors.newFixedThreadPool(12);              while (true) &#123;                  Set&lt;SelectionKey&gt; selectionKeys = selector.selectedKeys();                  Iterator&lt;SelectionKey&gt; iterator = selectionKeys.iterator();                //从选择器中获得所有的事件并创造一个迭代器                  while (iterator.hasNext()) &#123;                      SelectionKey key = iterator.next();                      if (key.isAcceptable()) &#123;  //对于一个接受事件，放到线程池中要求线程池创建对应的Socket通道                        executor.execute(() -&gt; &#123;                              try &#123;                                  SocketChannel socketChannel = serverSocketChannel.accept();                                  socketChannel.configureBlocking(false);                                  //既然这也是一个通道那么自然也可以注册到选择器中，这次我们监听可读事件                                socketChannel.register(selector, SelectionKey.OP_READ);                              &#125; catch (IOException e) &#123;                                  throw new RuntimeException(e);                              &#125;                          &#125;);                        &#125; else if (key.isReadable()) &#123;                          executor.execute(() -&gt; &#123;                         //如果出现了可读事件，那么就执行对应的信心处理操作                            ByteBuffer byteBuffer = ByteBuffer.allocate(1024);                              SocketChannel socketChannel = (SocketChannel) key.channel();                              try &#123;                                  socketChannel.read(byteBuffer);                                  byteBuffer.flip();                                  String message = new String(byteBuffer.array());                                  System.out.println(message);                                  String message2 = &quot;收到信息&quot;+message;                                  socketChannel.write(ByteBuffer.wrap(message2.getBytes()));                              &#125; catch (IOException e) &#123;                                  throw new RuntimeException(e);                              &#125;                          &#125;);                        &#125;                    //最后记得将处理过的事件移除                      iterator.remove();                  &#125;                &#125;            &#125; catch (IOException e) &#123;              throw new RuntimeException(e);          &#125;      &#125;  &#125;\n不知道你能否理解这种写法的好处，在这种写法中，没有一个线程会陷入阻塞去等待客户端的消息，每个线程都是去处理一个已经存在的确定可行的事件，单个线程可以处理多个来自不同连接的消息。这就是我们所说的异步 IO 机制。首先解释一下上面的一些内容，通道的事件可以分为四种\n\nconnect 连接事件，说明与对应的资源建立起了连接，这种连接可以是网络连接也可以是与文件资源的连接\naccept 接受事件，监听到了对应的连接需求，可以与对应的资源建立连接\nread 读就绪事件，有内容可以从通道中读取\nwrite 写就绪事件，可以向通道中写入内容，这个事件在没有锁时一般是一直允许的当然，并不是所有的通道都实现了这四种事件，有些通道只支持部分事件。当我们将通道与对应的事件注册到选择器中时，选择器就会监听并记录对应通道的对应事件。通过这种方法，我们可以很好的避免单个线程陷入无意义的阻塞。大大提高单个线程的利用率。那么你可以猜猜选择器到底是怎样工作的？最简单的方法其实是选择器在每次被询问有哪些事件时通过对所有通道进行轮询，如果存在对应的事件则进行记录，但是显然这种机制在通道数足够多的状态下每次轮询都要消耗大量的时间，这完全不可接受，那该怎么办？聪明人们想到了一种办法：事件驱动机制\n\n什么是事件驱动机制？简单来说事件驱动就是通过对对应的事件增添一个回调处理器，这个回调处理器中的操作会在事件发生时执行，而只要在回调处理器的操作中添加通知选择器的操作即可。回调处理器的操作由事件发生所驱动，这样选择器就无需主动询问不同的通道而是被动的接收事件发生的信息，那么无论存在多少个通道，时间复杂度永远是 O (1);\nJava 中选择器的监听\n结语NIO 机制我们暂时先介绍到这里，你可以试着去改进一下上面的代码，重点有三个：\n\n如果连接数特别大一个线程作为监听线程显然不够，尝试着支持多个监听线程\n如果一个连接在客户端被断开，那么上面的代码是没法发现的，还会保留原有的通道，想办法改进（提示：通道的 read 方法会返回读取到的字节数，如果连接断开返回-1）\n我们不可能真的只对客户端的信息做如此简单的处理，想办法创建将上面的流程拆分成几个类，降低耦合度，然后要支持在 excute 方法中放入任意的 Runnable 类\n\n下一篇我们正式的去研究一下 SpringWeb 中的网络机制\n","tags":["手写Spring"]},{"title":"互联网结构与网络通信协议","url":"/posts/4ee2495d/","content":"这一篇我们从互联网的结构开始梳理一下网络世界的通信到底是怎样实现的。\n网络模型我们首先从 OSI 模型讲起，在这个模型中互联网的结构被分成了七层：\n\n应用层（Application Layer）\n\n功能：直接与最终用户交互，为应用程序提供网络服务。\n常见协议：HTTP, FTP, SMTP, SNMP, DNS, Telnet。\n\n  我们常见的各种应用程序，都是工作在应用层\n  \n\n表示层（Presentation Layer）\n\n功能：数据格式化，转换，和数据加密，确保数据能被应用层正确读取和理解。\n常见功能：数据压缩、加密与解密、数据格式转换。\n\n\n会话层（Session Layer）\n\n功能：负责建立、管理和终止会话（通信连接）。\n常见功能：会话管理、全双工、半双工、和单工操作模式、会话检查点和恢复功能。\n\n\n传输层（Transport Layer）\n\n功能：提供端到端的通信控制，确保数据可靠传输。\n常见协议：TCP, UDP。\n常见功能：流量控制、错误检测与纠正、数据重传。\n\n  传输层也是我们需要重要学习的内容\n  \n\n网络层（Network Layer）\n\n功能：负责路由和转发数据包，处理逻辑地址（如IP地址）。\n常见协议：IP, ICMP, ARP, RARP。\n常见设备：路由器。\n\n\n数据链路层（Data Link Layer）\n\n功能：提供节点到节点间的传输，处理物理寻址（MAC地址）、错误检测和纠正。\n常见协议：Ethernet, PPP, HDLC。\n常见设备：交换机，网桥。\n\n\n物理层（Physical Layer）\n\n功能：定义了物理设备的电气和物理规范，如线缆类型，连接器，频率等。\n常见标准：RJ45, Ethernet，光纤标准。\n\n\n\n一般情况下，对于一次网络通信，信息的流向一般是从上到下的，先由应用层产生对应的数据，然后不断向下包装, 最终经过物理层被传输到其他的计算机中。在接收数据的一侧，又从物理层开始依次向下解包，最终获得想要的数据。这一套模型是公认的国际标准，但是不知道你是否认为这一套模型过于复杂，我们在一般情况下并不会真的去考虑这么多，在大多数情况下，我们采用一种更简单的模型：TCP&#x2F;IP 模型，其结构如下\n\n链路层（Link Layer）\n\n作用 ：\n\n数据封装与解封 ：将网络层的 IP 数据报封装成帧，帧是链路层传输的数据单位，它在帧的首部和尾部添加了用于在链路上传输的控制信息。例如，以太网帧的首部包含目的 MAC 地址、源 MAC 地址、类型字段等信息，尾部则有帧校验序列（FCS），用于接收方检测帧在传输过程中是否出现错误。\n\n物理地址寻址 ：负责在网络中的设备之间进行物理地址（MAC 地址）的识别和寻址，确保数据帧能够正确地从一个设备传输到另一个设备。MAC 地址是固化在设备的网卡上的 48 位地址，每个网卡都有一个唯一的 MAC 地址，链路层通过 MAC 地址来确定数据传输的源和目的端 。\n\n链路管理 ：负责建立、维护和管理链路的连接，包括链路的建立过程中的初始化、参数协商等操作，以及在链路出现故障时的检测和恢复处理。例如，在以太网中，链路层协议会检测物理链路的连接状态，如是否插好网线、链路是否正常工作等。\n\n错误检测与纠正 ：链路层提供了一定的错误检测和纠正机制，通过帧校验序列（FCS）等技术，对接收到的帧进行错误检测，如果发现帧有错误，可以要求发送方重新发送该帧，从而保证在链路上传输的数据的正确性。\n\n\n\n\n 网络层（Internet Layer）\n\n作用 ：\n\nIP 寻址与路由选择 ：为网络中的设备提供统一的逻辑地址（IP 地址），使得不同网络中的设备能够相互识别和定位。IP 地址是由一组数字组成的独特标识符，用于标识网络中的每一个设备。网络层的核心功能是根据 IP 地址进行路由选择，即确定数据从发送方到接收方的最优传输路径。路由器是网络层的关键设备，它根据路由表中的信息，将数据包转发到下一个合适的路由器或目标网络。\n\n数据包的分片与重组 ：由于不同网络的链路层帧的最大传输单元（MTU）不同，网络层负责将较大的 IP 数据报分割成较小的片段，以便在 MTU 较小的链路上进行传输。当数据报到达目的地后，再由接收方的网络层将这些片段重新组装成原始的数据报。\n\n无连接的数据传输 ：网络层提供的是无连接的服务，即在数据传输之前不需要建立专门的连接，每个数据包独立地进行传输和路由选择。这意味着每个数据包都可能通过不同的路径到达目的地但，这也增加了网络的灵活性和容错性，因为如果某条路径出现故障，数据包可以自动选择其他可用的路径进行传输。\n\n\n\n\n 传输层（Transport Layer）\n\n作用 ：\n\n端到端的通信 ：建立在进程到进程之间进行数据传输的通道，为应用程序提供端到端的通信服务。进程是操作系统中程序执行的一个实例，传输层通过端口号来标识不同的进程，使得不同的应用程序可以同时在网络上进行通信而互不干扰。\n\n连接管理与可靠传输（TCP） ：TCP 协议在传输层提供了面向连接的、可靠的传输服务。在数据传输之前，需要建立一个 TCP 连接，通过三次握手的过程来建立可靠的通信通道。在连接建立后，TCP 采用确认、重传、排序等机制，确保数据的可靠传输。接收方收到数据后，会发送确认信息给发送方，如果发送方在一定时间内未收到确认信息，则会重发相应数据。同时，TCP 还可以对收到的乱序数据进行排序，保证数据按正确的顺序交付给上层应用程序。\n\n无连接的快速传输（UDP） ：UDP 协议提供的是面向无连接的、不可靠的传输服务。UDP 不需要在传输前建立连接，数据直接以数据报的形式发送，因此它的传输延迟相对较低，适用于对实时性要求较高但对数据丢失不太敏感的应用场景，如音频、视频流媒体等。但由于 UDP 不提供可靠传输机制，数据可能会出现丢失、重复或乱序的情况。\n\n\n\n\n 应用层（Application Layer）\n\n作用 ：\n\n应用程序接口（API） ：为各种网络应用程序提供了编程接口和协议支持，使得应用程序能够方便地使用网络服务。例如，HTTP 协议为网页浏览应用提供了访问和传输网页内容的接口；FTP 协议为文件传输应用提供了上传、下载文件的功能；DNS 协议为域名解析应用提供了将域名转换为 IP 地址的服务等。\n\n网络服务提供 ：应用层包含了各种常见的网络服务协议，如文件传输、电子邮件、远程登录、域名解析、网络新闻等，为用户提供了丰富的网络应用服务。这些协议规定了应用程序之间进行通信时的格式、规则和过程，使得不同用户的应用程序能够在网络上相互协作和交互，共同完成各种网络应用任务。\n\n\n\n\n\n接下来我们就分别讲讲各层相关的一些比较重要的事情\n链路层在链路层，我们从 MAC 地址或者说物理地址讲起？我们的设备能够实现网络通信是通过我们设备的网卡实现的，而每个网卡再出厂时都会被分配一个全球唯一的 MAC 地址，一般被表示为一个 12 位 16 进制数，例如下面这张就是我当前连接网络的信息MAC 地址通常是局域网范围内不同设备的唯一标识。局域网中通信一般实现是这样的：诸多的设备共同连接在同一台交换机上，交换机会将自己的不同端口与不同的 MAC 地址相互绑定，而设备上也存储了不同设备的 MAC 地址，如果想要和某设备通信就告诉交换机自己想要和某个 MAC 地址对应的端口通信，交换机会将信息传递给对应的端口。\n在局域网特别是比较小的，受信任的局域网内这么搞肯定是没问题的，但如果在大规模的网络内指望通过 MAC 地址实现全网的通信，就会存在不小的问题：\n\nMAC 地址是取决于网卡的，也就是说我完全可以随便编一个假的 MAC 地址来掩盖我的身份或者更进一步我可以把自己包装为别人从而监听他人的信息。\nMAC 地址取决于网卡，而一块网卡可能被卖到全球的任何地点，而且这块网卡的位置是随时可能会发生改变的，也就是说必须存在一台设备在任何时刻都知道某块网卡位于哪里，才能将信息点对点的发送过去为了解决这个问题，人们搞出了 IP 地址这一网络层的地址\n\n网络层相较于链路层，网络层开始脱离实际存在的物理设备，而是更加关注网络拓扑环境。根据网络拓扑环境为不同的设备分配不同的 IP 地址。当前的 IP 协议可分为 IPv4 以及 IPv6，我们先来看看 IPv4 地址的规则IPv4 地址的规则主要体现在以下几个方面：\n\n地址格式\n点分十进制表示法 ：IPv4 地址采用 32 位二进制数表示，为了便于人类阅读和书写，通常将其分为 4 个 8位（1 字节）的段，每段转换为十进制数，段与段之间用点（.）分隔开，这就是所谓的点分十进制表示法。例如，一个典型的 IPv4 地址可能是 192.168.1.1，其中每个十进制数的取值范围为 0 到 255。\n\n地址分类\nA 类地址 ：\n\n范围 ：1.0.0.0 - 126.255.255.255\n\n特点 ：最高为位 0，网络号占 1 个字节（8 位），主机号占 3 个字节（24 位），一个 A 类地址可容纳的主机数量最多，理论上有 2^24-2≈16777214 个主机（减去网络地址和广播地址），但 A 类地址的网络数量相对较少，适用于大型网络。\n\n\n\nB 类地址 ：\n\n范围 ：128.0.0.0 - 191.255.255.255\n\n特点 ：前两位为 10，网络号占 2 个字节（16 位），主机号占 2 个字节（16 位），一个 B 类地址可容纳的主机数量为 2^16-2&#x3D;65534 个，适用于中型规模的网络。\n\n\n\nC 类地址 ：\n\n范围 ：192.0.0.0 - 223.255.255.255\n\n特点 ：前三位为 110，网络号占 3个 字节（24 位），主机号占 1 个字节（8 位），一个 C 类地址可容纳的主机数量为 2^8-2&#x3D;254 个，适合小型网络。\n\n\n\nD 类地址 ：\n\n范围 ：224.0.0.0 - 239.255.255.255\n\n特点 ：前四位为 1110，用于多播（组播）通信，即一个数据包可以同时发送给多个特定的接收者 。\n\n\n\nE 类地址 ：\n\n范围 ：240.0.0.0 - 255.255.255.255\n\n特点 ：前五位为 11110，目前保留用于实验和特殊用途。\n\n\n\n\n特殊地址\n网络地址 ：每个网络的起始地址，网络号部分固定，主机号部分全为 0，用于标识一个网络，不能分配给主机使用。\n\n广播地址 ：每个网络的结束地址，网络号部分固定，主机号部分全为 1，用于向该网络中的所有主机发送广播信息。\n\n回环地址 ：127.0.0.0 - 127.255.255.255，通常用于环回测试，当主机需要向自身发送数据时会使用这个地址，最常用的回环地址是 127.0.0.1。\n\n私有地址 ：也称为专用地址，用于私有网络内部通信，这些地址不会在互联网上被分配给任何组织或个人，包括：\n\nA 类私有地址 ：10.0.0.0 - 10.255.255.255\n\nB 类私有地址 ：172.16.0.0 - 172.31.255.255\n\nC 类私有地址 ：192.168.0.0 - 192.168.255.255\n\n\n\n\n\n我们常说的公网 IP 一般指的就是 IPv4 地址，因为一个 32 位二进制数的最大表示范围大概是 43 亿，或许在创建这套规则的时代这是一个比较大的数字，但是现在我们每个人需要联网的设备有多少，这完全不够用，该怎么解决这个问题呢？如今的办法就是按照上面所说的分配一部分私有地址，这部分地址在局域网内部被分配，局域网中存在一个路由器，这个路由器占据实际的公网地址，在访问互联网时局域网内所有的设备对外来说都在使用路由器的 IP，由路由器将不同的信息转发给不同的设备。（当然，国内现实的情况是一般一个小区只有一个公网 IP，我们家里的路由器也只使用被分配的私网 IP，所有信息由更上层的路由器转发），比如我当前电脑的 IP 就是 192.168 开头，说明是一个私有地址\n然后再讲讲这个 ABCDE 类别划分是什么鬼，对于 A 类地址，在分配时会只规定前 8 位，剩余 24 位不做分配，然后将整个网段交给某个组织使用，而 B 类地址会规定前 16 位，依次类推。我们一般情况下获得的公网IP 地址其实隶属于移动联通电信的 A 类网段\n再来看看这张图当我们连接路由器时一般情况下会通过 DHCP 协议自动分配 IP 地址，完成相应的配置，但同样也支持手动进行配置，我们发现我们需要手动配置 DNS，地址，子网掩码，网关，跃点。这些东西都是什么呢？\n先讲讲 DNS 服务，一般情况下我们不会直接通过 IP 地址访问某个网页，而是通过某个网址，那么我们又如何知道哪个网址对应那个 IP 呢，这就需要 DNS 服务了，DNS 服务器内保存了网址与 IP 地址的对应关系，在向某个网址发送请求时会先向 DNS 服务器发送服务器获得网址对应的 IP 地址，常用的 DNS 服务包括移动联通电信提供的 DNS 服务以及几个知名企业提供的 DNS 服务，比如 Public DNS+的 119.29.29.29，114 DNS 的 114.114.114.114，阿里的 233.5.5.5，当然还有不少，需要的可以自己上网上找找\n接下来是地址，也就是想要给当前设备分配的地址，只要不和别的设备冲突，192.168 后面随便写\n然后是子网掩码，子网掩码其实就是用来分辨网络类型的，比如说 A 类网络的默认子网掩码为 255.0.0.0，转换为二进制就是 11111111 00000000 00000000 00000000，将子网掩码与实际的 IP 地址进行按位与运算可以得到对应的网络号，例如将上面的掩码与 8.8.8.8 进行按位与运算或者说与 00001000 00001000 00001000 00001000 进行按位与运算得到的是 00001000 00000000 00000000 00000000 即 8.0.0.0，说明当前 IP 属于 8.0.0.0 这个网段，进一步的将子网掩码先按位取反再与 IP 地址进行按位与操作得到的就是当前 IP 在网段内的编号。一般情况下，A 类网络的子网掩码为 255.0.0.0，B 类位 255.255.0.0，C 类为 255.255.255.0 但这不是固定的，有些时候我们希望将一个 B 类网划分为多个 C 类网，那么久选择 255.255.255.0 作为子网掩码，或者要将网络按照特定的数量划分，我们也可以按照上面的逻辑编写更复杂的子网掩码。此外，有些时候子网掩码与 IP 地址会被合并在一起书写为 192.168.5.6&#x2F;24 的形式\n接着是网关，也就是我们的路由器的 IP，一般是当前网段的 1 号。\n最后是跃点，这个值一般情况下不用设置，在数据包的传输过程中每经过一个有路由功能的设备就称之为经过了一个跃点，如果我们设置了跃点，那么所有的数据会被强制先经过设置的跃点。\n那么了解了这些之后，请回答我的一个问题，既然有了 IP，那么 MAC 地址还有存在的必要性吗？答案是当然有，在当今的局域网中，分配私有 IP 的过程正是依赖与 MAC 地址，借助 MAC 地址来实现的，交换机或者路由器必须通过 MAC 地址来识别不同的设备。\n此外，在网络层，我们还应当了解端口的概念，考虑一个问题：我们的设备中有这么多应用在同时运行，这些应用都需要网络连接，那么操作系统在收到一段信息后该如何确定到底这个信息该传递给哪个应用？这就需要使用到端口号了，端口号通常由 16 位二进制数组成，实际范围为 0-65535，所有的信心在发送时都会被表明向对应 IP 的哪个端口发送，不同的应用占据不同的端口，操作系统只需要将收到的信息传递给与对应端口绑定的应用即可。一般情况下，有些端口被固定的服务占用，不推荐使用，比如 HTTP 占用 80 端口，HTTPS 占用 443 端口，ssh 服务占用 22 端口。如果我们想使用，除了创建一些约定成俗的服务，比如 MySQL 走 3306 端口，Tomcat 占 8080 端口，一般情况下都选择一些过万的端口，不怎么会被占用\n在了解了一些基本的网络概念后我们来到传输层\n传输层传输层最为重要的就是两个协议，TCP 协议与 UDP 协议，这两个协议支撑起了当今整个互联网的主要通信。我们今天会尽可能详细的讲一讲这两个协议。先从比较简单的 UDP 协议开始吧。\nUDP 协议UDP 全称 User Datagram Protocol 用户数据报协议，一种典型的无连接协议，当下通常被用于直播，视频电话等对实时性要求比较高且可以接受一定程度的数据损失的方式。这种协议在放弃了一定的安全性的基础上实现了低成本高速率的网络通信方式，其报文的结构大概长这样也就是说一个标准的 UDP 报文包括 8 字节的头部和一个不定长的有效载荷。通常情况下头部包含下面这些内容\n\n源端口（16 位） ：\n\n这是用来标识发送进程的端口号。端口号的作用是区分不同的应用程序进程。例如，一个计算机上可能同时运行着多个使用 UDP 协议的程序（如一个下载软件和一个即时通讯工具），源端口就可以区分数据是从哪个进程发出的。当接收方收到数据后，可以根据源端口将响应数据返回给正确的进程。\n\n\n目的端口（16 位） ：\n\n该字段用于标识接收进程的端口号。发送方需要知道将数据发送到接收方的哪个应用程序进程，目的端口就起到了这个作用。例如，在网络中的一个服务器上运行着多个服务（如 Web 服务和 FTP 服务），目的口端可以确定数据报应该交给哪个服务来处理。\n\n\n长度（16 位） ：\n\n表示 UDP 报文的长度，包括首部和数据部分的总长度。其最小值为 8 字节（当数据部分为空时，只有 UDP 首部）。这个字段可以让接收方知道整个 UDP 报文的大小，从而正确地读取和处理报文。例如，如果某个 UDP 报文的首部长度为 8 字节，数据部分长度为 1000 字节，那么长度字段的值就是 1008（8 + 1000）。\n\n\n校验和（16 位） ：\n\n用于对 UDP 报文的完整性进行校验。发送方会根据一定的算法对 UDP 报文（包括首部和数据部分）进行计算，得到一个验校和值，然后将其放入校验和字段中。接收方收到报文后，再按照相同的算法计算校验和，如果计算结果和报文中的校验和值不一致，则表明报文在传输过程中可能出现了错误。UDP 中的校验和算法相当简单粗暴，就是将所有数据的值相加得到一个数字，哪怕溢出也无所谓，因为接收方在计算时也会溢出，最终得到相同结果，但这种算法存在多个数据发生改变或换位导致数据本身改变但校验和不收影响的缺陷\n\n\n\n我猜你可能会问一个问题：这里面并没有明确的说明到底该给哪个 IP 地址传，那么 IP 地址是如何被确定的呢？IP 地址被存放在由 IP 协议确定的 IP 数据报中，是由网络层确定的内容。\n现在打包好了数据报，该怎么发送信息呢，直接发！我管你这的那的，反正我直接闭着眼把数据向对应地址发出去就完事了，不管实际有没有收到，有没有出错，极致的不确定换来极致的高效。\n当然，在当下的实现中，如果选择使用 UDP 协议，那么一般会对 UDP 协议进行魔改，在有效载荷中继续添加一些用于校验的机制，并实现在一方收到信息时返回收到信息。尽可能在保留 UDP 协议高效性的同时保证数据的准确性\nTCP 协议接下来讲讲 TCP 协议，TCP 协议即Transmission Control Protocol，传输控制协议，相较于 UDP 协议，TCP 协议添加了大量的措施来保证数据传输的完整性与准确性。我们的 Socket 体系就是基于 TCP 构建的\n我们先来看看 TCP 协议的头部内容与 UDP 协议相比，TCP 协议的头部就复杂了许多，我们来解释一下\n\n序列号：表示所发送数据载荷的第一个字节的编号，例如总计要发送 300 字节的内容，考虑到网络情况，将内容分 0 到 99，100 到 199，200 到 299 三部分发送，那么三次的序列号分别为 0，100，200.\n确认号：表示期望接收到的数据的编号起始，例如接收方收到了 0 到 99 的数据，那么确认号就是 100\n首部长度：由于总体上 TCP 头部长度可变，所以保留四位用于表示首部数据的长度\n保留：保留数据位，用于将来可能得功能\n标志位（6 位）：- URG（紧急指针）：此位置为 1 表示当前包中有紧急数据，优先处理此包中的数据- ACK（确认）：当 ACK 为 1 是确认号才有效，用于告知发送方已经正确的接受数据- PSH（推送）：此位置为 1 时表示应当尽快将包中数据交给应用层，而不用等待缓冲区满后再传递- RST（复位）：此位置为 1 表示将连接复位，当出现严重错误时添加此标识可强制关闭连接- SYN（同步）：用于建立连接，在建立连接阶段 SYN 位会被设置为 1- FIN（结束）：用于结束连接，在关闭连接阶段 FIN 位会被设置为 1\n窗口大小：用于接收方向发送发告知本方最大的缓冲大小，避免发送方发送过量数据造成接收方溢出或不能正确接受数据\n校验和：通过特定算法得出的特定数字串，用于校验数据是否发生了损坏\n紧急指针：只有当标志位的 URG 为 1 时才有效，表示数据中紧急数据接收的位置\n选项字段：这部分不定长，由通信双方约定，内部可以放置一些约定的内容\n\n怎么样，TCP 的头部是不是复杂了很多，但这还远远不够，我们上面提到 UDP 发送数据时直接向目标 IP 发送，不管对方是否实际接受到了数据，是一种无连接的通信协议。而 TCP 协议是一种面向连接的协议，我们首先来看看建立连接的过程\nTCP 建立连接的流程被称为三次握手，具体机制图如下：\n\n客户端向服务器发送一个 TCP 包要求开启连接，此时 SYN 位被设置为 1，序列号为一个一个随机数 A\n服务器向客户端发送一个 TCP 包表示接收到连接请求，此包中 SYN 与 ACK 位被设置为 1 ，确认码被设置为 A+1，同时服务端产生一个随机数 B 作为序列号\n客户端向服务器发送一个 TCP 包表示接收到连接确认，此包中 ACK 位被设置为 1，序列号为 A+1，确认号位 B+1\n\n 考虑一下为什么要这样设计，如果只执行第一步就开始发送数据，无法确定服务器能否收到客户端数据，如果执行前两步，服务器无法确定客户端能否正确接收服务器的数据。三步全部完成且标志位正确，序列号与确认号符合预期说明当前连接相对可靠，可以进行通信\n接下来是数据发送的过程，大概如下：\n建立连接后双方中的任何一方都可以发送数据与接受数据，只需要恰当的变动己方的序列号与确认号就可以保证数据的有序。为了简化情况，我们上图中以只有一方发送数据为例：\n第一次通信发送方发送了 1460 字节数据，序列号为 1，在收到信息后接收方回返回一个数据包，确认号为 1461，表示前面的 1460 字节数据已收到，要求可能存在的 1461 号字节\n第二次发送方又发送了 1460 字节的数据，但注意此时出于某种意外接收方没有返回正确的序列号为 1 确认号为 2921 的包\n第三次发送方发送的数据出于某种意外没有传递给接收方，发送方不知道这件事，但继续按照计划发送数据\n第四次发送了从 4381 到 5840 的数据，但直到此时接收方仍然没有回信\n第五次发送了从 5841 到结束的数据，在完成此次发送后接收方终于回信表示收到了第二次发送的 1461 到 2920 的数据，就像图中那样，即使接收方收到了第五段数据，但第二段到第四段直接不连续，此时回信中只会表示自己收到了前两段，要求发送第三段\n已发送方的视角看，从 2921 开始的 1460 字节的数据接收方始终没有收到，在等待一定的时间后发送方会重发对应的数据包，在上图的最后，接收方表示收到了截止 7300 的数据，发送方也得到信息，对方完成了所有数据的接受，不再重复发送数据\n上图中还有一种情况没有展示：接收方正确接受到了全部数据，但表示第三段数据正确接受的包中途丢了，表示第五段数据正确接受的包还没有到达，此时发送方会再发送一次第三段数据，当接受方收到后，接收方可以通过序列号判断出这事重复的包，然后将其丢弃\n当然，数据的重传是有一个对应的次数限制的，在超过一定的次数后仍然没有回话就会发送 RST 包强行终止连接\n还有一点需要指出：我上面的图展示的过程中总是一次发送一次接受一一对应，实际的情况是会连续的发送几个 ACK 包，每个包对应一个计时器，如果在限定时间范围内还没有得到对应的回应就进行重传。\n当一个连接中一方没有数据发送需求且连续一定时间（一般是两个小时）后没有收到对方信息时，会触发保活机制，会向对方发送包活探测报文，通常是一个空的 ACK 包，如果对方一定时间（一般为 75 秒）没有回应则再次重复，反复一定次数（一般为 8 次）后发送 RST 复位包，强行终端通信\n当然，双方也可以选择主动中断连接，这一机制被称为四次挥手\n\n客户端向服务端发送一个 FIN 标志位为 1 的包，表示数据传输完成，但此时客户端还保留着发送与接收数据的能力，对于超时的包仍然会重发，也可以正确的接受服务器的 ACK 包，但从此客户端不会发送新的数据，只会重发超时包\n在收到客户端的 FIN 包后，服务器将回应一个 ACK 包，确认号为 FIN 包序列号加一，但这里只表示服务器收到了停止连接的请求，服务器还可能有数据没有发送完\n在服务器发送 FIN 包之前，双方的通信仍然是正常的，服务器还可以继续向客户端发送数据，客户端也能正确回应，在服务器完成数据发送后也会发送一个 FIN 包，表示己方数据发送完成，此时服务器的超时重发等能力仍然被保留\n客户端收到 FIN 包后返回一个确认号为 FIN 包序列号加一的 ACK 包表示完成了对服务器所有的数据的接受，可以终止连接\n接收到客户端的 ACK 包后服务器会立刻终止连接，释放相关资源，而客户端会等待一段时间后才真正释放相关资源停止连接为什么客户端需要等待一段时间再停止呢，这是因为如果服务器在回应了 ACK 而没有回应 FIN 期间又发送了一些数据，由于网络原因，这些数据在 FIN 之后抵达，如果连接已经终止，这些数据将被丢失，需要等待一定的时间来保证没有类似的情况发生。此外，还有这样的可能，客户端向服务器发送的最后一个 ACK 丢失了，那么服务器会认为是自己的 FIN 包丢失了，会尝试再次重发 FIN 包，此时如果客户端还没有关闭还可以帮服务器处理这种异常。\n\n到此 TCP 协议的基本机制讲解完成，或许你会认为上面不少情况都考虑的太过极端，但实际上某些情况下出错几率远大于我们的想象，有时网络供应商为了降低负载，是会主动丢包的，所以我们必须尽可能的考虑所有情况。\n应用层 讲完了传输层，我们接下来聊一聊关于应用层的东西，应用层我们主要看一看当下使用最广泛的 HTTP 协议。\nHTTP 协议，即超文本传输协议，是当今互联网世界使用最为广泛的协议，出于稳定性的考虑，HTTP 协议是基于 TCP 协议实现的。在 HTTP 刚被使用时，每个请求都会创建一个 TCP 连接，这无疑添加了许多不必要的消耗，所以从 HTTP&#x2F;1.1 开始 HTTP 协议默认采用持久连接，一般在初次访问某个网站时建立连接，在关闭该网站的全部页面时再由浏览器主动将连接关闭。\n当我们尝试打开某个网站时浏览器会自动尝试生产对应的请求，这个请求一般基于我们输入的 URL 生成，比如说下面这个https://soulmate.org.cn/archives/关于什么是 URL，我们先要从 URI（Uniform Resource Identifiers）讲起，URI，译作统一资源标识符，是 HTTP 协议中用来定义某种资源的位置的数据，而 URL（Uniform Resource Locator）统一资源定位符是一种特殊的 URI，包含了访问一个资源所需要的全部信息，以下面这个我随便编的 URL 为例\nhttp://example.co:6543/abc.jpeg?id=12&amp;name=asd#section1\n这个 URL 中包含以下信息：\n\nhttp: 表示当前使用的是 http 协议，可用的协议还包括 https，ftp 等，后面跟一个无含义的分隔符&#x2F;&#x2F;\n域名部分，即上面的 example.co，这里的域名将通过 DNS 解析服务被替换为实际的 IP 地址，当然我们也可以直接写 IP 地址\n端口部分，即：6543，表示这里使用 6543 端口，这部分大部分时候都会被省略，所有的 HTTP 服务默认采用 80 端口，HTTPS 服务采用 443 端口，浏览器会自动补全\n虚拟地址部分，即&#x2F;abc.jpeg，我们访问的每个页面实际上都对应服务器的某些资源，所以我们需要具体的声明这些资源到底在哪里，例如上面我们就是在访问&#x2F;abc.jpeg 这一资源\n查询部分, ?Id&#x3D;12&amp;name&#x3D;asd 这部分相当于携带的查询参数，告诉服务器用户 id 为 12，name 为 asd，以？代表查询参数的开始。用&amp;分割不同的参数。此外查询参数中的空格用+替代，非 ASCII 字符会通过 Base 64 按照字符集编码进行转换\n锚部分，即 # section1, 用于标识页面的具体位置，我们有时候在进入某个页面时不会跳转到某个页面的开头，而是直接跳转到中间部分，锚正是用来确定这一位置的，这同样不是必须的\n\n根据上面这些信息，浏览器会自动生产对应的 HTTP 请求，当然，在某个页面内执行请求时一般是通过前端的 js 脚本实现的请求生成。当然，这个标准不一定需要严格遵守，比如虚拟地址部分我可以选择不去对应资源而去对应功能，例如用&#x2F;login 表示登录功能，然后将查询部分视为登录信息\n我们来看看一下一个比较标准的 HTTP 请求，\nPOST / HTTP1.1Host: www.wrox.comUser-Agent: Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; .NET CLR 2.0.50727; .NET CLR 3.0.04506.648; .NET CLR 3.5.21022)Content-Type: application/x-www-form-urlencodedContent-Length:4 0Connection: Keep-Alivename=Professional%20Ajax&amp;publisher=Wiley\n我们来分析一下能够看出什么信息，\n\n第一部分，即请求行，也就是第一行，说明我们的请求方式为 POST ，接着是一个空格，&#x2F;1.html 表示我们当前的访问路径，HTTP&#x2F;1.1 是我们使用的协议\n\n然后是第二部分，称为请求头，即我们上面的第二到八行，代表了更多约定的信息，如上面的 HOST 表示目标主机，User-Agent 是当前访问网站使用的应用等等，这部分除了常见的，我们也可以自己定义，像塞进去什么都可以\n\n最后是主体, 在请求头之后必须空一行再写比如这里的主体是name&#x3D;Professional%20Ajax&amp;publisher&#x3D;Wiley，即携带的内容为name&#x3D;Professional%20Ajax 与publisher&#x3D;Wiley 两部分你或许会想问请求头中不同的字段分别是什么意思，事实上这些字段都是可以随意定制的，只不过这部分字段我们事先约定好了对应的含义，如果有兴趣完全可以实现我们接下来看看各个不同的请求方法\n\nGET\n\n功能和用途 ：用于向服务器请求指定的资源。它是最常用的 HTTP 请求方法之一，主要目的是获取数据。例如，当你在浏览器的地址栏输入网址访问网页时，浏览器就会向服务器发送一个 GET 请求来获取网页内容。\n特点\n请求参数会附加在 URL 地址后面，以 “?” 作为标记，后面跟着参数列表，参数之间用 “&amp;” 分隔。例如，“https://example.com/page?id=1&amp;name=abc”。这种方式使得参数在 URL 中是可见的，方便调试，但也会导致一些安全问题，如敏感信息可能会被记录在浏览器历史记录或服务器日志中。\nGET 请求通常是幂等的。幂等性是指多次请求对服务器资源的影响是相同的，就像对同一个发起网页多次 GET 请求，不会改变服务器数据，只是获取网页内容。\nGET 请求可以被缓存，这样可以提高访问效率。浏览器在再次访问相同 URL 时，如果资源没有发生变化，可以使用缓存的数据，而不是每次都向服务器发送请求。\n\n\n\n\nPOST\n\n功能和用途 ：向服务器提交数据以创建新的资源。例如，当你在网页表单中填写信息并提交注册信息、登录信息等操作时，通常会使用 POST 请求。服务器会接收这些提交的数据并对其进行处理，如存储到数据库等操作。\n特点\n请求参数放在请求体（body）中，不会显示在 URL 地址栏中，比 GET 请求更安全，适合传递敏感信息。\nPOST 请求是非幂等的，因为每次 POST 请求可能会导致服务器资源的改变，如创建新的用户账号等操作。多次发送相同的 POST 请求可能会产生不同的结果，如多次提交表单可能会导致重复记录。\n与 GET 请求相比，POST 请求可以传输大量的数据。因为 URL 的长度是有限的，而请求体的大小限制相对较大，能够满足向服务器发送较多数据（如文件上传等场景）的需求。\n\n\n\n\nPUT\n\n功能和用途 ：用于向服务器更新指定资源的状态。它类似于 POST，但不同之处在于 PUT 通常是幂等的。例如，如果想要更新服务器上某个已知资源（如更新用户信息），可以使用 PUT 请求。\n特点\nPUT 请求也是将数据放在请求体中发送给服务器。\n由于其幂等性，多次发送相同的 PUT 请求对服务器资源的影响是一致的，这使得在一些需要确保资源状态更新的场景下很有用。例如，在更新一个文档的内容时，即使请求被重复发送，最终文档的内容也会是最后一次请求指定的内容。\n\n\n\n\nDELETE\n\n功能和用途 ：用于请求服务器删除指定的资源。例如，删除服务器上的某个文件或数据库中的某条记录。\n特点\nDELETE 请求通常是幂等的，多次删除同一个资源（如果资源存在）后的结果是一样的，即资源被删除。\n它的操作相对简单，主要是通过 URL 地址指定要删除的资源。\n\n\n\n\nHEAD\n\n功能和用途 ：请求获取与 GET 请求相同的资源，但不要返回资源的主体部分。主要用于获取资源的元信息，如资源的长度、最后修改时间等信息。这有助于客户端在不下载整个资源的情况下，先了解资源的一些基本信息。\n特点\nHEAD 请求和 GET 请求的请求头部分相同，并且服务器在响应 HEAD 请求时也会返回和 GET 相同的响应头信息，只是省略了响应体。\n由于没有响应体数据，HEAD 请求通常比 GET 请求的传输数据量小，响应速度也更快。\n\n\n\n\nOPTIONS\n\n功能和用途 ：用于获取关于服务器通信选项的信息。它可以请求服务器返回关于该资源所支持的 HTTP 方法等信息。例如，客户端可以使用 OPTIONS 请求来确定服务器是否允许使用 PUT 方法来更新某个资源。\n特点\nOPTIONS 请求可以对整个服务器或特定的资源进行询问。\n服务器的响应会包含一个 “Allow -” 首部字段，其中列出了该资源所支持的 HTTP 方法。\n\n\n\n\nPATCH\n\n功能和用途 ：用于对资源进行部分修改。与 PUT 不同，PUT 通常是整体替换资源，而 PATCH 是对资源进行部分更新。例如，如果只需要更改用户资料中的某个字段（如用户的邮箱地址），可以使用 PATCH 请求。\n特点\nPATCH 请求是非幂等的，因为多次发送相同的 PATCH 请求可能会导致不同的结果。例如，对某个资源进行两次相同的部分更新，可能使资源的状态进一步改变。\n\n\n\n\n\n\n\n虽然上面的方法有很多，但实际开发中一般不会全部使用，只使用其中几个就够了，毕竟到底在收到请求后干什么是服务器说了算的，你完全可以只使用 POST 一种请求完成所有的功能，当然我个人推荐保留 GET，POST，PUT，DELETE 四种方法，这样做起来比较舒服\n讲完了请求，再讲讲响应，一般来说响应体是这样的：\nHTTP/1.1 200 OKDate: Fri, 22 May 2009 06:07:21 GMTContent-Type: text/html; charset=UTF-8&lt;html&gt;      &lt;head&gt;&lt;/head&gt;      &lt;body&gt;            &lt;!--body goes here--&gt;      &lt;/body&gt;&lt;/html&gt;\n\n第一行是响应头，HTTP&#x2F;1.1 代表协议，200 OK 是状态码与状态消息，然后是消息报头，类似于请求头，接着空一行就是对应的响应内容了，我简单的贴一点不同的状态码的含义常见的 HTTP 状态码主要分为以下几类：\n\n1. 信息类（1 xx）\n100 Continue（继续） ：表示客户端应继续其请求。\n101 Switching Protocols（切换协议） ：表示服务器已切换到客户端在请求的升级头部指定的协议。\n\n2. 成功类（2 xx）\n200 OK（成功） ：请求成功，响应的内容通常包含所请求的资源。\n201 Created（已创建） ：请求成功并且服务器创建了新的资源，通常用于 POST 请求创建新资源后返回。\n204 No Content（无内容） ：请求成功处理，但返回的响应体为空。\n\n3. 重定向类（3 xx）\n301 Moved Permanently（永久重定向） ：请求的资源已永久移动到新位置，客户端应使用新的 URI。\n302 Found（临时重定向） ：请求的资源临时移动到另一个 URI，客户端应向新 URI 发起请求，但后续请求仍使用原 URI。\n\n\n\n304 Not Modified（未修改） ：客户端缓存的资源未被修改，客户端可以使用缓存的版本。\n4. 客户端错误类（4 xx）\n\n\n\n\n400 Bad Request（坏请求） ：请求出现语法错误，服务器无法理解。\n401 Unauthorized（未授权） ：请求需要用户的身份认证。\n403 Forbidden（禁止访问） ：服务器拒绝执行请求，通常是因为权限不足。\n404 Not Found（未找到） ：服务器找不到请求的资源。\n\n5. 服务器错误类（5 xx）\n500 Internal Server Error（内部服务器错误） ：服务器内部错误，无法完成请求。\n501 Not Implemented（尚未实现） ：服务器不支持该请求方法。\n503 Service Unavailable（服务不可用） ：服务器当前无法处理请求，通常是服务器过载或维护。 按照约定，不提供 600 以及以上的状态码\n\n\n当然，这也是约定的，如果想，完全可以返回一个 666，这样做虽然浏览器无法正确处理，但前端仍然可以自行处理\n在最后，HTTPS 是什么东西呢，HTTPS 是超文本传输安全协议，相比 HTTP 多了安全两字，即 HTTPS 实现了对 HTTP 通信的加密处理，在 HTTPS 中第三方能够看到的只有一个 URL，剩下的一概不可知。\n结语这篇就到这里吧，写的头疼。下一期我们将从 java 的角度来看看 http 通信的实现过程，然后真正的尝试自己手搓一个完整的 http 服务器\n","tags":["手写Spring"]},{"title":"多线程与线程池","url":"/posts/afff9093/","content":"今天我们来稍微了解一下线程与线程池的相关知识\n多线程的基本操作我们首先从最基本的Thread类讲起。我们知道多线程的基本使用方法大概如下\npublic class Main &#123;    public static void main(String[] args) &#123;        Thread thread = new Thread(() -&gt; &#123;            System.out.println(&quot;Hello World&quot;);        &#125;);        thread.start();    &#125;&#125;\n\n每一个Thread对象都是一个单独的线程，当调用这个对象的start方法时这个线程就会被启动。我们可以看看Thread类的构造方法\npublic Thread(Runnable task) &#123;        this((ThreadGroup)null, (String)null, 0, task, 0L, (AccessControlContext)null);    &#125;\n\nemm具体的构造方法到底是怎么实现的暂时先不用管，我们这里只是用来明确我们刚才那个lambda表达式实际上是一个Runnable接口的实现，所以理所当然的，我们可以这样去实现多线程\npublic class Test implements Runnable &#123;    @Override    public void run() &#123;        System.out.println(&quot;Hello World&quot;);    &#125;&#125;\n\n然后把这这个类的对象直接丢到线程类的构造方法中。或者你也可以选择继承Thread类，此时可以选择重写Thread类的run方法，然后直接调用子类的start方法。通过这样的方法可以给线程中运行的程序添加一些需要使用的参数\n但这种操作存在一个问题，run方法是void的，所以在某些情况下我们如果需要返回值，可以使用回调类Callable来实现\nimport java.util.concurrent.Callable;class MyCallable implements Callable&lt;Integer&gt; &#123;    @Override    public Integer call() throws Exception &#123;        int sum = 0;        for (int i = 0; i &lt; 100; i++) &#123;            sum += i;        &#125;        return sum;    &#125;&#125;\n\n先随便定义一个回调类然后通过ExecutorService（实际上就是一个线程池）来运行\nimport java.util.concurrent.ExecutionException;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.Future;public class Test &#123;    public static void main(String[] args) &#123;        ExecutorService executor = Executors.newFixedThreadPool(2);//新建线程池        MyCallable callable = new MyCallable();        Future&lt;Integer&gt; future1 = executor.submit(callable);        Future&lt;Integer&gt; future2 = executor.submit(callable);        //这里稍微解释一下Future类，当我们使用Future去保存异步方法的返回值时及时运算还没有完成程序也会继续向下运行，直到调用get方法获取值时如果没有运算完成才会造成阻塞        try &#123;            System.out.println(&quot;线程 1 的结果：&quot; + future1.get());            System.out.println(&quot;线程 2 的结果：&quot; + future2.get());        &#125; catch (InterruptedException | ExecutionException e) &#123;            e.printStackTrace();        &#125; finally &#123;            executor.shutdown();        &#125;    &#125;&#125;\n\n如果你有一定的基础，上面的这些内容对你来说一定是非常简单的，下面我们来聊聊睡眠与锁的问题\n首先来看一个相当经典的例子\npackage Winter;public class Test &#123;    private static int a = 0;    public static void main(String[] args) &#123;        Thread thread = new Thread(() -&gt; &#123;            for (int i = 1; i &lt;= 10000; i++) &#123;                a++;            &#125;        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            for (int i = 1; i &lt;= 10000; i++) &#123;                a++;            &#125;        &#125;);        thread.start();        thread2.start();        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        System.out.println(a);    &#125;&#125;\n\n此时a的值有很大的可能不是20000，为什么？两个线程分别加了10000次，为什么不是两千呢。非常简单，我们想象一下这个相加的过程：a被保存在内存中，线程1会首先从内存中读取这个值，然后放到累加器中进行累加，再将得到的值写回内存。但是这个过程存在一个问题：线程2也在做同样的事情，如果在线程1读取之后写回之前线程2进行读取，那么必然会导致最终的运算结果小于2000.所以这个问题该怎么解决？\n有一个相当愚蠢的做法是直接睡眠\npackage Winter;public class Test &#123;    private static int a = 0;    public static void main(String[] args) &#123;        Thread thread = new Thread(() -&gt; &#123;            for (int i = 1; i &lt;= 10000; i++) &#123;                a++;            &#125;        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                throw new RuntimeException(e);            &#125;            for (int i = 1; i &lt;= 10000; i++) &#123;                a++;            &#125;        &#125;);        thread.start();        thread2.start();        try &#123;            Thread.sleep(5000);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        System.out.println(a);    &#125;&#125;\n\n一个干完另一个继续干，这样就不会冲突了。但这样只能保证10000时不出问题，那么如果是一亿呢，睡1秒时间不够呢，如果是10呢，睡一秒又太过奢侈，所以我们这里又创造了更细致的控制方法，首先是interrupt方法\npackage Winter;public class Test &#123;    private static int a = 0;    public static void main(String[] args) &#123;        Thread thread = new Thread(() -&gt; &#123;            while (true)&#123;                if(Thread.currentThread().isInterrupted())&#123;                    break;                &#125;            &#125;//在没有收到中断信号之前始终处于死循环状态            Thread.interrupted();//将终端标记复位            for (int i = 1; i &lt;= 10000; i++) &#123;                a++;            &#125;        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            for (int i = 1; i &lt;= 10000; i++) &#123;                a++;            &#125;            thread.interrupt();//向线程1发送中断信号        &#125;);        thread2.start();        thread.start();        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        System.out.println(a);    &#125;&#125;\n\n我们可以看到通过这种方式可以灵活的控制一个线程的睡眠时间，确保结果正确\n当然，其实java在这方面的控制方法还是相当丰富的，我们随便写几个\nThread.currentThread().suspend();//在本线程内调度，直接暂停某个线程t.resume();//恢复t的运行\n\n你可以试着使用这两个方法对上面的代码进行修改，这两个方法相较interrrupt方法的优越性在与线程的暂停本质上是使当前线程处于阻塞状态，此时当前线程不会占用CPU资源，而上面的循环却会无意义的占用CPU资源。\n再看一看这个方法\npublic static void main(String[] args) &#123;    Thread t1 = new Thread(() -&gt; &#123;        System.out.println(&quot;线程1开始运行！&quot;);        for (int i = 0; i &lt; 50; i++) &#123;            System.out.println(&quot;1打印：&quot;+i);        &#125;        System.out.println(&quot;线程1结束！&quot;);    &#125;);    Thread t2 = new Thread(() -&gt; &#123;        System.out.println(&quot;线程2开始运行！&quot;);        for (int i = 0; i &lt; 50; i++) &#123;            System.out.println(&quot;2打印：&quot;+i);            if(i == 10)&#123;                try &#123;                    System.out.println(&quot;线程1加入到此线程！&quot;);                    t1.join();    //在i==10时，让线程1加入，先完成线程1的内容，在继续当前内容                &#125; catch (InterruptedException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;);    t1.start();    t2.start();&#125;\n\n这里使用到了join方法，join方法其实可以认为是刚才上面的三个方法的结合，首先将t2阻塞，然后等待t1运行完成后t2收到信号恢复运行。\n接下来继续想办法改进这一段代码，我们需要引入锁的概念，我们之前提到了之所以在多线程状态下会出现问题是因为不同哦ing线程在竞争同一个资源，所以我们之前的解决方法是优先使某个线程使用该资源，在一个线程使用完成后再让其他线程使用。但是一个线程中真正使用资源的时间只占一部分，那么我们能不能想办法把这部分资源节约出来呢？我们就需要使用synchronized关键字\npackage Winter;public class Test &#123;    private static int a = 0;    public static void main(String[] args) &#123;        Thread thread = new Thread(() -&gt; &#123;            synchronized (Test.class) &#123;                for (int i = 1; i &lt;= 10000; i++) &#123;                    a++;                &#125;            &#125;        &#125;);        Thread thread2 = new Thread(() -&gt; &#123;            synchronized (Test.class) &#123;                for (int i = 1; i &lt;= 10000; i++) &#123;                    a++;                &#125;            &#125;        &#125;);        thread2.start();        thread.start();        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        System.out.println(a);    &#125;&#125;\n\n所有的synchronized内的代码只能有一个线程执行，其余线程处于阻塞状态（其实你可以试着不用这个关键字而使用上面提到的方法来实现差不多的效果）\nsynchronized 关键自后括号内的是被加锁的对象，我们称这种锁为对象锁，该对象的锁只能被一个线程持有，只有持有锁的线程才能执行被加锁的代码。（这里使用的是Test类的Class对象），但不同的对象锁之间相互无影响\n当然，我们也有更灵活的写法，\nprivate static synchronized void add()&#123;    value++;&#125;\n\n这种写法被成为方法锁，只能有一个线程调用该方法。当然，这种写法实质上和对象锁是同一种东西，如果是静态方法，加锁对象为类的Class对象，如果是动态方法，加锁对象为方法所在对象。\n使用锁可以极大的发挥多线程优势，当然，要注意下面这种情况\npublic static void main(String[] args) throws InterruptedException &#123;    Object o1 = new Object();    Object o2 = new Object();    Thread t1 = new Thread(() -&gt; &#123;        synchronized (o1)&#123;//t1先启动，开始持有o1锁            try &#123;                Thread.sleep(1000);                synchronized (o2)&#123;//在持有o1锁的同时需要使用o2锁，等待o2锁，当前线程阻塞                    System.out.println(&quot;线程1&quot;);                &#125;            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;);    Thread t2 = new Thread(() -&gt; &#123;        synchronized (o2)&#123;//线程2持有o2锁            try &#123;                Thread.sleep(1000);                synchronized (o1)&#123;//等待o1锁，线程阻塞                    System.out.println(&quot;线程2&quot;);                &#125;            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;);    t1.start();    t2.start();&#125;\n\n此时两个线程均开始等待对方持有的锁，同时陷入阻塞，那么这两个线程都永远不会被唤醒，这种状态我们称之为死锁。\n另外，考虑到某些需求，我们需要在满足某些条件时主动的释放锁，交给其他线程，此时可以这样写\npublic static void main(String[] args) throws InterruptedException &#123;    Object o1 = new Object();    Thread t1 = new Thread(() -&gt; &#123;        synchronized (o1)&#123;            try &#123;                System.out.println(&quot;开始等待&quot;);                o1.wait();     //进入等待状态并释放锁                System.out.println(&quot;等待结束！&quot;);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;);    Thread t2 = new Thread(() -&gt; &#123;        synchronized (o1)&#123;            System.out.println(&quot;开始唤醒！&quot;);            o1.notify();     //唤醒处于等待状态的线程          \tfor (int i = 0; i &lt; 50; i++) &#123;               \tSystem.out.println(i);               &#125;          \t//唤醒后依然需要等待这里的锁释放之前等待的线程才能继续        &#125;    &#125;);    t1.start();    Thread.sleep(1000);    t2.start();&#125;\n\n这种方法可以很好的控制锁的获取与释放。此外还有一个notifyall方法，这个方法可以直接唤醒所有处于等待的线程，而上面提到的notify只能唤醒随机的一个\n一些简单的进阶知识synchronized的实现机制首先回答我一个问题：锁机制的底层实现是怎样的？你可以猜一猜。\n在比较久远的时代，Java中的synchronized被成为重量级锁，实质上将获取锁与释放锁的操作映射为CPU实际线程的阻塞与唤醒，这一过程由操作系统负责调度。但是有一点令人不爽：实际的阻塞与唤醒操作是一种开销很大的操作，过于频繁的阻塞与唤醒会消耗大量资源，后来人们针对性的做出了一定的改进。\n改进的成果被称为自旋锁，什么是自旋锁？当线程需要获取锁时不再被阻塞，而是进入一个循环反复试图获取锁。等等，这难道不是越改经越回去了吗？但是仔细想想，在一个锁的所有权被频繁切换的场景下，这种操作是不是就可理解多了，最多不过是浪费几次循环的算力，相比阻塞与唤醒的操作，其消耗的资源少得多。但是在另一个方面，如果锁的切换不是那么频繁呢？那样就会消耗大量资源，所以经过改进的synchronized 实际上在初始状态下是一个自旋锁，在自旋时间超过一定的界限后就自动转换为一个重量级锁。\n但改进并没有停止，既然有重量级锁，那么必然有轻量级锁。轻量级锁是一种乐观锁，上面提到的两种锁都总是认为有其他的线程想要和自己抢夺资源，所以总是要自己实质上拥有锁，但乐观锁不这么认为，乐观锁如轻量级锁总是认为没有人和自己争抢锁，所以在运行时直接读内存并进行计算，但同时保存内存中的初始值，在运算完成后先将保存的初始值与当前内存中的值做比较，如果内存中的值与刚刚保存的值一致，说明这期间没有其他线程修改，直接将运算结果写回，如果发生了变化则说明有其他线程进行了修改，放弃此次操作，重头开始，如果这种机制多次失败，那么向上转化为自旋锁\n但优化还没有停止，人们又创造出了偏向锁。人们注意到，在某些情况下，一个对象很多时候都只被一个线程使用,所以直接在这个锁内部添加添加一条信息用于记录线程的id,如果id匹配，那么当前线程直接将这个对象当作无锁对象使用，直到有别的线程来尝试获取这个锁，此时偏向锁向轻量级锁升级。\n可以看到synchronized的机制实质上是一个逐渐升级的过程，从偏向锁开始逐渐的随着竞争的程度向上升级直到使用重量级锁。这个流程被称为锁粗化。\n内存可见性问题我们来看一看下面这段代码\npublic class Test &#123;      private static int a = 0;      public static void main(String[] args) throws InterruptedException &#123;          new Thread(() -&gt; &#123;              while (a == 0);              System.out.println(&quot;线程结束！&quot;);          &#125;).start();            Thread.sleep(1000);          System.out.println(&quot;正在修改a的值...&quot;);          a = 1;         &#125;  &#125;\n\n表面上看这段代码似乎不存在任何问题，但实际上这玩意会变成一个死循环，为什么呢？这里我们可以简单的介绍以下java的内存模型\njava的内存分为主内存和工作内存两个部分，所有的线程在实际的操作中会先从主内存读取值并存储到自己的工作内存中，然后进行使用，在更新值之后再将值写回主内存，其余时间一直在使用工作内存中的值。在上面的例子中，主线程更新了主内存中的值，但另一个线程实际上一直在循环使用工作线程中的值，并不知道主内存中的值已经被更新，导致出现死循环。\n这个问题到底该如何解决？最直接的办法就是加锁，当一个对象被加锁后每次调用时都会从工作内存刷新这个值,可以参考下面的这段代码，此时受到锁机制的影响，代码的循环是有限的\npublic class Main &#123;    private static int a = 0;    public static void main(String[] args) throws InterruptedException &#123;       new Thread(() -&gt; &#123;            while (a == 0) &#123;                synchronized (Main.class)&#123;&#125;            &#125;            System.out.println(&quot;线程结束！&quot;);        &#125;).start();        Thread.sleep(1000);        System.out.println(&quot;正在修改a的值...&quot;);        synchronized (Main.class)&#123;            a = 1;        &#125;    &#125;&#125;\n这里稍微解释一下，加锁的对象的Main的Class对象，Main类的静态属性正是包含在Class对象中的，此时对Class对象加锁，那么每次获得锁时都会从主内存内获取属性的实际值\n但是除了这种方法以外再没有别的办法了吗，还是有的，这里我们再介绍一个关键字volitale，我们可以重新修改之前的代码\npublic class Main &#123;    //添加volatile关键字    private static volatile int a = 0;    public static void main(String[] args) throws InterruptedException &#123;        new Thread(() -&gt; &#123;            while (a == 0) ;            System.out.println(&quot;线程结束！&quot;);        &#125;).start();        Thread.sleep(1000);        System.out.println(&quot;正在修改a的值...&quot;);        a = 1;    &#125;&#125;\n\n此时的代码也不会出现问题，这个关键字的功能在于两点\n\n保证不同线程之间数据的可见性\n阻止编译器的重排序，编译器在编译时可能对部分代码进行优化，其中一个比较重要的过程就是进行重排序调整代码的执行顺序，但是在多线程环境下这种重排序是可能出现问题的，所以对于跨线程调用的变量即使不加锁也至少应该使用这个关键字\n\n当然，还有一个小知识点，既然我们可以要求某个变量在多个线程内可见，那么也自然可以创造出仅在线程的工作内存内使用的属性，代码如下\npackage Winter;public class Main &#123;    public static void main(String[] args) &#123;        ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;();        threadLocal.set(0);        Thread thread = new Thread(() -&gt; &#123;            threadLocal.set(1);            System.out.println(threadLocal.get());        &#125;);        thread.start();        System.out.println(threadLocal.get());            &#125;&#125;\nThreadLocal类中的值存储在每个线程的工作内存中，各自独立，互不干涉。可以被用来实现一些比较奇怪的需求，不过我个人似乎没怎么用过。\n现代锁框架接下来我们聊一聊现代锁框架。从java5开始，java的锁机制发生了一次重大更新，诞生了除了synchronized之外的另一套锁机制，这套锁机制更加的灵活，这里简单的介绍一下。\n现代锁框架主要涉及Lock类，Condition类以及几个原子类，我们首先可以看一看Lock类的接口\npublic interface Lock &#123;      void lock();//获取锁,如果拿不到锁会造成阻塞        void lockInterruptibly() throws InterruptedException;//获取锁且响应中断      boolean tryLock();  //尝试获取锁，但不会造成阻塞      boolean tryLock(long var1, TimeUnit var3) throws InterruptedException;//尝试获取锁，其中两个参数用来设置最大等待时间      void unlock();  //释放锁      Condition newCondition();  //这个下面讲&#125;\n\n这里再对lockInterruptibly方法做一点解释，这个方法提供了对中断的支持，我们前面提到每个线程都会有一个interrupt方法,这个方法不会真的打断线程，只是对线程进行一个通知，Lock类中的lockInterruptibly方法可以监测这个通知，当收到通知时即使处在阻塞状态也会直接抛出InterruptedException异常\n此时的锁从一个依赖于具体对象的关键字变成了一个实际存在的锁对象，这在设计上显然符合Java的万物皆对象的思想，接下来我们可以来简单的了解一下Condition类，这个类可以被认为是Object类中wait方法的上位替代，可以简单的看一下\npublic interface Condition &#123;      void await() throws InterruptedException;  //相当与wait      void awaitUninterruptibly();  //相当于wait但不会被中断      long awaitNanos(long var1) throws InterruptedException;//  等待固定的时间，如果在时间内唤醒则返回剩余时间，如果超时则返回负数，注意单位是纳秒      boolean await(long var1, TimeUnit var3) throws InterruptedException;//同上但支持更细致的时间控制        boolean awaitUntil(Date var1) throws InterruptedException;  //等待到固定的时间点      void signal();  //唤醒随机的一个      void signalAll();  //唤醒全部&#125;\n\n一个Lock下可以包含多个Conditon,来实现更细致的控制。\n特别说明，上面两个类的方法中涉及类TimeUtil类，这是一个枚举类，指的是时间的单位\n可重入锁接下来介绍Lock接口的两个重要实现：可重入锁与读写锁，我们先来了解一下可重入锁。所谓的可重入锁指的是可以被多次加锁的锁对象，大概就像这样\npublic class Main &#123;    public static void main(String[] args) &#123;        Lock lock = new ReentrantLock();        lock.lock();//可以反复加锁        lock.lock();        ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;();        threadLocal.set(0);        Thread thread = new Thread(() -&gt; &#123;        lock.lock();//尝试获得锁，进入阻塞            System.out.println(&quot;获得锁&quot;);        &#125;);        thread.start();        lock.unlock();        System.out.println(&quot;第一次释放锁&quot;);        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        System.out.println(&quot;第二次释放锁&quot;);        lock.unlock();    &#125;&#125;\n可以看到我们在第一次释放锁后thread并没有获得锁，而是等到两次释放锁之后才真正获得了锁。\n此处我们进一步引入公平锁与非公平锁的概念，两者的区别如下\n\n公平锁中维护了一个等待队列，所有尝试获取锁的线程都将进入这个队列，按照先进先出的顺序来获取锁\n非公平锁中同样拥有一个等待队列，但此时当一个线程需要获取锁时会尝试先获取锁，如果获取失败则进入等待队列\n\n我们上面展示的可重入锁就是非公平锁，不过我们也可以选择公平锁模式，就像这样\nLock lock = new ReentrantLock(true);\n此时的锁就是一个公平锁\n读写锁接下来我们介绍读写锁，这种锁的创造时考虑到了这样一个事实：对同一个变量，部分线程只需要读取，部分线程需要修改，而对于只有读取需求的线程来说，可以不占用锁。在这种情况下，读写锁将锁分成了两部分：\n\n读锁：在没有任何线程占用写锁的情况下可以被多个线程获取\n写锁：在没有任何线程占用读锁的情况下可以被唯一一个线程获取\n\n大致的使用方式如下\npublic class Main &#123;    public static void main(String[] args) &#123;        ReentrantReadWriteLock lock = new ReentrantReadWriteLock();        Thread thread = new Thread(() -&gt; &#123;            System.out.println(&quot;加写锁&quot;);            lock.writeLock().lock();            try &#123;                Thread.sleep(1000);            &#125; catch (InterruptedException e) &#123;                throw new RuntimeException(e);            &#125;            System.out.println(&quot;释放写锁&quot;);            lock.writeLock().unlock();            System.out.println(&quot;加读锁&quot;);            lock.readLock().lock();        &#125;);        thread.start();        lock.writeLock().lock();        System.out.println(&quot;获得写锁&quot;);        lock.writeLock().unlock();        try &#123;            Thread.sleep(1000);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125;        lock.readLock().lock();        System.out.println(&quot;获取写锁&quot;);    &#125;&#125;\n\n这种锁在部分线程需要读取部分线程需要写入时很好的满足了需求\n原子类有些时候我们只需要一些简单的操作，此时为了简化操作，人们又创造了原子类，类中所有的方法都是线程安全的。原子类包含三种\n\nAtomicInteger：原子更新int\nAtomicLong：原子更新long\nAtomicBoolean：原子更新boolean由于在使用上比较简单，我这里只放一个例子，就不做具体的解释了\n\npublic class Main &#123;    private static AtomicInteger i = new AtomicInteger(0);    public static void main(String[] args) throws InterruptedException &#123;        Runnable r = () -&gt; &#123;            for (int j = 0; j &lt; 100000; j++)                i.getAndIncrement();            System.out.println(&quot;自增完成！&quot;);        &#125;;        new Thread(r).start();        new Thread(r).start();        TimeUnit.SECONDS.sleep(1);        System.out.println(i.get());    &#125;&#125;\n\n并发容器最后再介绍一下jdk提供的并发容器，我们之前习惯的ArrayList，HashMap等容器实际上是线程不安全的，我们这里可以使用线程安全的并发容器，比较常用的包括\n\nCopyOnWriteArrayList\nConcurrentHashMap\nBlockingQueue由于在使用时与普通容器没什么大的区别，这里就不做介绍了\n\n线程池接下来我们来了解一下java的线程池相关内容，线程的创建与销毁是一个开销很大的工作，所以我们倾向于在有长期使用需要时创建一个线程池，一次性创建足够的线程病保存在池中，之后只使用池中线程java提供了一个原生的线程池实现，大概使用方式如下\npublic class Main &#123;    public static void main(String[] args) &#123;        ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 5, 0L,                TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;&gt;(200));        for (int i = 0; i &lt; 10; i++) &#123;            executor.execute(() -&gt; &#123;                System.out.println(Thread.currentThread().getName());            &#125;);        &#125;        System.exit(0);    &#125;&#125;\n\n接下来我们去底层看一看到底是做了什么，下面是全参的构造方法\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123;        this.ctl = new AtomicInteger(ctlOf(-536870912, 0));        this.mainLock = new ReentrantLock();        this.workers = new HashSet();        this.termination = this.mainLock.newCondition();        if (corePoolSize &gt;= 0 &amp;&amp; maximumPoolSize &gt; 0 &amp;&amp; maximumPoolSize &gt;= corePoolSize &amp;&amp; keepAliveTime &gt;= 0L) &#123;            if (workQueue != null &amp;&amp; threadFactory != null &amp;&amp; handler != null) &#123;                this.corePoolSize = corePoolSize;                this.maximumPoolSize = maximumPoolSize;                this.workQueue = workQueue;                this.keepAliveTime = unit.toNanos(keepAliveTime);                this.threadFactory = threadFactory;                this.handler = handler;                String name = Objects.toIdentityString(this);                this.container = SharedThreadContainer.create(name);            &#125; else &#123;                throw new NullPointerException();            &#125;        &#125; else &#123;            throw new IllegalArgumentException();        &#125;    &#125;\n我们先简单的看一下各个参数\npublic ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123;\n下面是名词解释：\n\ncorePoolSize：核心线程数量\nmaximumPoolSize：最大线程数量\nkeepAliveTime：非核心线程等待时间\nunit：等待时间的单位\nworkQueue：任务队列\nthreadFactory：线程工厂\nhandaler：拒绝策略线程池中的线程被分为核心线程与非核心线程，所有的任务都被放入任务队列中，线程从任务队列中获取任务进行执行，如果所有核心线程都有任务，就注册新的非核心线程进行处理，如果达到最大线程数量就将任务保留在任务队列中，如果任务队列已满，则按照拒绝策略进行处理\n\n我们再来看一看exucute方法具体的实现\npublic void execute(Runnable command) &#123;       if (command == null) &#123;           throw new NullPointerException();       &#125; else &#123;           int c = this.ctl.get();//此处稍微解释一下，ctl这个变量同时存储了线程池中工作线程的数量和线程池的状态，需要通过位运算分离           //如果正在工作的线程数小于核心线程数，直接将任务给核心线程中           if (workerCountOf(c) &lt; this.corePoolSize) &#123;               if (this.addWorker(command, true)) &#123;                   return;               &#125;               c = this.ctl.get();//此时没有成功的插入任务，说明发生了某种异常，重新获取ctl           &#125;           //isRunning方法检查线程池是否正在运行，尝试将任务放到任务队列           if (isRunning(c) &amp;&amp; this.workQueue.offer(command)) &#123;               int recheck = this.ctl.get();//再次检查线程池的工作状态               if (!isRunning(recheck) &amp;&amp; this.remove(command)) &#123;                   this.reject(command);//此分支说明线程池被设置为拒绝加入，使用拒绝策略               &#125; else if (workerCountOf(recheck) == 0) &#123;                   this.addWorker((Runnable)null, false);//此分支说明线程池中无线程               &#125;           &#125; else if (!this.addWorker(command, false)) &#123;//尝试将线程放到非核心线程中               this.reject(command);           &#125;       &#125;   &#125;\n\n这里有一个额外需要解释的点事ctl,这个原子整数中保存了一个32位的int,其中部分位用来保存线程池的状态,部分位用来保存线程池中线程的数量,通过位运算获得具体位的数字得到信息\n我们可以继续深入,看看addWorker方法干了些什么\nprivate boolean addWorker(Runnable firstTask, boolean core) &#123;        for(int c = this.ctl.get(); !runStateAtLeast(c, 0) || !runStateAtLeast(c, 536870912) &amp;&amp; firstTask == null &amp;&amp; !this.workQueue.isEmpty(); c = this.ctl.get()) &#123;            while(workerCountOf(c) &lt; ((core ? this.corePoolSize : this.maximumPoolSize) &amp; 536870911)) &#123;//这个奇奇怪怪的长整数转换为二进制为 `00011111111111111111111111111111`，是用来和ctl做位运算获得线程池的不同信息的                if (this.compareAndIncrementWorkerCount(c)) &#123;//此处利用CAS操作增加c的值                    c = 0;                    boolean workerAdded = false;                    Worker w = null;                    try &#123;                        w = new Worker(firstTask);//创建一个Worker,其实就是Thread套皮                        Thread t = w.thread;                        if (t != null) &#123;                            ReentrantLock mainLock = this.mainLock;                            mainLock.lock();                            try &#123;                                int c = this.ctl.get();                                if (isRunning(c) || runStateLessThan(c, 536870912) &amp;&amp; firstTask == null) &#123;                                    if (t.getState() != State.NEW) &#123;                                        throw new IllegalThreadStateException();                                    &#125;                                    this.workers.add(w);                                    workerAdded = true;                                    int s = this.workers.size();                                    if (s &gt; this.largestPoolSize) &#123;                                        this.largestPoolSize = s;                                    &#125;                                &#125;                            &#125; finally &#123;                                mainLock.unlock();                            &#125;                            if (workerAdded) &#123;                                this.container.start(t);                                c = 1;                            &#125;                        &#125;                    &#125; finally &#123;                        if (!c) &#123;                            this.addWorkerFailed(w);                        &#125;                    &#125;                    return (boolean)c;                &#125;            &#125;            return false;        &#125;        return false;    &#125;\n看不懂没关系,我们来直接自己实现一个线程池,只实现最基本的功能，一切追求简单\npublic class ThreadPool &#123;    private AtomicInteger coreThreadCount;    private AtomicInteger maxThreadCount;    private ArrayBlockingQueue&lt;Runnable&gt; workQueue;    private AtomicInteger activeThreadCount;    private long activeTime;    public ThreadPool(int coreThreadCount, int maxThreadCount,int workQueueSize, int activeThreadCount) &#123;      this.coreThreadCount = new AtomicInteger(coreThreadCount);      this.maxThreadCount = new AtomicInteger(maxThreadCount);      this.workQueue = new ArrayBlockingQueue&lt;&gt;(workQueueSize);      this.activeThreadCount = new AtomicInteger(0);      this.activeTime = activeThreadCount;  &#125;//简单的构造方法，全都是直接赋值        public void excute(Runnable task) &#123;        if(activeThreadCount.get()&lt;coreThreadCount.get())&#123;            Thread thread = new Thread(()-&gt;&#123;                task.run();                while(true)&#123;                    Runnable r = workQueue.poll();//这里直接利用阻塞队列的特性，如果队列中没有任务会陷入阻塞                    if(r!=null)&#123;                        r.run();                    &#125;                &#125;            &#125;);//核心线程反复尝试获取任务，注册后用不销毁            thread.start();            activeThreadCount.incrementAndGet();            coreThreadCount.incrementAndGet();        &#125; else if (activeThreadCount.get()&lt;maxThreadCount.get()) &#123;            Thread thread = new Thread(()-&gt;&#123;                task.run();                while(true)&#123;                    try &#123;                    Runnable r = workQueue.poll(activeTime,TimeUnit.MILLISECONDS);                    //此处设置非核心线程的等待时间，如果时间超过了设置的时间还没有任务则退出                    if(r!=null)&#123;                        r.run();                    &#125;                    &#125;catch (InterruptedException e)&#123;                        activeThreadCount.decrementAndGet();//记得在销毁线程时活动线程数减1                        break;                    &#125;                &#125;            &#125;);            thread.start();            activeThreadCount.incrementAndGet();        &#125;else &#123;            throw new RuntimeException(&quot;超出最大线程数量&quot;);        &#125;    &#125;    &#125;\n我们总计使用了56行就实现了一个最为简单的线程池，当然，你也可以试着自己优化这个线程池，加点什么状态控制，拒绝策略等等，但后面都是一些很好实现的东西了。\n工具类最后的最后我们还需要了解一下几个简单的工具类\nCountDownLatch计数器锁假设我们存在一个多线程任务，我们需要所有线程都完成后再在主线程执行下一步，各个线程执行时间未知，该怎么实现？我们可以使用计数器锁，大概如下\npublic class Main &#123;    public static void main(String[] args) &#123;        CountDownLatch countDownLatch = new CountDownLatch(10);//计数器中有10个数        Runnable runnable = new Runnable() &#123;            public void run() &#123;                try&#123;                    Thread.sleep(1000);                    countDownLatch.countDown();//每次调用这个方法都将初始的值减1                &#125;catch (InterruptedException e)&#123;                    throw new RuntimeException(e);                &#125;            &#125;        &#125;;        for (int i = 0; i &lt; 10; i++) &#123;            new Thread(runnable).start();        &#125;        countDownLatch.await();//等待减到0才会执行下一步        System.out.println(&quot;All done&quot;);            &#125;&#125;\n\nCyclicBarrier循环屏障上面我们使用for循环来启动了10个线程，但在某些需求下我们可能会要求线程同步启动，此时可以使用循环屏障\npublic static void main(String[] args) &#123;    CyclicBarrier barrier = new CyclicBarrier(10,   //创建一个初始值为10的循环屏障                () -&gt; System.out.println(&quot;飞机马上就要起飞了，各位特种兵请准备！&quot;));   //人等够之后执行的任务    for (int i = 0; i &lt; 10; i++) &#123;        int finalI = i;        new Thread(() -&gt; &#123;            try &#123;                Thread.sleep((long) (2000 * new Random().nextDouble()));                System.out.println(&quot;玩家 &quot;+ finalI +&quot; 进入房间进行等待... (&quot;+barrier.getNumberWaiting()+&quot;/10)&quot;);                barrier.await();    //调用await方法进行等待，直到等待的线程足够多为止                //开始游戏，所有玩家一起进入游戏                System.out.println(&quot;玩家 &quot;+ finalI +&quot; 进入游戏！&quot;);            &#125; catch (InterruptedException | BrokenBarrierException e) &#123;                e.printStackTrace();            &#125;        &#125;).start();    &#125;&#125;\n直到达到要求的线程数量所有线程才能进入下一步\n此外，循环屏障可以被重复使用，每次达到约定的线程后都会重置；\nExchanger数据交换类借助这个类我们可以实现不同线程之间的数据交换，大概如下\npublic static void main(String[] args) throws InterruptedException &#123;    Exchanger&lt;String&gt; exchanger = new Exchanger&lt;&gt;();    new Thread(() -&gt; &#123;        try &#123;            System.out.println(&quot;收到主线程传递的交换数据：&quot;+exchanger.exchange(&quot;AAAA&quot;));        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;    &#125;).start();    System.out.println(&quot;收到子线程传递的交换数据：&quot;+exchanger.exchange(&quot;BBBB&quot;));&#125;\n\n我个人感觉有那么点鸡肋；\n结语好的，到这里多线程的部分就算结束了，下一期我们来研究一下HTTP解析，实现简单的网络通讯。\n\n","tags":["手写Spring"]},{"title":"网络通信","url":"/posts/3e3a64ad/","content":"今天我们来聊聊网络通信的部分，我们知道的是Spring框架使用的是一个名为DispatchServlet的类作为网络通信的处理器，而这个类实际上来自于TomCat中的Servlet，我们先一层层推进看看这些东西到底是怎么实现的\nDispatchServlet分析从流程上看，首先存在一个简单的服务器用于监听端口，一般是TomCat，在TomCat发现请求后会转发给DisPatchServlet中的doService方法，其实现如下\nprotected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;      this.logRequest(request);      Map&lt;String, Object&gt; attributesSnapshot = null;      if (WebUtils.isIncludeRequest(request)) &#123;          attributesSnapshot = new HashMap();          Enumeration&lt;?&gt; attrNames = request.getAttributeNames();          while(attrNames.hasMoreElements()) &#123;              String attrName = (String)attrNames.nextElement();              if (this.cleanupAfterInclude || attrName.startsWith(&quot;org.springframework.web.servlet&quot;)) &#123;                  attributesSnapshot.put(attrName, request.getAttribute(attrName));              &#125;          &#125;      &#125;      request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.getWebApplicationContext());      request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver);      request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver);      request.setAttribute(THEME_SOURCE_ATTRIBUTE, this.getThemeSource());      if (this.flashMapManager != null) &#123;          FlashMap inputFlashMap = this.flashMapManager.retrieveAndUpdate(request, response);          if (inputFlashMap != null) &#123;              request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap));          &#125;          request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap());          request.setAttribute(FLASH_MAP_MANAGER_ATTRIBUTE, this.flashMapManager);      &#125;      RequestPath previousRequestPath = null;      if (this.parseRequestPath) &#123;          previousRequestPath = (RequestPath)request.getAttribute(ServletRequestPathUtils.PATH_ATTRIBUTE);          ServletRequestPathUtils.parseAndCache(request);      &#125;    //上面的一大堆都是缓存机制和纠错机制，有兴趣的可以自己学习，其实很简单      try &#123;          this.doDispatch(request, response);//这里是重点，开始分发      &#125; finally &#123;          if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted() &amp;&amp; attributesSnapshot != null) &#123;              this.restoreAttributesAfterInclude(request, attributesSnapshot);          &#125;          if (this.parseRequestPath) &#123;              ServletRequestPathUtils.setParsedRequestPath(previousRequestPath, request);          &#125;      &#125;  &#125;\n也就是说真正的分发出现在doDispatch方法中，我们再去这个方法看一看发生了什么\nprotected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123;      HttpServletRequest processedRequest = request;      HandlerExecutionChain mappedHandler = null;      boolean multipartRequestParsed = false;      WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);      try &#123;          try &#123;              ModelAndView mv = null;              Exception dispatchException = null;              try &#123;                  processedRequest = this.checkMultipart(request);//检查是否是Multipart类型的请求                  multipartRequestParsed = processedRequest != request;                //在这一步获得一个包含了我们自定义的Controller和拦截器的处理器                  mappedHandler = this.getHandler(processedRequest);                  if (mappedHandler == null) &#123;                      this.noHandlerFound(processedRequest, response);                      return;                  &#125;                  HandlerAdapter ha = this.getHandlerAdapter(mappedHandler.getHandler());                  String method = request.getMethod();                  boolean isGet = HttpMethod.GET.matches(method);//判断是否的Get类型的请求                  if (isGet || HttpMethod.HEAD.matches(method)) &#123;                //对方法为Get的请求，使用getLastModified方法检查锁请求的资源是否发生变动，如果资源没有发生修改则返回304，说明资源没有发生变动，要求使用客户端缓存的资源                      long lastModified = ha.getLastModified(request, mappedHandler.getHandler());                      if ((new ServletWebRequest(request, response)).checkNotModified(lastModified) &amp;&amp; isGet) &#123;                          return;                      &#125;                  &#125;                //这里开始调用拦截器的prehandle方法，如果方法返回false那么直接返回拒绝执行                  if (!mappedHandler.applyPreHandle(processedRequest, response)) &#123;                      return;                  &#125;                //在这里真正执行了处理器中的内容，获得了一个ModeAndView对象                  mv = ha.handle(processedRequest, response, mappedHandler.getHandler());                  if (asyncManager.isConcurrentHandlingStarted()) &#123;                      return;                  &#125;                //这一步用于检查是否包含View视图，如果包含那么将视图用request命名                  this.applyDefaultViewName(processedRequest, mv);                //这一步开始再次调用拦截器，处理拦截器中的postHandle                mappedHandler.applyPostHandle(processedRequest, response, mv);              &#125; catch (Exception ex) &#123;                  dispatchException = ex;              &#125; catch (Throwable err) &#123;                  dispatchException = new ServletException(&quot;Handler dispatch failed: &quot; + err, err);              &#125;            //这一步实际上将结果返回              this.processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException);          &#125; catch (Exception ex) &#123;              triggerAfterCompletion(processedRequest, response, mappedHandler, ex);          &#125; catch (Throwable err) &#123;              triggerAfterCompletion(processedRequest, response, mappedHandler, new ServletException(&quot;Handler processing failed: &quot; + err, err));          &#125;      &#125; finally &#123;          if (asyncManager.isConcurrentHandlingStarted()) &#123;              if (mappedHandler != null) &#123;                  mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response);              &#125;          &#125; else if (multipartRequestParsed) &#123;              this.cleanupMultipart(processedRequest);          &#125;      &#125;  &#125;\n\n好的，我们现在发现追到可processDispatchResult方法，我们继续查看，看看这个方法干了什么\nprivate void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception &#123;      boolean errorView = false;    //公共的异常处理流程      if (exception != null) &#123;          if (exception instanceof ModelAndViewDefiningException) &#123;              ModelAndViewDefiningException mavDefiningException = (ModelAndViewDefiningException)exception;              this.logger.debug(&quot;ModelAndViewDefiningException encountered&quot;, exception);              mv = mavDefiningException.getModelAndView();          &#125; else &#123;              Object handler = mappedHandler != null ? mappedHandler.getHandler() : null;              mv = this.processHandlerException(request, response, handler, exception);              errorView = mv != null;          &#125;      &#125;    //尝试对可能存在的视图进行渲染  \t    if (mv != null &amp;&amp; !mv.wasCleared()) &#123;\t    //调用渲染方法，如果存在视图名则进行渲染否则什么都不做，将渲染结果写到response中         this.render(mv, request, response);          if (errorView) &#123;              WebUtils.clearErrorRequestAttributes(request);          &#125;      &#125; else if (this.logger.isTraceEnabled()) &#123;          this.logger.trace(&quot;No view rendering, null ModelAndView returned.&quot;);      &#125;    //在不存在异步处理机制的情况下执行，异步处理有一套独立的机制      if (!WebAsyncUtils.getAsyncManager(request).isConcurrentHandlingStarted()) &#123;          if (mappedHandler != null) &#123;        //调用拦截器中的AfterCompletion方法              mappedHandler.triggerAfterCompletion(request, response, (Exception)null);          &#125;      &#125;  &#125;\n\n到这里Spring的处理流程就已经结束了，剩下的部分由TomCat完成，将对应的相应返回。\nTomCat机制分析通过上面的那些分析，我们已经走完了Spring在网络通信中负责的任务，接下来我们就要去TomCat中看一看了，研究一下在实际的网络通信流程中TomCat到底在干什么。\n接下来的内容需要你对 java 的异步 IO 机制有一定的了解，可以参考NIO 机制\nTomCat有几个核心组件，分别是Connector,Server,Service.当我们通过脚本启动TomCat时这几个组件都会开始运行，其中Connecter负责监听端口，所以我们先从这个组件开始\n在启动这个组件时会调用下面的方法\nprotected void startInternal() throws LifecycleException &#123;      String id = this.protocolHandler != null ? this.protocolHandler.getId() : null;    //一连串的异常检查      if (id == null &amp;&amp; this.getPortWithOffset() &lt; 0) &#123;          throw new LifecycleException(sm.getString(&quot;coyoteConnector.invalidPort&quot;, new Object[]&#123;this.getPortWithOffset()&#125;));      &#125; else &#123;          this.setState(LifecycleState.STARTING);          if (this.protocolHandler != null &amp;&amp; this.service != null) &#123;              this.protocolHandler.setUtilityExecutor(this.service.getServer().getUtilityExecutor());//获取一个用于处理非核心任务的线程池          &#125;          try &#123;              this.protocolHandler.start();//启动协议处理器          &#125; catch (Exception e) &#123;              throw new LifecycleException(sm.getString(&quot;coyoteConnector.protocolHandlerStartFailed&quot;), e);          &#125;      &#125;  &#125;\n我们注意到这个方法的实质就是在进行了几个基本的检查之后启动了一个叫做 protocolHandler 的对象，这个对象被称为协议处理器，这个处理器有多个实现用来适配不同的协议如HTTP1.0,HTTP1.1,AJP等，我们这里以当下比较常用的HTTP1.1为例，HTTP1.1对应的协议处理器叫做 HTTP11NIOProtocol,但你会发现里面并没有start方法的实现，往上找几层继承后你会来到一个叫做 AbstractProtocol 的类，这个类中实现了start方法\npublic void start() throws Exception &#123;      if (this.getLog().isInfoEnabled()) &#123;          this.getLog().info(sm.getString(&quot;abstractProtocolHandler.start&quot;, new Object[]&#123;this.getName()&#125;));          this.logPortOffset();      &#125;//获取日志对象记录日志      this.endpoint.start();//endpoint是TomCat自己实现的线程池，启动线程池      this.monitorFuture = this.getUtilityExecutor().scheduleWithFixedDelay(() -&gt; this.startAsyncTimeout(), 0L, 60L, TimeUnit.SECONDS);//调用之前Connecter设置的非核心任务的线程池，添加一个定时任务，作用是每60秒启动检查是否有异步任务超时  &#125;\n这部分的核心是启动了线程池，我们继续前进看看这个线程池的启动方法\n//start方法实现在AbstractEndPoint类public final void start() throws Exception &#123;      if (this.bindState == AbstractEndpoint.BindState.UNBOUND) &#123;//检查端口绑定状态，如果等于没有绑定          this.bindWithCleanup();//进行绑定并执行必要的清理工作        this.bindState = AbstractEndpoint.BindState.BOUND_ON_START;      &#125;      this.startInternal();//内部启动  &#125;\n我们先看看这个绑定端口的方法，这个方法的实现有两个版本，分别是NioEndPoint和Nio2EndPoint，这两个类分别使用了java的1.0和2.0的NIO API，我们这里统一看2.0版本的API\n//上面那个有清理的bindWithCleanup就是在下面这个方法外套了一个异常捕获public void bind() throws Exception &#123;      if (this.getExecutor() == null) &#123;          this.createExecutor();//如果线程池不存在那么创建一个新的线程池     &#125;      if (this.getExecutor() instanceof ExecutorService) &#123;          this.threadGroup = AsynchronousChannelGroup.withThreadPool((ExecutorService)this.getExecutor());  \t    &#125;//创建一个异步服务套接字组共享上面创建的线程池,负责接下来的实际网络通信    if (!this.internalExecutor) &#123;          log.warn(sm.getString(&quot;endpoint.nio2.exclusiveExecutor&quot;));//检查线程池是否是TomCat内部创建的，如果不是则做出警告     &#125;      this.serverSock = AsynchronousServerSocketChannel.open(this.threadGroup);//打开上面的套接字组    this.socketProperties.setProperties(this.serverSock);//配置套接字相关的属性      InetSocketAddress addr = new InetSocketAddress(this.getAddress(), this.getPortWithOffset());//创建监听端口的相关信息      this.serverSock.bind(addr, this.getAcceptCount());//绑定端口     this.initialiseSsl();//初始化ssl相关内容&#125;\n\n我们暂时就到这一步，有兴趣的话可以自己进一步看看异步套接字组的实现，接下来我们看看另一个内部启动方法，我们继续选择NIO2版本的实现\npublic void startInternal() throws Exception &#123;      if (!this.running) &#123;          this.allClosed = false;          this.running = true;          this.paused = false;          if (this.socketProperties.getProcessorCache() != 0) &#123;              this.processorCache = new SynchronizedStack(128, this.socketProperties.getProcessorCache());          &#125;//创建一个线程安全的栈作为处理器缓存         int actualBufferPool = this.socketProperties.getActualBufferPool(this.isSSLEnabled() ? this.getSniParseLimit() * 2 : 0);          if (actualBufferPool != 0) &#123;              this.nioChannels = new SynchronizedStack(128, actualBufferPool);          &#125;//创建缓存池来缓存网络IO中的建立的通道        if (this.getExecutor() == null) &#123;              this.createExecutor();          &#125;          this.initializeConnectionLatch();//创建一个连接计数器          this.startAcceptorThread();//初始化监听线程     &#125;  &#125;\n我们继续往下追查监听线程的任务，\nprotected void startAcceptorThread() &#123;      if (this.acceptor == null) &#123;          this.acceptor = new Nio2Acceptor(this);          this.acceptor.setThreadName(this.getName() + &quot;-Acceptor&quot;);      &#125;      this.acceptor.state = AcceptorState.RUNNING;      this.getExecutor().execute(this.acceptor);  &#125;//看来下一个目标是acceptor\n我直接贴对应的run方法\npublic void run() &#123;      if (!Nio2Endpoint.this.isPaused()) &#123;          try &#123;              Nio2Endpoint.this.countUpOrAwaitConnection();//计数或等待连接，如果连接数没有达到最大那么计数器加一，如果达到最大则当前线程等待          &#125; catch (InterruptedException var2) &#123;          &#125;          if (!Nio2Endpoint.this.isPaused()) &#123;              Nio2Endpoint.this.serverSock.accept((Object)null, this);// 监听端口然后处理信息          &#125; else &#123;              this.state = AcceptorState.PAUSED;          &#125;      &#125; else &#123;          this.state = AcceptorState.PAUSED;      &#125;  &#125;\n好吧，我们的下一步是accept方法，这个方法在叠了几层继承后有这样的实现,看起来有点复杂\nFuture&lt;AsynchronousSocketChannel&gt; implAccept(Object att, CompletionHandler&lt;AsynchronousSocketChannel, Object&gt; handler) &#123;      if (!this.isOpen()) &#123;//如果没有打开，那么直接进入异常处理流程          Throwable e = new ClosedChannelException();          if (handler == null) &#123;              return CompletedFuture.withFailure(e);          &#125; else &#123;              Invoker.invoke(this, handler, att, (Object)null, e);              return null;          &#125;      &#125; else if (this.localAddress == null) &#123;          throw new NotYetBoundException();      &#125; else if (this.isAcceptKilled()) &#123;          throw new RuntimeException(&quot;Accept not allowed due cancellation&quot;);      &#125; else if (!this.accepting.compareAndSet(false, true)) &#123;          throw new AcceptPendingException();      &#125; else &#123;//从这里开始进入正常情况的处理流程          FileDescriptor newfd = new FileDescriptor();          InetSocketAddress[] isaa = new InetSocketAddress[1];          Throwable exc = null;          try &#123;              this.begin();//这里只是简单的为接下来的操作加了一个读锁              int n = Net.accept(this.fd, newfd, isaa);//这个方法是使用C++实现的，看不了源码，比较遗憾，但就是这个方法实现了对端口的监听，其中this.fd就是对之前绑定的端口的描述,返回的n是接收到的可用连接数             if (n == -2) &#123;//如果n是-2，当前不存在可用的连接事件                PendingFuture&lt;AsynchronousSocketChannel, Object&gt; result = null;                  synchronized(this.updateLock) &#123;                      if (handler == null) &#123;                          this.acceptHandler = null;                          result = new PendingFuture(this);                          this.acceptFuture = result;                      &#125; else &#123;                          this.acceptHandler = handler;                          this.acceptAttachment = att;                      &#125;                      this.acceptAcc = System.getSecurityManager() == null ? null : AccessController.getContext();                      this.acceptPending = true;                  &#125;                  this.port.startPoll(this.fdVal, Net.POLLIN);                //这里是通过对系统底层的异步IO机制注册事件监听，相当于向选择器注册对对应事件的监听                  PendingFuture var8 = result;                //既然不存在可用的监听事件，那么返回一个PendingFuture表示待处理并结束当前线程的运行                  return var8;              &#125;          &#125; catch (Throwable var17) &#123;              Throwable x = var17;              if (var17 instanceof ClosedChannelException) &#123;                  x = new AsynchronousCloseException();              &#125;              exc = x;          &#125; finally &#123;              this.end();//释放读锁          &#125;          AsynchronousSocketChannel child = null;          if (exc == null) &#123;              try &#123;                  child = this.finishAccept(newfd, isaa[0], (AccessControlContext)null);                //这里创建了一个新的异步通道，将由这个异步通道负责接下来对连接的处理              &#125; catch (Throwable x) &#123;                  exc = x;              &#125;          &#125;          this.enableAccept();//重置标志位，运行继续创建连接          if (handler == null) &#123;//如果没有提供完成处理器，那么返回一个表示完成的future对象              return CompletedFuture.withResult(child, exc);  \t        &#125; else &#123;\t        //如果存在回调处理器那么调用处理器进行处理，注意，这里的回调并不是发生在当前线程              Invoker.invokeIndirectly(this, handler, att, child, exc);             return null;          &#125;      &#125;  &#125;\n这里要特别说明两个关键点\n\n文件描述符：上面的方法中使用了文件描述符来指代一个网络通信，这来自于unix系统的万物皆文件的思想，注意，这个类本身就叫做UnixAsynchronousServerSocketChannelImpl，在操作系统中所有的文件都有一个非负的整数作为标识，而万物皆文件，自然而然的网络连接也是一个文件，所以我们通过这个数字来访问网络通信（注意，这是 Linux 版本的实现方式，在 Windows 上存在另一套实现方式）\n第二个问题是我们一直捋到这里都没有发现一个循环机制，那么为什么可以持续监听端口？我们这里选择的是nio2版本的处理流程，如果你选择去查看nio1.0版本的流程，你会发现一个while循环，但在新的版本中使用了另一种的办法：回调机制我们可以从头捋一捋这一套机制，首先回到 Nio2EndPointAcceptor 这个类，这个类的声明如下\n\nprotected class Nio2Acceptor extends Acceptor&lt;AsynchronousSocketChannel&gt;      implements CompletionHandler&lt;AsynchronousSocketChannel, Void&gt;\n可以看到这个类实现了一个叫做 CompletionHandler 的接口，也就是我们前面提到的完成处理器，结构如下\npublic interface CompletionHandler&lt;V, A&gt; &#123;      void completed(V var1, A var2);        void failed(Throwable var1, A var2);  &#125;\n这个接口的实现规定了当某种操作结束时针对是否失败的不同情况的不同处理方法，而 Acceptor 中对 Completed 方法的实现如下\n public void completed(AsynchronousSocketChannel socket,          Void attachment) &#123;      // Successful accept, reset the error delay      errorDelay = 0;      // Continue processing the socket on the current thread      // Configure the socket    if (isRunning() &amp;&amp; !isPaused()) &#123;          if (getMaxConnections() == -1) &#123;              serverSock.accept(null, this);          &#125; else if (getConnectionCount() &lt; getMaxConnections()) &#123;              try &#123;                  // This will not block                  countUpOrAwaitConnection();//如果当前连接数小于最大值则当前连接数加1，否则阻塞             &#125; catch (InterruptedException e) &#123;                  // Ignore              &#125;              serverSock.accept(null, this); //看，这里有一次调用了accept方法        &#125; else &#123;              // Accept again on a new thread since countUpOrAwaitConnection may block              getExecutor().execute(this);          &#125;        //         if (!setSocketOptions(socket)) &#123;              closeSocket(socket);          &#125;      &#125; else &#123;          if (isRunning()) &#123;              state = AcceptorState.PAUSED;          &#125;          destroySocket(socket);      &#125;  &#125;\n还记得吗，Acceptor 的 run 方法实现其实也是调用了 serverSock.accept(null, this) 方法，注意，这个方法的两个参数分别如下\npublic abstract &lt;A&gt; void accept(A var1, CompletionHandler&lt;AsynchronousSocketChannel, ? super A&gt; var2);\n也就是说这里将自己做回完成处理器传入，进一步的，这个方法的实现是上面的 implAccept，这个方法在通道正常打开的情况下执行下面的代码\nFileDescriptor newfd = new FileDescriptor();          InetSocketAddress[] isaa = new InetSocketAddress[1];          Throwable exc = null;          try &#123;              this.begin();//这里只是简单的为接下来的操作加了一个读锁              int n = Net.accept(this.fd, newfd, isaa);            /*            *这个方法时是真正的连接方法，根据文件描述符去查询是否有可用的连接，这个方法时基于异步的NIO机制实现的，不会发生阻            *塞，其中返回的n是发现的可用的连接事件，及OP_Accept事件            */            if (n == -2) &#123;//如果n是-2，当前不存在可用的连接事件                PendingFuture&lt;AsynchronousSocketChannel, Object&gt; result = null;                  synchronized(this.updateLock) &#123;                      if (handler == null) &#123;                          this.acceptHandler = null;                          result = new PendingFuture(this);                          this.acceptFuture = result;                      &#125; else &#123;                          this.acceptHandler = handler;                          this.acceptAttachment = att;                      &#125;                      this.acceptAcc = System.getSecurityManager() == null ? null : AccessController.getContext();                      this.acceptPending = true;                  &#125;                 this.port.startPoll(this.fdVal, Net.POLLIN);                //这个方法是阻塞的，直到出现对应的事件才会继续执行                  PendingFuture var8 = result;                //既然不存在可用的监听事件，那么返回一个PendingFuture表示待处理并结束当前线程的运行                  return var8;              &#125;  \n这里有一点需要解释：既然 startPoll 方法是阻塞的，然后又返回了一个 PendingFuture，但在更上层的 completeed 和 run 方法中没有对返回值有任何处理呢？这源于对操作系统底层的回调机制的的处理，在 startPoll 方法中，向操作系统注册了对对应事件的监听，如果发生了对应事件，操作系统将会调用对应的回调方法将连接加入通道组，这个过程发生在操作系统中，所以在代码中不可见。当然，也存在当前有可用连接的情况，此时向下执行\nAsynchronousSocketChannel child = null;  if (exc == null) &#123;      try &#123;          child = this.finishAccept(newfd, isaa[0], (AccessControlContext)null);      &#125; catch (Throwable x) &#123;          exc = x;      &#125;  &#125;    this.enableAccept();  if (handler == null) &#123;      return CompletedFuture.withResult(child, exc);  &#125; else &#123;      Invoker.invokeIndirectly(this, handler, att, child, exc);      return null;  &#125;\n我们可以先看看这个 finishAccept 方法到底做了些什么\nprivate AsynchronousSocketChannel finishAccept(FileDescriptor newfd, final InetSocketAddress remote, AccessControlContext acc) throws IOException, SecurityException &#123;      AsynchronousSocketChannel ch = null;        try &#123;          ch = new UnixAsynchronousSocketChannelImpl(this.port, newfd, remote);        //创建一个新的异步通道，三个参数分别为绑定的端口，表示新连接的文件描述符，以及连接的相关信息remote    &#125; catch (IOException x) &#123;          nd.close(newfd);          throw x;      &#125;    //下面是对安全管理的一些设置，我们暂且略过    try &#123;          if (acc != null) &#123;              AccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123;                  public Void run() &#123;                      SecurityManager sm = System.getSecurityManager();                      if (sm != null) &#123;                          sm.checkAccept(remote.getAddress().getHostAddress(), remote.getPort());                      &#125;                        return null;                  &#125;              &#125;, acc);          &#125; else &#123;              SecurityManager sm = System.getSecurityManager();              if (sm != null) &#123;                  sm.checkAccept(remote.getAddress().getHostAddress(), remote.getPort());              &#125;          &#125;            return ch;      &#125; catch (SecurityException var8) &#123;          try &#123;              ch.close();          &#125; catch (Throwable suppressed) &#123;              var8.addSuppressed(suppressed);          &#125;            throw var8;      &#125;  &#125;\n然后还有一个值得一看的是 Invoker 的执行流程\nstatic &lt;V, A&gt; void invokeIndirectly(AsynchronousChannel channel, final CompletionHandler&lt;V, ? super A&gt; handler, final A attachment, final V result, final Throwable exc) &#123;      try &#123;          ((Groupable)channel).group().executeOnPooledThread(new Runnable() &#123;              public void run() &#123;//可以看到在这里使用了对应的线程池在新的线程中执行了下面的任务                  GroupAndInvokeCount thisGroupAndInvokeCount = (GroupAndInvokeCount)Invoker.myGroupAndInvokeCount.get();                  if (thisGroupAndInvokeCount != null) &#123;                      thisGroupAndInvokeCount.setInvokeCount(1);                  &#125;                    Invoker.invokeUnchecked(handler, attachment, result, exc);                  //这个方法就是直接调用了completed方法            &#125;          &#125;);      &#125; catch (RejectedExecutionException var6) &#123;          throw new ShutdownChannelGroupException();      &#125;  &#125;\n走到这一步，一个连接就被建立了起来，那么接下来了，是谁去处理连接后的任务呢，我们需要再往回倒一倒，看看 completed 方法\n@Override  public void completed(AsynchronousSocketChannel socket,          Void attachment) &#123;      // Successful accept, reset the error delay      errorDelay = 0;      // Continue processing the socket on the current thread      // Configure the socket    if (isRunning() &amp;&amp; !isPaused()) &#123;          if (getMaxConnections() == -1) &#123;              serverSock.accept(null, this);          &#125; else if (getConnectionCount() &lt; getMaxConnections()) &#123;              try &#123;                  // This will not block                  countUpOrAwaitConnection();              &#125; catch (InterruptedException e) &#123;                  // Ignore              &#125;              serverSock.accept(null, this);          &#125; else &#123;              // Accept again on a new thread since countUpOrAwaitConnection may block              getExecutor().execute(this);          &#125;        //注意这里，setSocketOptions中的参数为刚刚建立的连接，也就是说这里有对刚建立的连接的进一步处理         if (!setSocketOptions(socket)) &#123;              closeSocket(socket);          &#125;      &#125; else &#123;          if (isRunning()) &#123;              state = AcceptorState.PAUSED;          &#125;          destroySocket(socket);      &#125;  &#125;\n所以我们看看 setSocketOption 方法的实现\n@Override  protected boolean setSocketOptions(AsynchronousSocketChannel socket) &#123;      Nio2SocketWrapper socketWrapper = null;      try &#123;          // Allocate channel and wrapper          Nio2Channel channel = null;          if (nioChannels != null) &#123;              channel = nioChannels.pop();          &#125;//这个nioChannels就是在EndPoint启动时创建的通道缓存        //如果没可用的通道就创建一个，如果有那么直接用          if (channel == null) &#123;              SocketBufferHandler bufhandler = new SocketBufferHandler(                      socketProperties.getAppReadBufSize(),                      socketProperties.getAppWriteBufSize(),                      socketProperties.getDirectBuffer());              if (isSSLEnabled()) &#123;                  channel = new SecureNio2Channel(bufhandler, this);              &#125; else &#123;                              channel = new Nio2Channel(bufhandler);              &#125;          &#125;        //创建一个SocketWrapper          Nio2SocketWrapper newWrapper = new Nio2SocketWrapper(channel, this);          //将刚刚创建的连接通道打包进去        channel.reset(socket, newWrapper);        //connections是一个Map，以当前连接的异步通道为键，新打包的Wrapper为值放进去          connections.put(socket, newWrapper);          socketWrapper = newWrapper;            // Set socket properties          socketProperties.setProperties(socket);            socketWrapper.setReadTimeout(getConnectionTimeout());          socketWrapper.setWriteTimeout(getConnectionTimeout());          socketWrapper.setKeepAliveLeft(Nio2Endpoint.this.getMaxKeepAliveRequests());          // Continue processing on the same thread as the acceptor is async        //开始对通道中的信息进行处理，监听可用的读事件          return processSocket(socketWrapper, SocketEvent.OPEN_READ, false);      &#125; catch (Throwable t) &#123;          ExceptionUtils.handleThrowable(t);          log.error(sm.getString(&quot;endpoint.socketOptionsError&quot;), t);          if (socketWrapper == null) &#123;              destroySocket(socket);          &#125;      &#125;      // Tell to close the socket if needed      return false;  &#125;\n顺其自然的我们继续找 processSocket 方法\npublic boolean processSocket(SocketWrapperBase&lt;S&gt; socketWrapper,          SocketEvent event, boolean dispatch) &#123;      try &#123;          if (socketWrapper == null) &#123;              return false;          &#125;        //获取缓存的处理器Processor，如果不存在那么创建一个         SocketProcessorBase&lt;S&gt; sc = null;          if (processorCache != null) &#123;              sc = processorCache.pop();          &#125;          if (sc == null) &#123;              sc = createSocketProcessor(socketWrapper, event);          &#125; else &#123;        //如果处理器存在那么重新将处理器与当前的wrapper关联              sc.reset(socketWrapper, event);          &#125;          Executor executor = getExecutor();          //如果要求分发，在线程池执行，否则直接在当前线程执行        if (dispatch &amp;&amp; executor != null) &#123;              executor.execute(sc);          &#125; else &#123;        //刚刚的setSocketOption用的是false，直接在当前线程执行            sc.run();          &#125;      &#125; catch (RejectedExecutionException ree) &#123;          getLog().warn(sm.getString(&quot;endpoint.executor.fail&quot;, socketWrapper) , ree);          return false;      &#125; catch (Throwable t) &#123;          ExceptionUtils.handleThrowable(t);          // This means we got an OOM or similar creating a thread, or that          // the pool and its queue are full        getLog().error(sm.getString(&quot;endpoint.process.fail&quot;), t);          return false;      &#125;      return true;  &#125;\n那么刚刚 run 的是什么呢\npublic final void run() &#123;      Lock lock = socketWrapper.getLock();      lock.lock();      try &#123;          if (socketWrapper.isClosed()) &#123;              return;          &#125;          doRun();      &#125; finally &#123;          lock.unlock();      &#125;  &#125;\n好吧，加个锁，然后继续 run\n    @Override      protected void doRun() &#123;          boolean launch = false;          try &#123;              int handshake;                try &#123;             //这里时对TCP连接三次握手机制的检查，0表示完成了握手过程                if (socketWrapper.getSocket().isHandshakeComplete()) &#123;                      // No TLS handshaking required. Let the handler                      // process this socket / event combination.                                        handshake = 0;                  &#125; else if (event == SocketEvent.STOP || event == SocketEvent.DISCONNECT ||                          event == SocketEvent.ERROR) &#123;                      // Unable to complete the TLS handshake. Treat it as                      // if the handshake failed.                    handshake = -1;                  &#125; else &#123;                      handshake = socketWrapper.getSocket().handshake();                      event = SocketEvent.OPEN_READ;                  &#125;              &#125; catch (IOException x) &#123;                  handshake = -1;                  if (logHandshake.isDebugEnabled()) &#123;                      logHandshake.debug(sm.getString(&quot;endpoint.err.handshake&quot;,                              socketWrapper.getRemoteAddr(), Integer.toString(socketWrapper.getRemotePort())), x);                  &#125;              &#125;              if (handshake == 0) &#123;                  SocketState state;                  // Process the request from this socket                //这里真正的发生了处理                  state = getHandler().process(socketWrapper, Objects.requireNonNullElse(event, SocketEvent.OPEN_READ));                //检查处理完后的状态                  if (state == SocketState.CLOSED) &#123;                      // Close socket and pool                      socketWrapper.close();                    //如果状态标识为需要升级协议，将launch变为true                 &#125; else if (state == SocketState.UPGRADING) &#123;                      launch = true;                  &#125;              &#125; else if (handshake == -1 ) &#123;                  getHandler().process(socketWrapper, SocketEvent.CONNECT_FAIL);                  socketWrapper.close();              &#125;          &#125; catch (VirtualMachineError vme) &#123;              ExceptionUtils.handleThrowable(vme);          &#125; catch (Throwable t) &#123;              log.error(sm.getString(&quot;endpoint.processing.fail&quot;), t);              if (socketWrapper != null) &#123;                  socketWrapper.close();              &#125;          &#125; finally &#123;              if (launch) &#123;                  try &#123;                //新创建一个处理器处理进一步处理                      getExecutor().execute(new SocketProcessor(socketWrapper, SocketEvent.OPEN_READ));                  &#125; catch (NullPointerException npe) &#123;                      if (running) &#123;                          log.error(sm.getString(&quot;endpoint.launch.fail&quot;),                                  npe);                      &#125;                  &#125;              &#125;              socketWrapper = null;              event = null;              //return to cache            //然后将当前的处理器重新放到缓存中              if (running &amp;&amp; processorCache != null) &#123;                  processorCache.push(this);              &#125;          &#125;      &#125;  &#125;\n接下来看看 process 方法在干什么，这个方法不太好找，位于 AbstractProtocol 类中，而且比较长，所以我只截取部分\nProcessor processor = (Processor) wrapper.takeCurrentProcessor();//在这里获取处理器state = processor.process(wrapper, status);//调用处理器的process方法\n这个 process 方法的实现也不好找，位于AbstractProcessorLight，看一眼具体的实现\n@Override  public SocketState process(SocketWrapperBase&lt;?&gt; socketWrapper, SocketEvent status) throws IOException &#123;        SocketState state = SocketState.CLOSED;      Iterator&lt;DispatchType&gt; dispatches = null;      do &#123;          if (dispatches != null) &#123;              DispatchType nextDispatch = dispatches.next();              if (getLog().isTraceEnabled()) &#123;                  getLog().trace(&quot;Processing dispatch type: [&quot; + nextDispatch + &quot;]&quot;);              &#125;              state = dispatch(nextDispatch.getSocketStatus());              if (!dispatches.hasNext()) &#123;                  state = checkForPipelinedData(state, socketWrapper);              &#125;          &#125; else if (status == SocketEvent.DISCONNECT) &#123;              // Do nothing here, just wait for it to get recycled          &#125; else if (isAsync() || isUpgrade() || state == SocketState.ASYNC_END) &#123;              state = dispatch(status);              state = checkForPipelinedData(state, socketWrapper);          &#125; else if (status == SocketEvent.OPEN_WRITE) &#123;              // Extra write event likely after async, ignore              state = SocketState.LONG;          &#125; else if (status == SocketEvent.OPEN_READ) &#123;        //当时传入的状态是读，所以我们直接看这里              state = service(socketWrapper);          &#125; else if (status == SocketEvent.CONNECT_FAIL) &#123;              logAccess(socketWrapper);          &#125; else &#123;              // Default to closing the socket if the SocketEvent passed in              // is not consistent with the current state of the Processor                        state = SocketState.CLOSED;          &#125;            if (getLog().isTraceEnabled()) &#123;              getLog().trace(                      &quot;Socket: [&quot; + socketWrapper + &quot;], Status in: [&quot; + status + &quot;], State out: [&quot; + state + &quot;]&quot;);          &#125;            /*           * If state is already CLOSED don&#x27;t call asyncPostProcess() as that will likely change the state to some                  * other value causing processing to continue when it should cease. The AsyncStateMachine will be recycled                  *          as part of the Processor clean-up on CLOSED so it doesn&#x27;t matter what state it is left in at this point.                   */                 if (isAsync() &amp;&amp; state != SocketState.CLOSED) &#123;              state = asyncPostProcess();              if (getLog().isTraceEnabled()) &#123;                  getLog().trace(                          &quot;Socket: [&quot; + socketWrapper + &quot;], State after async post processing: [&quot; + state + &quot;]&quot;);              &#125;          &#125;            if (dispatches == null || !dispatches.hasNext()) &#123;              // Only returns non-null iterator if there are              // dispatches to process.                        dispatches = getIteratorAndClearDispatches();          &#125;      &#125; while (state == SocketState.ASYNC_END || dispatches != null &amp;&amp; state != SocketState.CLOSED);        return state;  &#125;\n所以接下来我们要看看 service 方法，这个方法也比较长，所以我们只看看关键部分\nsetSocketWrapper(socketWrapper);//直接将打包好的连接放进处理器，之后直接通过处理器来获得对应的信息//首先是这部分，开始尝试对HTTP请求进行解析if (!inputBuffer.parseRequestLine(keptAlive, protocol.getConnectionTimeout(),          protocol.getKeepAliveTimeout())) &#123;      if (inputBuffer.getParsingRequestLinePhase() == -1) &#123;          return SocketState.UPGRADING;      &#125; else if (handleIncompleteRequestLineRead()) &#123;          break;      &#125;  &#125;    // Process the Protocol component of the request line  // Need to know if this is an HTTP 0.9 request before trying to  // parse headers.//开始获取请求的协议  prepareRequestProtocol();    if (protocol.isPaused()) &#123;      // 503 - Service unavailable      response.setStatus(503);      setErrorState(ErrorState.CLOSE_CLEAN, null);  &#125; else &#123;      keptAlive = true;      // Set this every time in case limit has been changed via JMX      request.getMimeHeaders().setLimit(protocol.getMaxHeaderCount());      // Don&#x27;t parse headers for HTTP/0.9      if (!http09 &amp;&amp; !inputBuffer.parseHeaders()) &#123;          // We&#x27;ve read part of the request, don&#x27;t recycle it          // instead associate it with the socket                openSocket = true;          readComplete = false;          break;      &#125;      if (!protocol.getDisableUploadTimeout()) &#123;          socketWrapper.setReadTimeout(protocol.getConnectionUploadTimeout());      &#125;  &#125;\n我们今天只讨论网络通信本身，不会深入的探究具体的对请求的解析流程，所以如果对请求的解析实现有兴趣可以自己看看。接下来会运行到这里\nif (getErrorState().isIoAllowed()) &#123;      // Setting up filters, and parse some request headers      rp.setStage(org.apache.coyote.Constants.STAGE_PREPARE);      try &#123;              prepareRequest();      &#125; catch (Throwable t) &#123;          ExceptionUtils.handleThrowable(t);          if (log.isDebugEnabled()) &#123;              log.debug(sm.getString(&quot;http11processor.request.prepare&quot;), t);          &#125;          // 500 - Internal Server Error          response.setStatus(500);          setErrorState(ErrorState.CLOSE_CLEAN, t);      &#125;  &#125;\n prepareRequest 方法负责将收到的请求信息转换为能够使用的键值对形式，还是和上面的一样，HTTP 信息解析不属于我们今天讨论的内容，有需要可以自己了解 接下来就是正式的请求处理了 if (getErrorState().isIoAllowed()) &#123;//如果运行进行IO      try &#123;          rp.setStage(org.apache.coyote.Constants.STAGE_SERVICE);//将状态切换为正在处理          getAdapter().service(request, response);//调用Adapter进行处理，此时请求的信息已经被封装到了request中        if (keepAlive &amp;&amp; !getErrorState().isError() &amp;&amp; !isAsync() &amp;&amp;                  statusDropsConnection(response.getStatus())) &#123;              setErrorState(ErrorState.CLOSE_CLEAN, null);          &#125; 在这里，我们终于见到了 Tomcat 的下一个重要组件：Adapter。这个组件时一个转换组件，负责将获得的 HTTP 请求信息转换为容器能够处理的形式。\n我们在上一部分中看到了 Adapter 组件被调用，adapter 会尝试着对信息做分离，然后将需要处理的信息投送到对应的 Container 组件中进行处理，我们使用 Tomcat 时提供的 Servlet 就是容器的一种，负责具体的业务处理上面我们看到了 adapter 方法被调用，在完成几个异常检查之后会有下面的流程\n//对请求中的信息做必要的处理postParseSuccess = postParseRequest(req, request, res, response);  if (postParseSuccess) &#123;      // check valves if we support async    //检查是否支持异步      request.setAsyncSupported(connector.getService().getContainer().getPipeline().isAsyncSupported());      // Calling the container    //开始获取正确的容器然后对请求进行处理      connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);  &#125;\n解释一下最后一行的一长串流式调用，首先获得当前的 connector 对应的 Service，然后从 service 中获取容器，此处的获取容器方法固定返回 Engine 容器，Engine 一般在每个 Service 中只有一个，是顶层容器，负责将请求分发给真正负责处理的容器。然后从 Engine 中获得处理管线，处理管线由一个基本容器 BaseContainer 和一系列可选包装器（Valves）组成，这些包装器负责在正式的请求处理前的检查工作与请求结束后的资源清理工作。Tomcat 原生实现了大量的 Valve，具体可以看一下这张图在默认的情况下 Engine 中的 Valve 是一个 StandardEngineValve（当然可以通过配置加一些实现），实现如下\npublic void invoke(Request request, Response response) throws IOException, ServletException &#123;        // Select the Host to be used for this Request      Host host = request.getHost();      if (host == null) &#123;          if (!response.isError()) &#123;              response.sendError(404);          &#125;          return;      &#125;      if (request.isAsyncSupported()) &#123;          request.setAsyncSupported(host.getPipeline().isAsyncSupported());      &#125;        // Ask this Host to process this request      host.getPipeline().getFirst().invoke(request, response);  &#125;\n我们可以看到这里实际上是将请求分发到了 HOST 容器，HOST 容器包含一个 StandardHostValve，实现如下\npublic void invoke(Request request, Response response) throws IOException, ServletException &#123;        // Select the Context to be used for this Request      Context context = request.getContext();     //尝试获取请求的上下文容器     if (context == null) &#123;          // Don&#x27;t overwrite an existing error          if (!response.isError()) &#123;              response.sendError(404);          &#125;          return;      &#125;        if (request.isAsyncSupported()) &#123;          request.setAsyncSupported(context.getPipeline().isAsyncSupported());      &#125;        boolean asyncAtStart = request.isAsync();        try &#123;          context.bind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);            if (!asyncAtStart &amp;&amp; !context.fireRequestInitEvent(request.getRequest())) &#123;             return;             //异步请求检查        &#125;    .        try &#123;              if (!response.isErrorReportRequired()) &#123;            //尝试将请求分发给context容器                  context.getPipeline().getFirst().invoke(request, response);              &#125;          &#125; catch (Throwable t) &#123;              ExceptionUtils.handleThrowable(t);              container.getLogger().error(sm.getString(&quot;standardHostValve.exception&quot;, request.getRequestURI()), t);  .            if (!response.isErrorReportRequired()) &#123;                  request.setAttribute(RequestDispatcher.ERROR_EXCEPTION, t);                  throwable(request, response, t);              &#125;          &#125;        //现在请求又回到了Host的控制下          response.setSuspended(false);            Throwable t = (Throwable) request.getAttribute(RequestDispatcher.ERROR_EXCEPTION);          //如果context容器刚刚已经销毁了，直接返回        if (!context.getState().isAvailable()) &#123;              return;          &#125;            //如果程序需要进行错误报告          if (response.isErrorReportRequired()) &#123;            //接下来检测是否运行更进一步的IO              AtomicBoolean result = new AtomicBoolean(false);              response.getCoyoteResponse().action(ActionCode.IS_IO_ALLOWED, result);            //如果允许IO，那么渲染一个错误页面              if (result.get()) &#123;                  if (t != null) &#123;                      throwable(request, response, t);                  &#125; else &#123;                      status(request, response);                  &#125;              &#125;          &#125;            if (!request.isAsync() &amp;&amp; !asyncAtStart) &#123;              context.fireRequestDestroyEvent(request.getRequest());          &#125;      &#125; finally &#123;       //刷新长连接的最后一次访问的时间          if (context.getAlwaysAccessSession()) &#123;              request.getSession(false);          &#125;            context.unbind(Globals.IS_SECURITY_ENABLED, MY_CLASSLOADER);      &#125;  &#125;\n接下来是 context 容器的 invoke 方法，这个方法我就不展示了，在 StandardContextValve 中实现，就是做了一点处理后移交给 Wrapper 容器，我们可以看看 Wrapper 在干什么\n//在跳过错误检查后开始分配Servlet// Allocate a servlet instance to process this request  try &#123;      if (!unavailable) &#123;          servlet = wrapper.allocate();      &#125;  &#125; catch (UnavailableException e) &#123;      container.getLogger().error(sm.getString(&quot;standardWrapper.allocateException&quot;, wrapper.getName()), e);      checkWrapperAvailable(response, wrapper);  &#125; catch (ServletException e) &#123;      container.getLogger().error(sm.getString(&quot;standardWrapper.allocateException&quot;, wrapper.getName()),              StandardWrapper.getRootCause(e));      throwable = e;      exception(request, response, e);  &#125; catch (Throwable e) &#123;      ExceptionUtils.handleThrowable(e);      container.getLogger().error(sm.getString(&quot;standardWrapper.allocateException&quot;, wrapper.getName()), e);      throwable = e;      exception(request, response, e);      // servlet = null; is set here  &#125;\n对，在上面漫长的兜圈子后我们终于看到了我们熟悉的 Servlet，allocate 方法就不看了，就是将 Wrapper 内携带的单例容器返回来而已，如果没有创建单例就自己创建一个\nif ((servlet != null) &amp;&amp; (filterChain != null)) &#123;      // Swallow output if needed      if (context.getSwallowOutput()) &#123;    //判断是否需要捕获系统输出，如System.in或System.err          try &#123;              SystemLogHandler.startCapture();              if (request.isAsyncDispatching()) &#123;//异步请求处理                  request.getAsyncContextInternal().doInternalDispatch();              &#125; else &#123;              //调用过滤链                filterChain.doFilter(request.getRequest(), response.getResponse());              &#125;          &#125; finally &#123;         //最后记录刚刚捕获的信息             String log = SystemLogHandler.stopCapture();              if (log != null &amp;&amp; !log.isEmpty()) &#123;                  context.getLogger().info(log);              &#125;          &#125;      &#125; else &#123;      //不需要捕获输出那么直接处理        if (request.isAsyncDispatching()) &#123;              request.getAsyncContextInternal().doInternalDispatch();          &#125; else &#123;              filterChain.doFilter(request.getRequest(), response.getResponse());          &#125;      &#125;    &#125;\n实质上 Servlet 容器中方法的调用发生在 doFilter 方法中，我们可以看一下\nprivate void internalDoFilter(ServletRequest request, ServletResponse response)          throws IOException, ServletException &#123;        // Call the next filter if there is one      if (pos &lt; n) &#123;        //顺次获取下一个过滤器          ApplicationFilterConfig filterConfig = filters[pos++];          try &#123;              Filter filter = filterConfig.getFilter();                if (request.isAsyncSupported() &amp;&amp; !(filterConfig.getFilterDef().getAsyncSupportedBoolean())) &#123;                  request.setAttribute(Globals.ASYNC_SUPPORTED_ATTR, Boolean.FALSE);              &#125;              if (Globals.IS_SECURITY_ENABLED) &#123;                  final ServletRequest req = request;                  final ServletResponse res = response;                  Principal principal = ((HttpServletRequest) req).getUserPrincipal();                    Object[] args = new Object[] &#123; req, res, this &#125;;                  SecurityUtil.doAsPrivilege(&quot;doFilter&quot;, filter, classType, args, principal);              &#125; else &#123;            //再次调用相同的方法，调用下一个过滤器，由于一般情况下过滤器是我们自己实现的，我们会在            //doFilter中进行过滤，然后手动调用filterChain.doFilter来实现连续的过滤                  filter.doFilter(request, response, this);              &#125;          &#125; catch (IOException | ServletException | RuntimeException e) &#123;              throw e;          &#125; catch (Throwable e) &#123;              e = ExceptionUtils.unwrapInvocationTargetException(e);              ExceptionUtils.handleThrowable(e);              throw new ServletException(sm.getString(&quot;filterChain.filter&quot;), e);          &#125;          return;      &#125;        // We fell off the end of the chain -- call the servlet instance     //运行到此处说明走完了所有过滤器，接下来调用Servlet容器     try &#123;          if (dispatcherWrapsSameObject) &#123;              lastServicedRequest.set(request);              lastServicedResponse.set(response);          &#125;            if (request.isAsyncSupported() &amp;&amp; !servletSupportsAsync) &#123;              request.setAttribute(Globals.ASYNC_SUPPORTED_ATTR, Boolean.FALSE);          &#125;          // Use potentially wrapped request from this point          if ((request instanceof HttpServletRequest) &amp;&amp; (response instanceof HttpServletResponse) &amp;&amp;                  Globals.IS_SECURITY_ENABLED) &#123;              final ServletRequest req = request;              final ServletResponse res = response;              Principal principal = ((HttpServletRequest) req).getUserPrincipal();              Object[] args = new Object[] &#123; req, res &#125;;              SecurityUtil.doAsPrivilege(&quot;service&quot;, servlet, classTypeUsedInService, args, principal);          &#125; else &#123;        //一般的HTTP请求直接运行到这里，然后调用Service方法              servlet.service(request, response);          &#125;      &#125; catch (IOException | ServletException | RuntimeException e) &#123;          throw e;      &#125; catch (Throwable e) &#123;          e = ExceptionUtils.unwrapInvocationTargetException(e);          ExceptionUtils.handleThrowable(e);          throw new ServletException(sm.getString(&quot;filterChain.servlet&quot;), e);      &#125; finally &#123;          if (dispatcherWrapsSameObject) &#123;              lastServicedRequest.set(null);              lastServicedResponse.set(null);          &#125;      &#125;  &#125;\n\n显然，到这一步请求对应的相应已经有了，该返回对应的结果了，那么返回怎么走，来，回忆上面的流程，我们实际是调用了 Adapter 组件的 service 方法，然后一层一层的调用容器，现在我们继续返回 service 方法，看看接下来该干什么，比较关键的是这个\n// Recycle the wrapper request and response  if (!async) &#123;      updateWrapperErrorCount(request, response);      request.recycle();      response.recycle();  &#125;\n我们注意到分别调用了请求和响应的 recycle 方法，这个方法会释放对象内所有的引用，即清理对象，使对象可以循环使用。再往回是 processor 的 service 方法，最后部分的实现如下\nif (getErrorState().isError() || (protocol.isPaused() &amp;&amp; !isAsync())) &#123;      return SocketState.CLOSED;//如果存在错误或者协议处理器中标注被暂停且不是异步请求  &#125; else if (isAsync()) &#123;      return SocketState.LONG;  &#125; else if (isUpgrade()) &#123;      return SocketState.UPGRADING;  &#125; else &#123;      if (sendfileState == SendfileState.PENDING) &#123;          return SocketState.SENDFILE;  //可能的状态为Pending，即等待处理，此时需要发送文件    &#125; else &#123;          if (openSocket) &#123;              if (readComplete) &#123;                  return SocketState.OPEN;              &#125; else &#123;                  return SocketState.LONG;              &#125;          &#125; else &#123;              return SocketState.CLOSED; //对于一个非异步的，没有出错的，不要求长连接的请求，返回关闭信号        &#125;      &#125;  &#125;\n接下来是协议处理器的 process 方法，我就不展示了，检测到 closed 状态直接返回，最后一路收到 closed 状态一路关闭与回收，最终关闭 Socket 通道\n我们可以大概的梳理一下上面的过程，当 Tomcat 启动时 Service 组件启动Connector ，Connector组件启动线程池与监听端口的 Acceptor，监听到的请求被 SocketWrapper，SocketWrapper 实现了 Runnable 接口，自己将自己传递给 Protocol 协议处理器，协议处理器内部通过 Adapter 将请求转发给 Container，在经历了 Engine，Host，Context，Wrapper 容器的 Valve 后被传递给负责实际业务逻辑的 Servlet，在 Servlet 内发生实际的请求处理，将相应结果写回。\n在最后的最后，我们再回到一个问题，Spring 框架与 Tomcat 时怎么整合的？答案非常简单，DisPatchServlet 是 HttpServlet 的一个子类，然后在启动时相 Tomcat 只注册了这一个 Servlet，然后由 DisPatchServlet 来调用不同的 Controller 实现。\n结语终于写完了，心累啊。不过讲了这么多，还是存在不少问题，比如我们实际上没有去关注 TCP 协议，HTTP 协议等内容，只是泛泛的谈了一下 Tomcat 的思路，下期吧，下一篇我们直接从网络架构开讲，好好说说各个协议的实现。\n\n","tags":["手写Spring"]},{"title":"Linux常用命令汇总","url":"/posts/319acda5/","content":"今天再新开一个 Tag ，专门用来记录一些常用但比较容易忘的东西，话不多说，我们直接不如正题。首先警告：请千万不要在确保无害前直接在自己的设备上执行下面的命令\n查看命令的功能授人以鱼不如授人以渔，linux 大部分的命令都有自己的操作手册，我们可以通过，man 命令来查看他们具体的作用\nman ls\n例如我们如果不知道 ls 命令的作用，我们可以通过上面的命令来直接获得 ls 命令的操作手册（当然是全英文的，不过作为程序员，想必这不是什么大的问题）\n目录操作目录操作时最为基础的操作了，我们首先看一下一些常用的别名\n. # 表示当前目录.. # 表示当前目录的父目录~ #当前用户的根目录/ # 系统的根目录 \n首先我们看一看如何在不同的目录之间移动\ncd /dir/test #转移到/dir/test目录cd test #转移到当前目录的子目录testcd .. # 转移到当前目录的父目录 \n此外 cd ~ 表示转移到当前用户的根目录，而 cd / 是转移到系统的根目录。然后是查看当前目录下的文件\nls # 查看当前目录下的所有文件ls /dir #查看/dir目录下的所有文件ls -a # 查看当前目录下的所有文件（包括隐藏文件）\n在默认状态下，linux 中以 . 开头的文件是会被隐藏的，只有添加了 -a 参数才会被显示（ls 命令的其余参数可通过 man 命令得到，我这里不再详述）然后是剪切与复制\nmv /dir/test1.txt /temp/test2.txt #将/dir下的test1.txt剪切到/temp下并命名为test2.txtcp /dir/test1.txt /temp/test2.txt #将/dir下的test1.txt复制到/temp下并命名为test2.txt\n但注意，如果想要操作目录，需要这么做\nmv -r /dir /temp # 将/dir的内容复制到/tempcp -r /dir /temp # 将/dir的内容粘贴到/temp\n-r 表示 recursion, 即递归操作，因为一个目录本质上也是一个文件, 在不加-r 参数时我们相当于只操作了目录文件而没有操作目录下的文件，通常 mv 还被用来对一个文件进行重命名然后是删除\nrm test.txt # 删除当前目录下的test.txt文件rm -r /dir #删除当前目录与目录下的所有文件（会依次询问每个文件是否删除）rm -rf /dir # 强制删除/dir目录下所有文件（不会询问，直接删除对应的目录）\n互联网热梗 rm -rf / 将会直接删除整个系统，且在没有备份的情况下无法回复。最后还有两个小命令\nfind /dir -name &#x27;a*&#x27; # find命令用于查找满足特定条件的文件，例如这个命令就是查找/dir目录下所有名称以a开头的文件并打印其名称，单引号中的内容被称为正则表达式，这个我们会在下一篇中专门讲到pwd # 打印当前所在的目录\nfind 命令的功能其实极为强大，值得专门写一篇来讲，不过对于初学者，我给出一个更为简单的使用模板\nfind 你想要查找的文件目录 -name &#x27;*target*&#x27;\n这个命令会查找对应目录下名称中包含 target 的所有文件，比如我想要查找一下我博客的配置文件，我记得这个文件叫_congfig.xml, 且一定在~&#x2F;myblog 下，那么我就写\nfind ~/myblog -name &#x27;_config.xml&#x27; # *表示任意数量的字符，我这里已经确切的知道名字了，就不加了\n最后是创建目录命令\nmkdir mydir # 创建一个名为mydir的目录\n\n文件操作看完了文件操作，我们来聊一聊文件操作，先从创建文件开始\ntouch test.txt # 在当前目录下创建名为test.txt的文件\n虽然 touch 的实际作用是修改某个文件的时间戳，但实践上更多的被用于创建文件然后是修改文件，通常使用 vim 实现，不过这就又值得单开一章了，所以我们暂时跳过，如果有兴趣可以自己找一些教程去学习 vim 的操作接下来我们了解一些常用的文件处理操作\ncat test.txt # 将test.txt的内容打印到控制台，-n参数可用来显示行号less test.txt # 按页显示内容，空格翻页more test.txt # 按页显示内容，Page UP与Page Down翻页tail -n 10 test.txt # 显示文件最后10行（没有-n 10 时为默认值5行）head -n 10 test.txt # 显示文件开头10行（没有-n 10时为默认值5行）head与tail可以实时查看文件的变化，通常被用来看日志\n那么我如果希望直接通过控制台向某个文件写入内容呢，这里我们首先引入一个概念：标准输出与标准输出。我们在学习 C 语言一定会学到一个头文件 stdio.h 这个文件实际上是指 standard input and output，即标准输入与输出。一般我们称控制台上的输入与输出为标准输入与标准输出。例如上面我们使用命令来获得某个文件的内容，就是将内容定向到标准输出，我们可以通过将这一过程重定向来实现\ncat text.txt &gt;&gt; text2.txt # 将test.txt的内容追加到text2.txt末尾\n此处的 &gt;&gt; 就表示追加重定向，将标准输出重定向为 text2.txt，此外还有覆写重定向 &gt;, 此时的输出会直接覆盖原来的内容。当然，也有一个专门的命令来实现这件事\necho ‘Hello World’ &gt;&gt; text.txt # 将引号中的内容直接写入\n关于这些奇奇怪怪的符号，我们等会儿再介绍，先看下一个命令\ngrep &#x27;test&#x27; test.txt #匹配test.txt中包含test的所有行，并打印到标准输出（支持同时查找多个文件）\n注意，这里的行不是我们所看到的行, 而是以 /r 标示的才算行，所以更多的实际上是匹配我们所认为的段的内容grep 同样支持通过正则表达式进行匹配，同时还有极为丰富的选项，我随便写几个常用的\n-i #忽略大小写差异-v #翻转，输出不符合条件的-n #输出匹配的行号-c #只输出匹配的行号，忽略内容-F #将查找的内容视为字符串而不是正则表达式\n不过如果我们希望具体的对文件的某一行进行编辑呢，直接用文本编辑器如 vim 打开编辑显然是可以的，但如果要在命令行中完成呢，我们可以通过 sed 命令来实现，sed 是 Linux 中的一款强大的流编辑器，它可以对文本进行各种操作，如替换、删除、插入等。以下是 sed 命令的详细用法：\n基本语法\nsed [选项]... &#123;script&#125; [输入文件]...\n\nsed [选项]... -f 脚本文件 [输入文件]...\n\n\n常见选项\n-n ：安静模式（quiet mode），默认情况下 sed 会将模式空间中的内容输出到屏幕，使用该选项后，只有经过处理的行才会被输出，常用于与打印命令配合使用。\n\n-i ：直接修改文件内容，而不是仅仅输出到屏幕。\n\n-f ：指定 sed 脚本文件，可以从文件中读取编辑脚本。\n\n\n基本用法\n替换文本\n\ns/pattern/replacement/flags ：这是 sed 最常用的替换命令格式，表示将匹配到的 pattern 替换为 replacement。flags 是可选参数，用于控制替换行为。\n\n示例 1 ：将文件中的 “Linux” 替换为 “linux”，且只替换每行的第一个匹配项。\n\n命令：sed &#39;s/Linux/linux/&#39; input.txt\n\n解释：s 表示替换，Linux 是要匹配的模式，linux 是要替换成的内容，/ 是分隔符。\n\n\n\n示例 2 ：全局替换，将文件中的每个 “Linux” 都替换为 “linux”。\n\n命令：sed &#39;s/Linux/linux/g&#39; input.txt\n\n解释：g 表示全局替换，即替换每行中所有匹配到的模式。\n\n\n\n示例 3 ：只替换每行的第 2 个匹配项。\n\n命令：sed &#39;s/Linux/linux/2&#39; input.txt\n\n解释：2 表示只替换每行的第 2 个匹配项。\n\n\n\n示例 4 ：忽略大小写替换，将文件中的 “linux”、“Linux”、“LINUX” 等多种大小写形式都替换成 “linux”。\n\n命令：sed &#39;s/[Ll]inux/linux/g&#39; input.txt 或 sed &#39;s/linux/linux/gi&#39; input.txt\n\n解释：第一种方法是使用正则表达式中的字符类 [Ll] 来匹配大小写不同的 “L”，第二种方法中 i 表示忽略大小写。\n\n\n\n\n\n删除文本\n\nd ：删除匹配的行。\n\n示例 1 ：删除文件中包含 “error” 的行。\n\n命令：sed &#39;/error/d&#39; input.txt\n\n解释：/error/ 是地址模式，用于指定要删除的行，d 是删除命令。\n\n\n\n示例 2 ：删除文件中的空白行。\n\n命令：sed &#39;/^$/d&#39; input.txt\n\n解释：^ 表示行首，$ 表示行尾，^$ 匹配空白行。\n\n\n\n示例 3 ：删除文件中的第 3 到第 5 行。\n\n命令：sed &#39;3,5d&#39; input.txt\n\n解释：3,5 表示行号范围，d 是删除命令。\n\n\n\n\n\n打印文本\n\np ：打印模式空间中的内容，默认情况下 sed 会自动打印模式空间，但在安静模式下需要用 p 来指定要打印的行。\n\n示例 1 ：在安静模式下打印文件中包含 “success” 的行。\n\n命令：sed -n &#39;/success/p&#39; input.txt\n\n解释：-n 禁止自动打印，/success/ 是匹配模式，p 表示打印。\n\n\n\n示例 2 ：打印文件的第 1 到第 3 行。\n\n命令：sed -n &#39;1,3p&#39; input.txt\n\n解释：-n 禁止自动打印，1,3 表示行号范围，p 表示打印。\n\n\n\n\n\n插入和追加文本\n\ni ：在匹配行之前插入文本。\n\na ：在匹配行之后追加文本。\n\n示例 1 ：在文件中包含 “note” 的行之前插入一行 “This is a new line”。\n\n命令：sed &#39;/note/i This is a new line&#39; input.txt\n\n解释：/note/ 是匹配模式，i 表示插入，后面跟着要插入的文本，需用空格分隔。\n\n\n\n示例 2 ：在文件的第 2 行之后追加一行 “Appended line”。\n\n命令：sed &#39;2a Appended line&#39; input.txt\n\n解释：2 表示行号，a 表示追加，后面跟着要追加的文本。\n\n\n\n\n\n替换整个行\n\nc ：将匹配的行替换为指定的文本。\n\n示例：将文件中包含 “warning” 的行替换为 “This line has been changed”。\n\n命令：sed &#39;/warning/c This line has been changed&#39; input.txt\n\n解释：/warning/ 是匹配模式，c 表示替换整个行，后面跟着替换后的新文本。\n\n\n\n\n\n\n高级用法\n使用正则表达式\n\nsed 支持丰富的正则表达式语法，可以实现复杂的文本匹配和操作。例如，匹配以某个字符串开头或结尾的行、匹配包含特定模式的行等。\n\n示例 1 ：匹配以 “#” 开头的行并删除。\n\n命令：sed &#39;/^#/d&#39; input.txt\n\n解释：^# 表示行首的 “#”，d 是删除命令。\n\n\n\n示例 2 ：匹配以数字开头的行并打印。\n\n命令：sed -n &#39;/^[0-9]/p&#39; input.txt\n\n解释：^[0-9] 表示行首的数字，-n 禁止自动打印，p 表示打印。\n\n\n\n\n\n使用脚本文件\n\n可以将多个 sed 命令写入一个脚本文件中，然后使用 -f 选项执行该脚本文件，方便对复杂的文本处理任务进行管理和复用。\n\n示例：创建一个名为 script.sed 的文件，内容如下：\n\ns/error/ERROR/g\n\n/SUCCESS/d\n\ns/warning/Warning/g\n\n然后使用命令 sed -f script.sed input.txt 来执行该脚本文件，对 input.txt 文件进行一系列的文本替换和删除操作。\n\n\n\n\n\n\n文件的打包与压缩接下来讲一讲文件的打包与压缩，在 Windows 上，打包与压缩通常同时发生，但在 linux 上这是两个完全独立的过程，举个简单的例子，例如有一个目录叫 /mydir，我希望将这个目录下的文件都转发给别人，但挨个发既麻烦又不能很好的保存文件的目录结构等信息，此时我们可以通过将这个目录打包为一个文件来解决，也就是我们所看到的 .tar 文件，命令如下\ntar -cf mydir.tar ./mydir # -c表示打包，-f是重命名\n此时我们得到了一个叫做 mydir.tar 的文件，这就是目录的打包文件，然后我又觉得文件体积太大，为了方便传输，所以再将这个文件压缩, 我们就用 gzip 来压缩吧\ngzip -c mydir.tar &gt;&gt; mydir.tar.gz #使用&gt;&gt;来讲输出重定向到对应的文件（这个文件可以不存在）\n上面的流程也可以简化为\ntar -zcvf mydir.tar.gz ./mydir #-z表示调用gzip压缩，-v是显示压缩过程\n然后是解压操作，如果分步走时这样的\ngunzip mydir.tar.gz # 先解压tar -xvf mydir.tar  #再解包，-x表示解包tar -zxvf mydir.tar.gz -C ./temp # -z调用gzip解压然后-x解包 -C将输出定向到./temp 目录下\n或许你会问直接压缩不是能实现同样的效果吗，这个问题下面可以解答\n文件权限管理接下来我们来讲一讲 linux 的权限管理，上面的内容一直在讲文件，那么我们就先从文件的权限管理说起吧，首先，我们随便用 ls -l 一个目录, 下面是结果\ndrwxrwxr-x 2 soul soul 7月  6 05:00 imgdrwxrwxr-x 2 soul soul 7月  6 00:48 _postsdrwxrwxr-x 2 soul soul 4月  1 21:20 tags\n\n我们看到开头是一行奇怪的字符串 drwxrwxr-x，这串字符表示的就是该文件的类型与权限，开头的 d 表示这是一个目录，之后的九位分为三组，分别代表所有者，同用户组，其余所有人对该文件的权限，开头三个是 rwx，即 read write execute 权限，对应读，写，执行。说明文件的所有者可以对这个文件进行读，写，执行。接着的 rwx 表示和所有者同用户组的成员可以读，写，执行这个文件。最后的 r-x 则表示可以读与执行，但不能写，即非同用户组成员只能读或执行，不可修改。权限的变更可以通过 chmod 命令实现, 首先，u 代表所有者，g 代表用户组，o 代表其他人，a 代表所有人，然后+是添加，-时删去，&#x3D;是设置为，例如\nchmod o+rw test.txt\n就表示对非用户组内的用户添加读写权限\nchmod g-x test.txt \n表示删去同组用户的执行权限有两点需要注意，首先，一个目录必须同时可被读与执行才能正常访问，其次如果要对目录操控需要使用 —R 参数表示递归。此外，或许你还见过另一种格式的权限修改，例如这样\nchmod 777 ./mydir\n上面的命令相当于赋予所有人全部权限。在 linux 中，read&#x3D;4，write&#x3D;2，excute&#x3D;1；7&#x3D;4+2+1，即全部权限，三位数分别代表用户，用户组，其余人。再例如\nchmod 755 ./mydir\n就表示将拥有者的权限修改为 7（读，写，执行），其余人的权限为读与执行（4+1）。上面我们反复提及用户与用户组，我们接下来看看什么是用户与用户组。\n用户与用户组首先，我们从用户说起，linux 是一个多用户的操作系统，不同的用户除了可以用于区分不同的现实使用者，也可以用于负责不同的功能，不同的功能对应不同的用户不同的权限，这样可以最大程度的保护我们设备的安全。我们先看一些基础的命令。（下面的所有命令如果权限不足请在开头添加 sudo）我们可以首先来看看自己的设备上现在有哪些用户，用户列表通常存储在 /eec/passwd 文件中，所以我们可以直接通过上面提到的 cat 命令查看\nsudo cat /etc/passwd\n我们会得到类似下面的信息\nroot:x:0:0:root:/root:/usr/bin/zshdaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologinbin:x:2:2:bin:/bin:/usr/sbin/nologin\n上面的信息中展示了三个用户的信息，每个用户占一行，不同的信息之间通过冒号分割例如第一行，从左到右分别说明用户名为 root，密码已被隐藏（x），用户 id 为 0，所属的主组 id 为 0，用户描述为 root，用户的根目录为&#x2F;root（或者叫家目录），默认的 shell 是&#x2F;usr&#x2F;bin&#x2F;zsh然后我们来看一些关于用户管理的基本命令\nuseradd testuser #添加一个名为testuser 的用户adduser testuser #部分发行版中存在的命令，添加一个名为testuser的用户并引导完成用户相关设置userdel testuser #删除名为testuser的用户passwd testuser #为用户testuser设置密码\n然后是用户相关的设置，统一使用 usermod 命令完成，不同的参数含义如下\nusermod -d /home/test testuser #将用户的家目录修改为/home/test（默认为/home/username）usermod -c ‘something’ testuser #将testuser的用户描述设置为somethingusermod -e 2030-01-01 testuser #设置testuser用户将在2030年1月1日失效usermod -s /bin/bash testuser #设置用户的默认shellusernod -u 666 testuser #设置用户的id为666usermod -g group1 testuser #设置用户的主组为group1usermod -G group2 testuser #将用户的附属组设置为group2usermod -aG group2 testuser #将用户添加到group2中\n我们上面反复提及用户组，那么什么是用户组呢？每个用户都有不同的权限，而如果在某一刻我们希望对某个权限进行批量操作时我们该怎么办？如果一个一个操作，那么这岂不是太过浪费时间？所以为了方便，我们选择将不同的用户聚集起来构成一个个用户组，用户组的信息存储在&#x2F;etc&#x2F;group 中，可以按照上面的方式自己产看一下现在有哪些用户组。然后来看一些基本的操作\ngroupadd group1 #创建一个叫做group1的用户组groupdel group1 #删除该用户组（需要确保此时组中无用户）\n然后是用户组的相关设置\ngroupmod -n group group1 #将group1的名称修改为groupgroupmod -U a,b,c group1 #将group1的成员设置为a,b,c三人groupmod -aU a,b,c group1 #添加三人到用户组中gpasswd -d user group1 #将用户user从group1中移除\n我们再上面了解到，我们所有的命令实际上都是在执行某些文件，我们通过控制这些文件只能被特定用户组的用户执行就可以实现不同的用户只能执行特定的命令。此外还有一点值得补充，在默认情况下，当一个用户被创建时，如果没有手动规定，他的主组是一个与他同名的组，组中只有他一人，而由特定的用户创建的文件则属于该用户的主组，不过我们也可以手动制定\n语法chown [选项] 所有者[:组] 文件…chown [选项] –reference&#x3D;参考文件 文件…\n选项 :\n\n-R, –recursive: 递归更改目录及其子目录中所有文件的所有者\n-v, –verbose: 显示详细操作信息\n-c, –changes: 只显示实际发生更改的文件\n-f, –silent, –quiet: 抑制错误信息\n–reference&#x3D;文件: 使用参考文件的所有者和组设置\n-h, –no-dereference: 影响符号链接本身，而不是链接指向的文件\n–from&#x3D;当前所有者: 只有当前所有者匹配时才更改\n\n基本使用格式1. 只更改所有者\nhown username filenamechown john file.txt`\n2. 同时更改所有者和组\nchown username:groupname filenamechown john:developers script.sh\n3. 只更改组（所有者前留空）\nchown :groupname filenamechown :staff document.txt\n4. 使用数字ID\nchown 1000:1000 filename    # 用户ID 1000，组ID 1000chown 1001 filename         # 只更改用户ID\n\n特殊符号为了方便后面的解释，我觉得有必要先解释一下几个比较重要的有特定含义的符号\n\n重定向输出符号:\n\n&gt; 标准输出重定向。我们上面提到了所有的命令默认将信息通过标准输出输出到控制台上，我们可以通过标准输出重定向来将输出内容指向其他地方,例如下面这样\necho &#x27;hello&#x27; &gt; text.txt\n\n上面的命令会用hello取代text.txt中的原内容\n\n&gt;&gt;标准输出追加重定向，也就是我们上面提到的，将内容追加到文件的末尾而不是直接覆盖\necho &#x27;hello&#x27; &gt;&gt; text.txt\n\n2&gt;标准错误输出重定向，当执行命令出现报错时将报错的内容输出到指定位置\nls err 2&gt; error.log\n\n&amp;&gt;或者&gt;&amp;,会同时重定向标准输出与标准错误\n\n\n\n重定向输入符号\n\n&lt;,从特定的文件而不是键盘获取输入\nfind ~/mydir -name &lt;file.txt\n\n例如此处的find命令我们通过file.txt来获取我们想要查找的文件名称而不是手动输入\n\n&lt;&lt; 多行输入重定向，可以将复杂的多行输入作为输入,例如我可以这样来方便的向文件中写入内容\n\n\n\n\ncat &gt; test.txt &lt;&lt;EOFhello linux!this is a test.EOF\n两个EOF是约定的表示文件的起始与结尾，无实际的含义3. 管道符\n\n|管道符，可以将上一条命令的输出作为下一条命令的输入，举个例子，我们知道用户的信息存在&#x2F;etc&#x2F;passwd，如果我希望查看特定用户的信息，可以\ncat /etc/passwd | grep user\n\n|&amp;包含标准错误的管道符\n\n\n\n其他相关符号\n\n;命令之间的分隔符，不必多说\n&amp;&amp;逻辑与，前一条命令执行成功才会执行后一条命令\n||逻辑或，前一条命令执行失败才会执行后一条命令\n\n\n\n网络相关接下来介绍一些和网络有关的内容，这是一个很大的内容，很难一次性讲完，我尽可能的把一些常用的命令讲一讲，但具体的操作还是需要自己去了解，我们先从最简单的 ping 讲起吧如果我希望确定自己当前的网络是否存在问题，最简单的测试方法就是 ping 命令，例如\nping www.baidu.com\n如果网络正常，我们通常会看到类似下面的信息\n❯ ping www.baidu.comPING www.baidu.com (2408:871a:2100:186c:0:ff:b07e:3fbc) 56 data bytes64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=1 ttl=53 time=182 ms64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=2 ttl=53 time=41.9 ms64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=3 ttl=53 time=82.1 ms64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=4 ttl=53 time=42.0 ms64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=5 ttl=53 time=198 ms64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=6 ttl=53 time=49.5 ms64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=7 ttl=53 time=27.8 ms64 bytes from 2408:871a:2100:186c:0:ff:b07e:3fbc: icmp_seq=8 ttl=53 time=30.5 ms^C--- www.baidu.com ping statistics ---9 packets transmitted, 8 received, 11.1111% packet loss, time 7994msrtt min/avg/max/mdev = 27.766/81.830/198.480/64.731 ms\nPing 命令会通过 ICMP 协议向对应的服务器发送数据包，支持 ICMP 协议的服务器将会返回对应的应答，我们可以通过这些信息知道延迟，丢包率等详细信息。然后是查看一些本地的网络信息\nip addr\n输出的信息类似于\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host noprefixroute        valid_lft forever preferred_lft forever2: enp12s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc fq_codel state DOWN group default qlen 1000    link/ether fc:5c:ee:27:08:af brd ff:ff:ff:ff:ff:ff3: wlp0s20f3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000    link/ether f0:20:ff:25:06:2f brd ff:ff:ff:ff:ff:ff    inet 192.168.127.105/24 brd 192.168.127.255 scope global dynamic noprefixroute wlp0s20f3       valid_lft 3066sec preferred_lft 3066sec    inet6 2408:8427:8c01:6d9:1330:1453:194b:b795/64 scope global temporary dynamic        valid_lft 7061sec preferred_lft 7061sec    inet6 2408:8427:8c01:6d9:9789:e6be:dcc9:62e0/64 scope global dynamic mngtmpaddr noprefixroute        valid_lft 7061sec preferred_lft 7061sec    inet6 fe80::5dd6:c7ca:ff9:7dc0/64 scope link noprefixroute        valid_lft forever preferred_lft forever4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default     link/ether 2e:9f:2f:66:21:65 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0       valid_lft forever preferred_lft forever\n上面的信息体现了我有 4 个网络接口, 第一个是 lo 即本地环路，第二个 e 开头表示的是有线连接，第三个 wl 开头是无线连接，最后是 docker 创建的虚拟网络接口。至于其中具体的信息，受篇幅所限，我们暂时跳过，ip 命令可选的取值如下\n\nlink：网络设备\naddress：设备上的协议（IP或IPv6）地址\naddrlabel：协议地址选择的标签配置\nroute：路由表条目\nrule：路由策略数据库中的规则顺带一提，ip 命令在部分发行版上不是自带的，需要手动安装。然后是端口的开放与关闭，比较通用的是 iptables\n\niptables -A INPUT -p 协议 -dport 端口 -j ACCEPT #开放端口iptables -D INPUT -p 协议 -dport 端口 -j ACCEPT #关闭端口\n当然，现在的比较新的发行版上会有不同的工具，例如 ubuntu\nufw allow 端口号/协议ufw delete 端口号/协议\n或者红帽系\nfirewall-cmd --permanent --add-port=端口号/协议firewall-cmd --reload #开启firewall-cmd --permanent --remove-port=端口号/协议firewall-cmd --reload  #关闭\n\n远程连接本来这部分该放在网络相关中讲的，但是这部分还是比较重要的，所以单独放一部分来讲，我们最常使用的就是 ssh 了，假设我有一台服务器，现在希望远程进行连接，那么我可以使用\nssh 用户名@主机名 \n来远程连接，之后按照引导输入密码即可远程连接，有一些可能用到的参数\n\n-p，指定端口（默认为 22）\n-i，使用身份验证文件，例如\n\nssh -i /pass/private_key 用户名@主机名\n此外也可以在\nssh 用户名@主机 command\n来执行特定的命令如果我们希望将本地的文件上传到服务器或者从服务器下载文件，可以使用 scp，就像下面这样\nscp /path/test.txt usernam@hostname:/path/target\n如果想要下载，就\nscp username@hostname:/path/test.txt /path/target\n有以下比较常用的参数\n\n-P 指定端口\n-r 递归复制目录\n-C 启用压缩模式，将文件压缩后再传输\n-i 使用身份验证文件当然，还有一个工具值得一提：rsync常规的使用和 scp 一致，讲几个比较常用的参数\n-a, 归档模式，保留用户组，权限等文件信息\n-z，压缩模式\n–exclude&#x3D;‘pattern’, 排除满足特定模式的文件\n–include&#x3D;‘pattern’，只包含满足特定模式的文件\n–partial ,启用断点续传，可以在上一次传输失败的情况下继承上一次的进度\n\n硬盘管理接下来我们聊一聊硬盘管理，首先我们来看一看 df 命令\ndf 选项 目录或文件名\n可以用来查看具体的目录或文件的硬盘占用，当然如果不填文件名的话默认使用根目录，可用的参数如下\n\n-h, 以更可读的格式输出\n-T, 显示文件系统类型\n-i, 显示 inode 使用情况然后是 fdisk 命令，首先我们需要查看我们现有的存储设备\n\nfdisk -l\n其输出一般如下\n\n设备              起点        末尾        扇区  大小 类型&#x2F;dev&#x2F;sda1           34       32767       32734   16M Microsoft 保留&#x2F;dev&#x2F;sda2        32768 10552868863 10552836096  4.9T Microsoft 基本数据&#x2F;dev&#x2F;sda3  10552868864 23437768703 12884899840    6T Linux 文件系统\n\n我们进一步可以通过 fdisk 工具来管理文件系统分区等操作，但这里我们就不做详细的介绍了，我们直接讲讲如何自动挂载存储设备，在 window 上我们插上一个 U 盘，通常可以做到自动识别，但在 linux 上特别是在一些比较老的发行版上这一点却很难做到，我们可以选择手动挂载，例如我希望挂载上面的&#x2F;dev&#x2F;sda 2, 就可以选择这样做：\nmount /dev/sda2 #挂载umount /dev/sda2 # 卸载\n\n如果这是一个经常被使用的, 我们也可以选择自动挂载，只需要修改&#x2F;etc&#x2F;fstab 文件。首先查看设备的 UUID ,可以通过\nsudo blkid\n这一操作的输出大致如下\n/dev/sda2: LABEL=&quot;Getea&quot; BLOCK_SIZE=&quot;512&quot; UUID=&quot;A8E69DCFE69D9DDE&quot; TYPE=&quot;ntfs&quot; PARTLABEL=&quot;Basic data partition&quot; PARTUUID=&quot;ec52a3ff-d720-4090-b27b-884557716feb&quot;\n然后编辑&#x2F;etc&#x2F;fstab 文件即可，使用下面的格式：UUID&#x3D;设备UUID 挂载点文件系统类型选项 0 0如上面输出中的设备就可以写为\nUUID=A8E69DCFE69D9DDE /mnt/bigdrive ntfs defaults 0 0\n其中 defaults 表示默认权限，即所有人有权限访问，也可以输入用户 id 或用户组 id 来表示特定范围的用户可以访问。最后两个 0 分别表示不备份，不检查。\n任务执行器在最后，我们再介绍一个比较重要的组件：sysytemctl. 这个组件的主要作用是管理一些需要每时每刻都在后台运行的应用，例如 mysql, docker. 对于 systemctl 来说，每一个进程都是一个 unit, 我们可以通过操作 unit 来实现不同的功能\nsystemctl list-units\n可以查看受其管理的所有 unit 的列表。习惯上，我们通过 service 文件来规定每个 unit 的行为，通常配置文件可以在&#x2F;etc&#x2F;systemd&#x2F;system 中找到。下面的文件是我的 docker 服务的配置文件\n[Unit]Description=Docker Application Container EngineDocumentation=https://docs.docker.comAfter=network-online.target nss-lookup.target docker.socket firewalld.service containerd.service time-set.targetWants=network-online.target containerd.serviceRequires=docker.socketStartLimitBurst=3StartLimitIntervalSec=60[Service]Type=notify# the default is not to use systemd for cgroups because the delegate issues still# exists and systemd currently does not support the cgroup feature set required# for containers run by dockerExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sockExecReload=/bin/kill -s HUP $MAINPIDTimeoutStartSec=0RestartSec=2Restart=always# Having non-zero Limit*s causes performance problems due to accounting overhead# in the kernel. We recommend using cgroups to do container-local accounting.LimitNPROC=infinityLimitCORE=infinity# Comment TasksMax if your systemd version does not support it.# Only systemd 226 and above support this option.TasksMax=infinity# set delegate yes so that systemd does not reset the cgroups of docker containersDelegate=yes# kill only the docker process, not all processes in the cgroupKillMode=processOOMScoreAdjust=-500\n我们可以看到这个文件其实是由很多配置项组成的，我下面简单的展示不同配置项的作用\n这里只列出部分介绍，可以去官网查看Unit配置文件文档介绍，https://www.freedesktop.org/software/systemd/man/systemd.unit.html。- Unit   - Description，服务的描述   - Documentation，文档介绍   - After，该服务要在什么服务启动之后启动，比如Mysql需要在network和syslog启动之后再启动- Install   - WantedBy，值是一个或多个Target，当前Unit激活时(enable)符号链接会放入/etc/systemd/system目录下面以Target名+.wants后缀构成的子目录中   - RequiredBy，它的值是一个或多个Target，当前Unit激活(enable)时，符号链接会放入/etc/systemd/system目录下面以Target名+.required后缀构成的子目录中   - Alias，当前Unit可用于启动的别名   - Also，当前Unit激活(enable)时，会被同时激活的其他Unit- Service   - Type，定义启动时的进程行为。它有以下几种值。   - Type=simple，默认值，执行ExecStart指定的命令，启动主进程   - Type=forking，以 fork 方式从父进程创建子进程，创建后父进程会立即退出   - Type=oneshot，一次性进程，Systemd 会等当前服务退出，再继续往下执行   - Type=dbus，当前服务通过D-Bus启动   - Type=notify，当前服务启动完毕，会通知Systemd，再继续往下执行   - Type=idle，若有其他任务执行完毕，当前服务才会运行   - ExecStart，启动当前服务的命令   - ExecStartPre，启动当前服务之前执行的命令   - ExecStartPost，启动当前服务之后执行的命令   - ExecReload，重启当前服务时执行的命令   - ExecStop，停止当前服务时执行的命令   - ExecStopPost，停止当其服务之后执行的命令   - RestartSec，自动重启当前服务间隔的秒数   - Restart，定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog   - TimeoutSec，定义 Systemd 停止当前服务之前等待的秒数   - Environment，指定环境变量\n\n我们这里随便写一个脚本作为测试\n#!/bin/bashwhile truedosleep 1 date=`date -d today +&quot;%Y-%m-%d %T&quot;` echo $&#123;date&#125;done\n上面的脚本会每隔一秒向打印一次时间，然后我们随便写一个配置文件\n[Service]ExecStart=/home/soul/test.shUser=rootGroup=rootType=forkingKillMode=processRestart=on-failureRestartSec=30s[Install]WantedBy=multi-user.targetalias=test\n接着启动这个服务\nsudo systemctl daemon-reload # 重新加载配置文件sudo systemctl enable test #允许开机自启sudo systemctl start test #现在立刻启动\n此外还有一些比较常用的命令\n# 启动服务sudo systemctl start [服务名]# 停止服务sudo systemctl stop [服务名]# 重启服务sudo systemctl restart [服务名]# 重新加载配置（不重启服务）sudo systemctl reload [服务名]# 查看单个服务状态systemctl status [服务名]# 查看所有运行中的服务systemctl list-units --type=service --state=running# 查看失败的服务systemctl --failed# 启用服务（开机自启）sudo systemctl enable [服务名]# 禁用服务（取消开机自启）sudo systemctl disable [服务名]# 查看服务是否启用systemctl is-enabled [服务名]\n如果我们需要定时执行某个命令，可以使用 timer 文件创建一个定时器单元文件（.timer），用于定义定时任务的执行时间。例如，创建 /etc/systemd/system/test.timer 文件，内容如下：\n[Unit]Description=Run test script daily[Timer]OnCalendar=dailyPersistent=true[Install]WantedBy=timers.target\n然后\nsudo systemctl enable test.timersudo systemctl start test.timer\n当然，另一个更简单的方法是使用 corn\n使用cron定时执行cron 是一个传统的定时任务调度工具，适合大多数定时任务的需求。\n\n编辑cron表： 使用crontab -e命令编辑当前用户的cron表。如果你需要以root用户身份运行任务，可以使用sudo crontab -e。\n\n配置定时任务： 在cron表中添加一行来定义定时任务的执行时间、用户和命令。格式如下：\n * * * * * command\n 其中，每列的含义依次为：\n\n分钟（0-59）\n\n小时（0-23）\n\n日（1-31）\n\n月（1-12）\n\n星期几（0-7，0和7都代表星期日）\n\ncommand：要执行的命令或脚本路径\n\n\n 例如，每天凌晨2点执行/home/soul/test.sh脚本：\n 0 2 * * * /home/soul/test.sh\n \n\n保存并退出： 保存 cron 表后，系统会自动加载新的定时任务配置。\n\n\n结语终于讲完了，我们下一期详细的讲一讲正则表达式怎么写。\n","tags":["常用汇总"]}]